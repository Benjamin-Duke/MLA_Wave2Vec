{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from Modules import LoadingModule\n",
    "from Modules import Features_encoder\n",
    "from Modules import quantizationModule\n",
    "from Modules import wav2vec_transformer\n",
    "from Modules import ContrastiveLoss\n",
    "\n",
    "from Modules import TempLibriSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#data loader module init\\nStandardScalerTransform = LoadingModule.StandardScalerTransform\\nLargeDataModule = LoadingModule.LargeDataModule(\"./data/Librispeech\", batch_size=16, num_workers=1, transform=StandardScalerTransform)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "#data loader module init\n",
    "StandardScalerTransform = LoadingModule.StandardScalerTransform\n",
    "LargeDataModule = LoadingModule.LargeDataModule(\"./data/Librispeech\", batch_size=16, num_workers=1, transform=StandardScalerTransform)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temp import dataloader ### rendre compatible PLightning quand on aura le GPU\n",
    "# en attendant import manuel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "dataset = TempLibriSpeech.LibriSpeech(split=\"train-clean-100\", target_length=48000, device='cuda')\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 1\n",
      "Audio shape: torch.Size([8, 48000])\n",
      "Texte: ('INTO THESE THE BLOOD OF NECESSITY FLOWS FROM THE HOLLOW VEIN INTO THE RIGHT AND FROM THE VENOUS ARTERY INTO THE LEFT BECAUSE THESE TWO VESSELS ARE ALWAYS FULL OF BLOOD AND THEIR ORIFICES WHICH ARE TURNED TOWARDS THE HEART CANNOT THEN BE CLOSED', 'OTHERS SINGING OTHERS PLAYING THE VARIOUS INSTRUMENTS ALREADY MENTIONED', 'STILL I WAS SORRY FOR THE POOR LITTLE OLD LADY I WISH SOMEHOW SHE COULD HAVE THAT HUNDRED DOLLARS IT WAS THE MAN WHO SAID THIS NOT THE COLLECTOR SO DO I REJOINED BILLY DOLEFULLY', \"WE OUGHT TO BE ABLE TO GET A GOOD DINNER ZVERKOV OF COURSE WON'T PAY OF COURSE NOT SINCE WE ARE INVITING HIM SIMONOV DECIDED CAN YOU IMAGINE FERFITCHKIN INTERRUPTED HOTLY AND CONCEITEDLY\", 'ONE CARRIAGE DELAYED SUFFICED TO PARALYZE THE WHOLE LINE THEN THEY SET OUT AGAIN ON THE MARCH THE WEDDING CARRIAGES WERE IN THE FILE PROCEEDING TOWARDS THE BASTILLE AND SKIRTING THE RIGHT SIDE OF THE BOULEVARD', 'AND FORGOT HER OWN GRIEF IN SOLACING THAT OF OTHERS THERE WERE CERTAIN GOOD WORKS WHICH THE CHURCH GAVE TO CHRISTIAN WIDOWS TO PERFORM THE HOSPITALS FOR INSTANCE WERE ENTIRELY IN THEIR HANDS', 'AND MAKES REMARKS WHICH YEARS LATER ARE RETOLD TO IT BUT WHICH IT HAS ITSELF ENTIRELY FORGOTTEN BESIDES THE MEMORY IN THE EARLY YEARS IS MORE FACILE BECAUSE IT IS LESS BURDENED THAN IN LATER YEARS', \"SURE AND CERTAIN RESPONDED THE GRATIFIED JUSTICE FIRE AND WATER SHOULDN'T KEEP ME AWAY SOON AFTER MISTER CARLYLE WAS LEFT ALONE ANOTHER CLERK ENTERED MISS CARLYLE IS ASKING TO SEE YOU SIR AND COLONEL BETHEL'S COME AGAIN\")\n",
      "--------------------------------------------------\n",
      "Exemple 2\n",
      "Audio shape: torch.Size([8, 48000])\n",
      "Texte: ('THERE WERE TWO INFLUENCES AT WORK IN JESSE BENTLEY AND ALL HIS LIFE HIS MIND HAD BEEN A BATTLEGROUND FOR THESE INFLUENCES FIRST THERE WAS THE OLD THING IN HIM HE WANTED TO BE A MAN OF GOD AND A LEADER AMONG MEN OF GOD', 'SHE THANKED HIM AS HEARTILY AS IF HE HAD WRITTEN IT HIMSELF TIS ONLY FROM JAMES HOWEVER AS SHE LOOKED AT THE DIRECTION SHE OPENED IT IT WAS FROM OXFORD AND TO THIS PURPOSE DEAR CATHERINE', 'AND ALL THE OTHERS RUNG OUT WITH ORDER OR WITHOUT ORDER BREAKING THE HUSH DIRECTLY AS THE HORSES BELLS WERE STILLED THROWN INTO THE AIR WITH ALL THE GLADNESS OF CHILDHOOD', 'ON WEDNESDAY ASIDE FROM A LITTLE MORE WHISPERING AND SIGNIFICANT GLANCES EXCHANGED AMONG THE PUPILS NOT A RIPPLE DISTURBED THE CALM OF THE STUDY HALL IT WAS THEREFORE A DISTINCT AND NOT ALTOGETHER PLEASANT SURPRISE WHEN MISS THOMPSON WALKED INTO THE ROOM', 'WE HAVE A QUARTER OF AN HOUR BEFORE THE POSSE CAN GET DOWN TO US BUT COME THEY WILL AND THOU CANST JUDGE WHAT CHANCE WE HAVE TO SAVE LIBERTY', 'EVERYTHING IS AS YOU LEFT IT BUT IT GLIDED ABOUT THE ROOM WITH THE GRACE OF A FAIRY AND THE TENDERNESS OF AN ANGEL', 'I HAVE A PLAN TO PROPOSE I WAS HERE LAST SUMMER WITH A COUPLE OF HARVARD MEN AND WE LODGED AT A FARMHOUSE ABOUT A MILE DISTANT FROM THE CATHEDRAL IF YOU WILL STEP INTO THE COFFEE ROOM FOR AN HOUR', 'IS BECOME A MERE JARGON EVERY BODY PRETENDS TO FEEL AND TRIES TO DESCRIBE WITH THE TASTE AND ELEGANCE OF HIM WHO FIRST DEFINED WHAT PICTURESQUE BEAUTY WAS I DETEST JARGON OF EVERY KIND AND SOMETIMES I HAVE KEPT MY FEELINGS TO MYSELF')\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, (audio, text) in enumerate(data_loader):\n",
    "    print(f\"Exemple {i+1}\")\n",
    "    print(f\"Audio shape: {audio.shape}\")\n",
    "    print(f\"Texte: {text}\")\n",
    "    print(\"-\" * 50)\n",
    "    if i == 1: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model dev ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model_W2V(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, d_model, num_layers, max_relative_position):\n",
    "\n",
    "        #EAB\n",
    "        self.batch_size = batch_size\n",
    "        #self.seq_length = seq_length\n",
    "        self.embed_size = embed_size\n",
    "        self.mask_prob = 0.50\n",
    "        self.mask_length = 1\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.forward_expansion = forward_expansion\n",
    "        self.kernel_size = kernel_size\n",
    "        self.groups = groups\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.num_codebooks = 2\n",
    "        self.num_codes = 320\n",
    "        \n",
    "        self.code_dim = 256\n",
    "        self.output_dim = 512\n",
    "        self.temperature= 0.5\n",
    "\n",
    "        self.max_relative_position = max_relative_position\n",
    "\n",
    "        super(Model_W2V, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.FeaturesEncoder = Features_encoder.FeatureEncoder(input_channels=1, feature_dim=512) #1501 ?\n",
    "        self.masking = wav2vec_transformer.MaskingWithLearnableEmbedding()\n",
    "        # d_model, num_heads, dropout, forward_expansion):\n",
    "        self.TranformerBlock = wav2vec_transformer.TransformerBlockW(self.d_model, self.num_heads, self.dropout, self.forward_expansion)   #(self.embed_size, self.num_heads, self.dropout, self.forward_expansion, self.kernel_size, self.groups, self.d_model, self.max_relative_position)\n",
    "        self.quantization = quantizationModule.QuantizationModule(\n",
    "            input_dim=512,  # Should match feature_dim from FeatureEncoder\n",
    "            codebook_size=self.num_codes,\n",
    "            num_codebooks=self.num_codebooks,\n",
    "            output_dim=self.output_dim,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        self.LossItem = ContrastiveLoss.LossW2V(20,self.temperature)\n",
    "#embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, d_model):\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "       # print(\"ORIGINAL , \", x.shape)\n",
    "        x = x.to(next(self.parameters()).device)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = self.FeaturesEncoder(x)\n",
    "        \n",
    "       #\n",
    "        \n",
    "        \n",
    "        # print(\"q\",x.shape)\n",
    "        \n",
    "        quantized_repr = self.quantization(x)\n",
    "        \n",
    "        masked_reps, mask = self.masking(x, self.mask_prob, self.mask_length) #(self, x, mask_prob, mask_length)\n",
    "        \n",
    "        contextualized_reps = self.TranformerBlock(masked_reps, masked_reps, masked_reps, mask)\n",
    "                                                # value, key, query, mask=None\n",
    "        \n",
    "\n",
    "        #print(\"Debug\", contextualized_reps.shape, quantized_repr.shape, mask.shape)\n",
    "        loss = self.LossItem.compute_loss(contextualized_reps, quantized_repr, mask, self.batch_size)\n",
    "        # print(\"Context Representation shape:\", contextualized_reps.shape)\n",
    "        # print(\"Quantized Representation shape:\", quantized_repr.shape)\n",
    "        # print(\"Mask Indices shape:\", masked_reps.shape)\n",
    "        # mask = torch.tensor(mask)\n",
    "        # print(\"Unique Mask Indices values:\", mask.unique())\n",
    "\n",
    "        \n",
    "   # embed_size, num_heads, dropout, forward_expansion, kernel_size, groups,d_model\n",
    "        \n",
    "        return x, contextualized_reps, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, dataset, epochs, learning_rate, device):\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=model.batch_size, shuffle=True)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        num_batches = len(dataloader) - 1\n",
    "\n",
    "        for batch_idx, (inputs, _) in enumerate(tqdm( data_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "            if batch_idx >= num_batches:\n",
    "                break  # S'arrêter avant la dernière itération\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            _,_, loss = model(inputs)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{batch_idx+1}/{num_batches}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 1/3568 [00:00<49:42,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/3567], Loss: 3.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   3%|▎         | 101/3568 [00:57<32:34,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [101/3567], Loss: 3.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   6%|▌         | 201/3568 [01:53<31:35,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [201/3567], Loss: 2.9518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   8%|▊         | 301/3568 [02:51<31:11,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [301/3567], Loss: 2.9485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  11%|█         | 401/3568 [03:49<30:01,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [401/3567], Loss: 2.9473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  14%|█▍        | 501/3568 [04:45<28:47,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [501/3567], Loss: 2.9472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  17%|█▋        | 601/3568 [05:42<28:16,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [601/3567], Loss: 2.9466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  20%|█▉        | 701/3568 [06:38<27:19,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [701/3567], Loss: 2.9458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  22%|██▏       | 801/3568 [07:35<25:58,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [801/3567], Loss: 2.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  25%|██▌       | 901/3568 [08:32<25:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [901/3567], Loss: 2.9457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  28%|██▊       | 1001/3568 [09:29<25:04,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1001/3567], Loss: 2.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  31%|███       | 1101/3568 [10:26<23:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1101/3567], Loss: 2.9458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  34%|███▎      | 1201/3568 [11:23<22:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1201/3567], Loss: 2.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  36%|███▋      | 1301/3568 [12:20<21:22,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1301/3567], Loss: 2.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  39%|███▉      | 1401/3568 [13:16<20:18,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1401/3567], Loss: 2.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  42%|████▏     | 1501/3568 [14:13<19:57,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1501/3567], Loss: 2.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  45%|████▍     | 1601/3568 [15:10<18:31,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1601/3567], Loss: 2.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  48%|████▊     | 1701/3568 [16:07<17:40,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1701/3567], Loss: 2.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  50%|█████     | 1801/3568 [17:04<16:31,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1801/3567], Loss: 2.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  53%|█████▎    | 1901/3568 [18:01<15:49,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1901/3567], Loss: 2.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  56%|█████▌    | 2001/3568 [18:58<14:25,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2001/3567], Loss: 2.9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  59%|█████▉    | 2101/3568 [19:55<14:30,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2101/3567], Loss: 2.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  62%|██████▏   | 2201/3568 [20:52<12:36,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2201/3567], Loss: 2.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  64%|██████▍   | 2301/3568 [21:49<11:56,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2301/3567], Loss: 2.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  67%|██████▋   | 2401/3568 [22:46<10:36,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2401/3567], Loss: 2.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  70%|███████   | 2501/3568 [23:43<10:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2501/3567], Loss: 2.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  73%|███████▎  | 2601/3568 [24:39<08:58,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2601/3567], Loss: 2.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  76%|███████▌  | 2701/3568 [25:36<08:05,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2701/3567], Loss: 2.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  79%|███████▊  | 2801/3568 [26:32<08:14,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2801/3567], Loss: 2.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  81%|████████▏ | 2901/3568 [27:29<06:17,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2901/3567], Loss: 2.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  84%|████████▍ | 3001/3568 [28:26<05:19,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3001/3567], Loss: 2.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  87%|████████▋ | 3101/3568 [29:24<04:23,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3101/3567], Loss: 2.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  90%|████████▉ | 3201/3568 [30:20<03:31,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3201/3567], Loss: 2.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  93%|█████████▎| 3301/3568 [31:16<02:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3301/3567], Loss: 2.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  95%|█████████▌| 3401/3568 [32:13<01:33,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3401/3567], Loss: 2.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  98%|█████████▊| 3501/3568 [33:10<00:38,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3501/3567], Loss: 2.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|█████████▉| 3567/3568 [33:48<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] Average Loss: 2.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "seq_length = 151\n",
    "embed_size = 512\n",
    "num_heads = 8\n",
    "dropout = 0.1\n",
    "forward_expansion = 4\n",
    "kernel_size = 7\n",
    "groups = 2\n",
    "d_model = 512\n",
    "num_layers = 12\n",
    "\n",
    "max_relative_position=128\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "device = 'cuda'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model_W2V(embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, d_model, num_layers, max_relative_position).to(device)\n",
    "\n",
    "\n",
    "train_model(model, dataset, epochs=1, learning_rate=1e-4, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mavg_loss\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'avg_loss' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Créez un DataLoader pour le jeu de données de test\n",
    "dataset = TempLibriSpeech.LibriSpeech(split=\"test-clean\", target_length=480000, device='cuda')\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "all_quantized_reps = []\n",
    "all_contextualized_reps = []\n",
    "\n",
    "# Calcul de la perte de reconstruction ou de quantification\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        inputs, _ = batch  # Ici, _ signifie qu'il n'y a pas de labels\n",
    "        \n",
    "        inputs = inputs.to('cuda')  # Assurez-vous que les inputs sont sur le bon device\n",
    "\n",
    "        # Passe avant\n",
    "        quantized_repr, contextualized_reps, loss = model(inputs)\n",
    "\n",
    "        # Ajout des représentations à la liste\n",
    "        all_quantized_reps.append(quantized_repr.cpu().numpy())\n",
    "        all_contextualized_reps.append(contextualized_reps.cpu().numpy())\n",
    "\n",
    "        # Accumuler la perte\n",
    "        total_loss += loss.item()\n",
    "\n",
    "# Calcul de la moyenne de la perte sur l'ensemble du dataset\n",
    "average_loss = total_loss / len(data_loader)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Average Loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_loss = total_loss / len(data_loader)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Average Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
