{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from Modules import LoadingModule\n",
    "from Modules import Features_encoder\n",
    "from Modules import quantizationModule\n",
    "from Modules import wav2vec_transformer\n",
    "from Modules import ContrastiveLoss\n",
    "\n",
    "from Modules import TempLibriSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#data loader module init\\nStandardScalerTransform = LoadingModule.StandardScalerTransform\\nLargeDataModule = LoadingModule.LargeDataModule(\"./data/Librispeech\", batch_size=16, num_workers=1, transform=StandardScalerTransform)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "#data loader module init\n",
    "StandardScalerTransform = LoadingModule.StandardScalerTransform\n",
    "LargeDataModule = LoadingModule.LargeDataModule(\"./data/Librispeech\", batch_size=16, num_workers=1, transform=StandardScalerTransform)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temp import dataloader ### rendre compatible PLightning quand on aura le GPU\n",
    "# en attendant import manuel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "dataset = TempLibriSpeech.LibriSpeech(split=\"train-clean-100\", target_length=16000, device='cuda')\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 1\n",
      "Audio shape: torch.Size([16, 16000])\n",
      "Texte: ('THE FACTOR THAT UNDERLIES ALL THE PERPLEXITIES AND MOST OF THE CONTENTMENT OF MARRIAGE IS ITS UNIQUE DEGREE OF CONCENTRATED INTIMACY HERE THE SUPREME TESTING ALWAYS COMES EACH MEANS SO MUCH TO THE OTHER', \"YOUR HONOUR REPLIED THE CORPORAL KNOWS OF TOM'S MISFORTUNES BUT THIS AFFAIR HAS NOTHING TO DO WITH THEM ANY FURTHER THAN THIS\", \"YES I SUPPOSE IT'S SO WELL SENATOR BALLOON PUT FIFTEEN CENTS WORTH OF STAMPS ON EACH OF THOSE SEVEN HUGE BOXES OF OLD CLOTHES AND SHIPPED THAT TON OF SECOND HAND RUBBISH OLD BOOTS AND PANTALOONS AND WHAT NOT THROUGH THE MAILS AS REGISTERED MATTER\", 'I IMAGINED THAT THEY WOULD BE DISGUSTED UNTIL', \"BUT PIERCED BY ONE ONLY THE MOTTO BEING SHE ALONE THE HEART WAS MADE OF A SINGLE RUBY AS BIG AS AN OSTRICH'S EGG\", 'STAY COUNT HE ADDED YOU WHO MAY BE CALLED THE EMPEROR IF I CLAIM THE TITLE OF KING OF FINANCE HAVE YOU MANY PIECES OF PAPER OF THIS SIZE EACH WORTH A MILLION', 'MISTER WILMINGTON AND MISSUS MUNGER ARE OLD FRIENDS THE YOUNG FELLOW BOWED SILENTLY AND ANNIE INSTANTLY TOOK A DISLIKE TO HIM HIS HEAVY JAW LONG EYES AND LOW FOREHEAD ALMOST HIDDEN UNDER A THICK BANG HE SAT DOWN CORNERWISE ON A CHAIR', 'HE WHO WOUNDED JUSSAC CRIED THE KING HE A BOY', 'THE MODIFICATIONS OF THE HUMAN BODY OF WHICH THE IDEAS REPRESENT EXTERNAL BODIES AS PRESENT TO US WE WILL CALL THE IMAGES OF THINGS THOUGH THEY DO NOT RECALL THE FIGURE OF THINGS WHEN THE MIND REGARDS BODIES IN THIS FASHION WE SAY THAT IT IMAGINES', 'AS WELL AS YOU DO LOOK AT MY LONG GREEN BODY AND THESE ENDLESS LEGS AND THEN TALK TO ME ABOUT HAVING WINGS AND A PAINTED FEATHERY COAT FOOL AND FOOL YOU CRIED THE INDIGNANT LARK', 'MAN CONTINUES FOR EVER THUS LOSING OUR IDENTITY THAT OF WHICH WE ARE CHIEFLY CONSCIOUS WE GLORY IN THE CONTINUITY OF OUR SPECIES AND LEARN TO REGARD DEATH WITHOUT TERROR', 'GROGAN DO YOU REMEMBER WHO WAS IN THE BAR BETWEEN SEVEN THIRTY AND EIGHT THIRTY ON THE NIGHT OF THE FELDERSON MURDER ONLY ONE OR TWO OF THE GENTLEMEN SIR THERE WAS MISTER FARNSWORTH AND MISTER BROWN AND I THINK MISTER WOODS', 'HE WAS IN A BAD FIX ANOTHER FELLOW WAS CONTESTING HIS PATENT AND FIGHTING HARD TO HEAD HIM OFF IT WOULD TAKE A LOT OF MONEY TO FIGHT BACK THREE THOUSAND AT LEAST', \"I GUESS IT'S ALL UP I GUESS I KNEW IT WOULD BE SOME DAY MOYNE HADN'T ANYTHING TO DO WITH IT I STOLE THE MONEY MYSELF FROM THE BANK TO NIGHT I GUESS IT'S ALL UP\", \"SAID JANE AS SHE FINISHED IT IS IT NOT CLEAR ENOUGH DOES IT NOT EXPRESSLY DECLARE THAT CAROLINE NEITHER EXPECTS NOR WISHES ME TO BE HER SISTER THAT SHE IS PERFECTLY CONVINCED OF HER BROTHER'S INDIFFERENCE\", 'IN ITS FIGHT FOR DEMOCRACY THREE THOUSAND MILES AWAY THIS WAS TOO DREADFUL A FLURRY AT THE GATES OF THE CHIEF OF THE NATION AT SUCH A TIME WOULD NEVER DO OUR ALLIES IN THE CRUSADE FOR DEMOCRACY MUST NOT KNOW THAT WE HAD A DAY BY DAY UNREST AT HOME')\n",
      "--------------------------------------------------\n",
      "Exemple 2\n",
      "Audio shape: torch.Size([16, 16000])\n",
      "Texte: ('AND TILL HE HAD PATIENTLY WITH LONG CONTINUING AND DEEP AFFECTION WORKED HIS WAY INTO HER REGARD WAS SET ASIDE DURING THE PRESENT WALK HE WOULD SPEAK TO HER OF HIS PASSIONATE ATTACHMENT BEFORE HE LEFT FOR AN UNCERTAIN LENGTH OF TIME AND THE CERTAIN DISTANCE OF LONDON', 'AND HAD NOT EVEN THE AIR OF HEARING HIM WHEN MARIUS RAISED HIS VOICE TO SAY I KNOW HIM', 'WHICH WAS FIXED FOR MIDDAY HE CAST HIS EYES AROUND AND SEEING THAT THE STREET WAS EMPTY SAID TO HIS ADVERSARY MY FAITH IT IS FORTUNATE FOR YOU ALTHOUGH YOUR NAME IS BERNAJOUX TO HAVE ONLY TO DEAL WITH AN APPRENTICE MUSKETEER', 'AND HER ENTRANCE ACCORDINGLY GREETED WITH THE PROPER ROUND OF APPLAUSE SUCH IMPRESSIONS AS WE THUS NOTE FOR DENSHER COME AND GO IT MUST BE GRANTED IN VERY MUCH LESS TIME THAN NOTATION DEMANDS BUT WE MAY NONE THE LESS MAKE THE POINT THAT THERE WAS STILL FURTHER', 'GAVE GREAT OFFENCE TO THE REAL VENUS SHAKING HER AMBROSIAL LOCKS WITH INDIGNATION SHE EXCLAIMED AM I THEN TO BE ECLIPSED IN MY HONORS BY A MORTAL GIRL IN VAIN THEN DID THAT ROYAL SHEPHERD WHOSE JUDGMENT WAS APPROVED BY JOVE HIMSELF', 'THERE MUST HAVE BEEN MORE DANCING THROUGHOUT THE COUNTRY IN THOSE DAYS THAN THERE IS NOW', 'FAILURE IS OFTEN THE TURNING POINT THE PIVOT OF CIRCUMSTANCE THAT SWINGS US TO HIGHER LEVELS IT MAY NOT BE FINANCIAL SUCCESS IT MAY NOT BE FAME IT MAY BE NEW DRAUGHTS OF SPIRITUAL MORAL OR MENTAL INSPIRATION', 'TOWARD THE CENTER OF THE CITY WAS A LARGE PLAZA AND UPON THIS AND IN THE BUILDINGS IMMEDIATELY SURROUNDING IT WERE CAMPED SOME NINE OR TEN HUNDRED CREATURES OF THE SAME BREED AS MY CAPTORS', \"YOU SHOULD LEAVE HERE ABOUT SEVEN O'CLOCK THIS EVENING IT IS NOW SIX FIFTEEN MINUTES LATER THEY HAD EXAMINED THEIR ARMS AND EQUIPPED THEMSELVES WITH A FULL SUPPLY OF SMALL ARMS AMMUNITION PORTABLE WIRELESS INSTRUMENT AND ANTENNAE AND THREE RATIONS EACH OF EATING CHOCOLATE\", \"ANSWERED SAM PRODUCING HALF A DOLLAR AS IF SUCH MAGNIFICENT SUMS WERE NO STRANGERS TO HIS POCKET COME ON BROWN YOU'LL BE A FIRST RATE FELLOW TO SHOW US ROUND AS YOU KNOW ALL THE DODGES SAID BILLY\", 'THE FULL ACCOUNT OF WHICH MARGARET HAD NEVER HEARD AND WHICH NOW SEEMED DOOMED TO BE BURIED IN SAD OBLIVION', 'SO FAR AS EYE COULD REACH THE HOUSE TO THE RIGHT WAS A ROOF RATHER THAN A HOUSE NOTHING COULD BE MORE MEAN THE WALLS WERE OF MUD THE ROOF WAS OF STRAW AND THERE WAS MORE THATCH THAN WALL', 'WHILE EACH SIDE TOOK ACCOUNT OF STOCK AND MADE NECESSARY REPAIRS OR ALTERED THEIR PLANS TO MEET THE NEW SITUATION OUR YOUNG FRIENDS WERE BUSY WITH WASH BASIN SOAP AND WATER', \"AND AS HE HOBBLED ALONG SAID HE TO THE ESQUIRES WHAT A SAD MISFORTUNE IS THIS TO ONE OF MY BIRTH AND CHARACTER THE OTHER CHAMPIONS PLAY'D THEIR PARTS MUCH BETTER AND ALL CAME OFF WITH CREDIT\", 'THE ROOM WAS WHITEWASHED AS IS THE CUSTOM IN PRISONS BUT IT LOOKED QUITE BRILLIANT TO A PRISONER THOUGH A STOVE A BED A CHAIR AND A TABLE FORMED THE WHOLE OF ITS SUMPTUOUS FURNITURE', \"THEY UNTIED IT AND LED IT AWAY SOME OF THEM PUT THEIR CLOTHES ON THE DONKEY'S BACK FOR A KING MUST RIDE IN COMFORT OTHERS SPREAD THEIR CLOTHES OUT ON THE STREET FOR A KING SHOULD RIDE IN STATE\")\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, (audio, text) in enumerate(data_loader):\n",
    "    print(f\"Exemple {i+1}\")\n",
    "    print(f\"Audio shape: {audio.shape}\")\n",
    "    print(f\"Texte: {text}\")\n",
    "    print(\"-\" * 50)\n",
    "    if i == 1: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model dev ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model_W2V(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, d_model, num_layers, max_relative_position):\n",
    "\n",
    "        #EAB\n",
    "        self.batch_size = batch_size\n",
    "        #self.seq_length = seq_length\n",
    "        self.embed_size = embed_size\n",
    "        self.mask_prob = 0.50\n",
    "        self.mask_length = 10\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.forward_expansion = forward_expansion\n",
    "        self.kernel_size = kernel_size\n",
    "        self.groups = groups\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.num_codebooks = 2\n",
    "        self.num_codes = 320\n",
    "        \n",
    "        self.code_dim = 256\n",
    "        self.output_dim = 512\n",
    "        self.temperature= 0.05\n",
    "\n",
    "        self.max_relative_position = max_relative_position\n",
    "\n",
    "        super(Model_W2V, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.FeaturesEncoder = Features_encoder.FeatureEncoder(input_channels=1, feature_dim=512) #1501 ?\n",
    "        self.masking = wav2vec_transformer.MaskingWithLearnableEmbedding()\n",
    "        # d_model, num_heads, dropout, forward_expansion):\n",
    "\n",
    "        #embed_size, num_heads, dropout, forward_expansion,max_relative_position):\n",
    "        self.TranformerBlock = wav2vec_transformer.TransformerBlockW(self.embed_size, self.num_heads, self.dropout, self.forward_expansion, self.max_relative_position)   #(self.embed_size, self.num_heads, self.dropout, self.forward_expansion, self.kernel_size, self.groups, self.d_model, self.max_relative_position)\n",
    "        self.quantization = quantizationModule.QuantizationModule(\n",
    "            input_dim=512,  # Should match feature_dim from FeatureEncoder\n",
    "            codebook_size=self.num_codes,\n",
    "            num_codebooks=self.num_codebooks,\n",
    "            output_dim=self.output_dim,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "\n",
    "        # (K , k temp, G codevectorgroup, Vcodevectorpergroup, a 0,05)\n",
    "        \n",
    "        self.LossItem = ContrastiveLoss.Wav2vec2Loss(K=100,k=self.temperature, G=self.num_codebooks, V = self.num_codes, a=0.05)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "       # print(\"ORIGINAL , \", x.shape)\n",
    "        x = x.to(next(self.parameters()).device)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = self.FeaturesEncoder(x)\n",
    "        \n",
    "       #\n",
    "        \n",
    "        \n",
    "        # print(\"q\",x.shape)\n",
    "        \n",
    "        quantized_repr, diversity_loss = self.quantization(x)\n",
    "        \n",
    "        masked_reps, mask = self.masking(x, self.mask_prob, self.mask_length) #(self, x, mask_prob, mask_length)\n",
    "        \n",
    "        contextualized_reps = self.TranformerBlock(masked_reps, masked_reps, masked_reps, mask)\n",
    "                                                # value, key, query, mask=None\n",
    "        \n",
    "\n",
    "        #print(\"Debug\", contextualized_reps.shape, quantized_repr.shape, mask.shape)\n",
    "        \n",
    "        \n",
    "        # context_repr, quantized_repr, perplexity, time_mask_indices):\n",
    "\n",
    "        \n",
    "        loss = self.LossItem(contextualized_reps, quantized_repr, diversity_loss, mask)\n",
    "        \n",
    "        # print(\"Context Representation shape:\", contextualized_reps.shape)\n",
    "        # print(\"Quantized Representation shape:\", quantized_repr.shape)\n",
    "        # print(\"Mask Indices shape:\", masked_reps.shape)\n",
    "        # mask = torch.tensor(mask)\n",
    "        # print(\"Unique Mask Indices values:\", mask.unique())\n",
    "\n",
    "        \n",
    "   # embed_size, num_heads, dropout, forward_expansion, kernel_size, groups,d_model\n",
    "        \n",
    "        return x, contextualized_reps, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "loss_123 = []\n",
    "\n",
    "def train_model(model, dataset, epochs, learning_rate, device):\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=model.batch_size, shuffle=True)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        num_batches = len(dataloader) - 1\n",
    "\n",
    "        for batch_idx, (inputs, _) in enumerate(tqdm( data_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "            \n",
    "            if batch_idx >= num_batches:\n",
    "                print(\"break\")\n",
    "                break  # S'arrêter avant la dernière itération\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            _,_, loss = model(inputs)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{batch_idx+1}/{num_batches}], Loss: {loss.item():.4f}\")\n",
    "                loss_123.append(loss.item())\n",
    "                \n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return loss_123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 1/1784 [00:01<58:03,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/1783], Loss: 6.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   6%|▌         | 101/1784 [02:23<40:02,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [101/1783], Loss: 5.7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  11%|█▏        | 201/1784 [04:42<37:01,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [201/1783], Loss: 5.7110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  17%|█▋        | 301/1784 [07:05<35:07,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [301/1783], Loss: 5.7143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  22%|██▏       | 401/1784 [09:26<32:33,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [401/1783], Loss: 5.7120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  28%|██▊       | 501/1784 [11:48<29:17,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [501/1783], Loss: 5.7156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  34%|███▎      | 601/1784 [14:08<27:47,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [601/1783], Loss: 5.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  39%|███▉      | 701/1784 [16:26<25:14,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [701/1783], Loss: 5.7140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  45%|████▍     | 801/1784 [18:47<22:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [801/1783], Loss: 5.7119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  51%|█████     | 901/1784 [21:13<22:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [901/1783], Loss: 5.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  56%|█████▌    | 1001/1784 [23:34<18:42,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1001/1783], Loss: 5.7052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  62%|██████▏   | 1101/1784 [25:54<16:12,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1101/1783], Loss: 5.7144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  67%|██████▋   | 1201/1784 [28:14<13:16,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1201/1783], Loss: 5.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  73%|███████▎  | 1301/1784 [30:35<10:59,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1301/1783], Loss: 5.7112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  79%|███████▊  | 1401/1784 [32:56<09:08,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1401/1783], Loss: 5.7174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  84%|████████▍ | 1501/1784 [35:19<06:47,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1501/1783], Loss: 5.7085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  90%|████████▉ | 1601/1784 [37:41<04:15,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1601/1783], Loss: 5.7154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  93%|█████████▎| 1656/1784 [39:00<03:00,  1.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;66;03m#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m Model_W2V(embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, embed_size, num_layers, max_relative_position)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 20\u001b[0m loss_123 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# S'arrêter avant la dernière itération\u001b[39;00m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m _,_, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 68\u001b[0m, in \u001b[0;36mModel_W2V.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m  x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFeaturesEncoder(x)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     64\u001b[0m  \n\u001b[1;32m     65\u001b[0m  \n\u001b[1;32m     66\u001b[0m  \u001b[38;5;66;03m# print(\"q\",x.shape)\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m  quantized_repr, diversity_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m  masked_reps, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_prob, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_length) \u001b[38;5;66;03m#(self, x, mask_prob, mask_length)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m  contextualized_reps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTranformerBlock(masked_reps, masked_reps, masked_reps, mask)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/W2V/MLA_Wave2Vec/Modules/quantizationModule.py:43\u001b[0m, in \u001b[0;36mQuantizationModule.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     40\u001b[0m batch_size, num_tokens, feature_dim \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mshape  \u001b[38;5;66;03m# Ex: 8,49,512\u001b[39;00m\n\u001b[1;32m     41\u001b[0m z_flat \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mview(batch_size \u001b[38;5;241m*\u001b[39m num_tokens, feature_dim)\n\u001b[0;32m---> 43\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodebook_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_flat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Clustering K-means\u001b[39;00m\n\u001b[1;32m     44\u001b[0m codebook \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(kmeans\u001b[38;5;241m.\u001b[39mcluster_centers_, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(z\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Application du STE \u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1519\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[0;32m-> 1519\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1535\u001b[0m     inertia \u001b[38;5;241m<\u001b[39m best_inertia\n\u001b[1;32m   1536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[1;32m   1537\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:162\u001b[0m, in \u001b[0;36m_threadpool_controller_decorator.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m controller \u001b[38;5;241m=\u001b[39m _get_threadpool_controller()\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api):\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:757\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[0;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict_convergence:\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# rerun E-step so that predicted labels match cluster centers\u001b[39;00m\n\u001b[1;32m    745\u001b[0m     lloyd_iter(\n\u001b[1;32m    746\u001b[0m         X,\n\u001b[1;32m    747\u001b[0m         sample_weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    754\u001b[0m         update_centers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    755\u001b[0m     )\n\u001b[0;32m--> 757\u001b[0m inertia \u001b[38;5;241m=\u001b[39m \u001b[43m_inertia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels, inertia, centers, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "seq_length = 151\n",
    "embed_size = 512\n",
    "num_heads = 8\n",
    "dropout = 0.0\n",
    "forward_expansion = 1024\n",
    "kernel_size = 7\n",
    "groups = 2\n",
    "d_model = 512\n",
    "num_layers = 12\n",
    "\n",
    "max_relative_position=128\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "device = 'cuda'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model_W2V(embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, embed_size, num_layers, max_relative_position).to(device)\n",
    "\n",
    "\n",
    "loss_123 = train_model(model, dataset, epochs=1, learning_rate=5e-4, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '28dec_15epochs_train3'\n",
    "\n",
    "model_path = f\"./models/training-breakpoint/{name}.pth\"\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "name_loss = f'loss_{name}'\n",
    "array_path = f\"./models/training-breakpoint/{name_loss}.npy\"\n",
    "\n",
    "np.save(array_path, loss_123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb1940f2c20>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
