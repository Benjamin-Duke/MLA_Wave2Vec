{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from Modules import LoadingModule\n",
    "from Modules import Features_encoder\n",
    "from Modules import quantizationModule\n",
    "from Modules import wav2vec_transformer\n",
    "from Modules import ContrastiveLoss\n",
    "\n",
    "from Modules import TempLibriSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#data loader module init\\nStandardScalerTransform = LoadingModule.StandardScalerTransform\\nLargeDataModule = LoadingModule.LargeDataModule(\"./data/Librispeech\", batch_size=16, num_workers=1, transform=StandardScalerTransform)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "#data loader module init\n",
    "StandardScalerTransform = LoadingModule.StandardScalerTransform\n",
    "LargeDataModule = LoadingModule.LargeDataModule(\"./data/Librispeech\", batch_size=16, num_workers=1, transform=StandardScalerTransform)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temp import dataloader ### rendre compatible PLightning quand on aura le GPU\n",
    "# en attendant import manuel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "dataset = TempLibriSpeech.LibriSpeech(split=\"train-clean-100\", target_length=48000, device='cuda')\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 1\n",
      "Audio shape: torch.Size([8, 48000])\n",
      "Texte: ('ALL THIS CONSIDERED THERE IS A JUDGMENT OF HEAVEN UPON THIS NATION IF THESE DISTRACTIONS CONTINUE GOD SO DEAL WITH ME AND MINE AS ALL MY THOUGHTS AND INTENTIONS ARE UPRIGHT FOR THE MAINTENANCE OF THE TRUE PROTESTANT PROFESSION', 'AS ONE JAPANESE HAS WRITTEN OUR REFLECTION BROUGHT INTO PROMINENCE NOT SO MUCH THE MORAL AS THE NATIONAL CONSCIOUSNESS OF THE INDIVIDUAL TO US THE COUNTRY IS MORE THAN LAND AND SOIL FROM WHICH TO MINE GOLD OR REAP GRAIN', 'THEY HAD SUNSHINE RAIN HAIL SNOW AND A TORNADO AND THEN RAIN AGAIN AND MORE SUNSHINE SUNNY ITALY SEEMED A MISNOMER THAT DAY AS INDEED IT DOES MANY DAYS IN WINTER AND SPRING', 'BUT NO ONE WAS MORE DELIGHTED TO MEET ELSIE THAN HERBERT AND SHE WAS VERY GLAD TO LEARN THAT HIS HEALTH WAS GRADUALLY IMPROVING HE WAS NOT HOWEVER AT ALL STRONG EVEN YET AND HIS MOTHER THOUGHT IT BEST FOR HIM TO LIE DOWN AND REST A LITTLE AFTER HIS RIDE', 'EVEN SHOULD I BREAK ONE OF THEM WITH MY FIRST BLOW FOR I FIGURED THAT HE WOULD ATTEMPT TO WARD OFF THE CUDGEL HE COULD REACH OUT AND ANNIHILATE ME WITH THE OTHERS BEFORE I COULD RECOVER FOR A SECOND ATTACK', \"HE'S SEEN HIS SLICE OF LUCK HAS DICK AND YOU MAY LAY TO THAT BUT HERE THE LONG MAN WITH THE YELLOW EYES STRUCK IN\", 'FOR HER BY HIS PROMPT RECOGNITION OF HER RARITY BY PRECEDING HER IN A FRIENDLY SPIRIT AS HE HAD THE EAR OF SOCIETY WITH A SHARP FLASHLIGHT OR TWO HE MET POOR DENSHER THESE ENQUIRIES AS HE COULD', 'YOU MUST HAVE THOUGHT ME SO RUDE BUT INDEED IT WAS NOT MY OWN FAULT WAS IT MISSUS ALLEN DID NOT THEY TELL ME THAT MISTER TILNEY AND HIS SISTER WERE GONE OUT IN A PHAETON TOGETHER AND THEN WHAT COULD I DO BUT I HAD TEN THOUSAND TIMES RATHER HAVE BEEN WITH YOU')\n",
      "--------------------------------------------------\n",
      "Exemple 2\n",
      "Audio shape: torch.Size([8, 48000])\n",
      "Texte: ('HAD CAPTURED THE WHOLE FIELD THE FIRST PROPAGANDISTS THEN DID NOT STAND UP TO THE OFFICIAL PRESS AS EQUALS THEY CREPT IN AS INFERIORS OR RATHER AS OPEN EX CENTRICS', 'AND ON A SPECIAL AND MYSTERIOUS CONNECTION BETWEEN THE MENSTRUATING WOMAN AND THE OCCULT FORCES OF MAGIC TEND TO DIE OUT THE SEPARATION OF THE SEXES THEY INVOLVE BECOMES UNNECESSARY LIVING IN GREATER COMMUNITY WITH MEN', 'AND CHRISTIANITY BUT HE WAS NOT SATISFIED WITH EITHER OF THEM', 'HE WAS SATISFIED THAT THIS UNWIELDY CONTRIVANCE WOULD SUPPORT HIM IN THE WATER AMONG OTHER THINGS HE HAD FOUND IN HIS RUMMAGINGS ABOUT THE HOLD WAS AN OLD KNIFE AND WITH THIS IN HIS HAND HE NOW SAT WAITING FOR A GOOD OPPORTUNITY TO ATTACK HIS SENTINEL', 'BISCUITS WITH SUGAR ON THE TOP PRESERVED GINGER HAMS BRAWN UNDER GLASS EVERYTHING IN FACT THAT MAKES LIFE WORTH LIVING', 'IS IT THAT YOU ARE AFRAID OF TEARING A HOLE IN YOUR RAGS WORTHLESS VAGABOND IN THE STREETS AT THIS HOUR WHO ARE YOU ANSWER BUT NO I FORBID YOU TO ANSWER THERE YOU ARE COLD', 'THERE WAS MISSUS FISHER UP BY THE TINY WINDOW BENDING OVER AN OLD WOMAN WHO HAD SPREAD OUT IN HER LAP SOME WHITE EMBROIDERED GARMENTS WHILE A YOUNG WOMAN HOVERED NEAR SMILING AND BLUSHING AND VERY HAPPY AT ALL THIS NOTICE', 'A WOMAN BEAUTIFUL AWESOME INCREDIBLE SHE WAS TALL STANDING THERE SWATHED FROM CHIN TO FEET IN CLINGING VEILS OF PALE AMBER SHE SEEMED TALLER EVEN THAN TALL DRAKE')\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, (audio, text) in enumerate(data_loader):\n",
    "    print(f\"Exemple {i+1}\")\n",
    "    print(f\"Audio shape: {audio.shape}\")\n",
    "    print(f\"Texte: {text}\")\n",
    "    print(\"-\" * 50)\n",
    "    if i == 1: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model dev ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model_W2V(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, d_model, num_layers, max_relative_position):\n",
    "\n",
    "        #EAB\n",
    "        self.batch_size = batch_size\n",
    "        #self.seq_length = seq_length\n",
    "        self.embed_size = embed_size\n",
    "        self.mask_prob = 0.00\n",
    "        self.mask_length = 1\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.forward_expansion = forward_expansion\n",
    "        self.kernel_size = kernel_size\n",
    "        self.groups = groups\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.num_codebooks = 2\n",
    "        self.num_codes = 320\n",
    "        \n",
    "        self.code_dim = 256\n",
    "        self.output_dim = 512\n",
    "        self.temperature= 0.07\n",
    "\n",
    "        self.max_relative_position = max_relative_position\n",
    "\n",
    "        super(Model_W2V, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.FeaturesEncoder = Features_encoder.FeatureEncoder(input_channels=1, feature_dim=512) #1501 ?\n",
    "        self.masking = wav2vec_transformer.MaskingWithLearnableEmbedding()\n",
    "        # d_model, num_heads, dropout, forward_expansion):\n",
    "        self.TranformerBlock = wav2vec_transformer.TransformerBlockW(self.d_model, self.num_heads, self.dropout, self.forward_expansion)   #(self.embed_size, self.num_heads, self.dropout, self.forward_expansion, self.kernel_size, self.groups, self.d_model, self.max_relative_position)\n",
    "        self.quantization = quantizationModule.QuantizationModule(self.num_codebooks, self.num_codes, self.code_dim, self.output_dim, self.temperature)\n",
    "        self.LossItem = ContrastiveLoss.LossW2V(20)\n",
    "#embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, d_model):\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "       # print(\"ORIGINAL , \", x.shape)\n",
    "        x = x.to(next(self.parameters()).device)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = self.FeaturesEncoder(x)\n",
    "        \n",
    "       #\n",
    "        \n",
    "        \n",
    "      #  print(\"q\",x.shape)\n",
    "        \n",
    "        quantized_repr = self.quantization(x)\n",
    "\n",
    "        masked_reps, mask = self.masking(x, self.mask_prob, self.mask_length) #(self, x, mask_prob, mask_length)\n",
    "\n",
    "        contextualized_reps = self.TranformerBlock(masked_reps, masked_reps, masked_reps, mask)\n",
    "                                                # value, key, query, mask=None\n",
    "    \n",
    "\n",
    "        #print(\"Debug\", contextualized_reps.shape, quantized_repr.shape, mask.shape)\n",
    "        loss = self.LossItem.compute_loss(contextualized_reps, quantized_repr, mask, self.batch_size)\n",
    "        \n",
    "   # embed_size, num_heads, dropout, forward_expansion, kernel_size, groups,d_model\n",
    "        \n",
    "        return x, contextualized_reps, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, dataset, epochs, learning_rate, device):\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=model.batch_size, shuffle=True)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        num_batches = len(dataloader) - 1\n",
    "\n",
    "        for batch_idx, (inputs, _) in enumerate(tqdm( data_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "            if batch_idx >= num_batches:\n",
    "                break  # S'arrêter avant la dernière itération\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            _,_, loss = model(inputs)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{batch_idx+1}/{num_batches}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/250:   0%|          | 0/1784 [00:00<?, ?it/s]/home/jessy/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Error detected in MulBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_7660/727632579.py\", line 20, in <module>\n",
      "    train_model(model, dataset, epochs=250, learning_rate=1e-5, device=device)\n",
      "  File \"/tmp/ipykernel_7660/2874262722.py\", line 26, in train_model\n",
      "    _,_, loss = model(inputs)\n",
      "  File \"/home/jessy/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/jessy/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_7660/3812239861.py\", line 64, in forward\n",
      "    loss = self.LossItem.compute_loss(contextualized_reps, quantized_repr, mask, self.batch_size)\n",
      "  File \"/home/jessy/W2V/MLA_Wave2Vec/Modules/ContrastiveLoss.py\", line 80, in compute_loss\n",
      "    diversity = self.diversity_loss(quantized_repr, batch_size)\n",
      "  File \"/home/jessy/W2V/MLA_Wave2Vec/Modules/ContrastiveLoss.py\", line 63, in diversity_loss\n",
      "    similarity_matrix = F.cosine_similarity(\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:110.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Epoch 1/250:   0%|          | 0/1784 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 11.13 GiB. GPU 0 has a total capacity of 47.43 GiB of which 324.31 MiB is free. Including non-PyTorch memory, this process has 0 bytes memory in use. Of the allocated memory 35.60 GiB is allocated by PyTorch, and 11.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;66;03m#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m Model_W2V(embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, d_model, num_layers, max_relative_position)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     26\u001b[0m _,_, loss \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 11.13 GiB. GPU 0 has a total capacity of 47.43 GiB of which 324.31 MiB is free. Including non-PyTorch memory, this process has 0 bytes memory in use. Of the allocated memory 35.60 GiB is allocated by PyTorch, and 11.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "seq_length = 151\n",
    "embed_size = 512\n",
    "num_heads = 8\n",
    "dropout = 0.1\n",
    "forward_expansion = 4\n",
    "kernel_size = 7\n",
    "groups = 2\n",
    "d_model = 512\n",
    "num_layers = 12\n",
    "\n",
    "max_relative_position=128\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "device = 'cuda'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model_W2V(embed_size, num_heads, dropout, forward_expansion, kernel_size, groups, d_model, num_layers, max_relative_position).to(device)\n",
    "\n",
    "\n",
    "train_model(model, dataset, epochs=250, learning_rate=1e-5, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Créez un DataLoader pour le jeu de données de test\n",
    "dataset = TempLibriSpeech.LibriSpeech(split=\"test-clean\", target_length=480000, device='cuda')\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "all_quantized_reps = []\n",
    "all_contextualized_reps = []\n",
    "\n",
    "# Calcul de la perte de reconstruction ou de quantification\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        inputs, _ = batch  # Ici, _ signifie qu'il n'y a pas de labels\n",
    "        \n",
    "        inputs = inputs.to('cuda')  # Assurez-vous que les inputs sont sur le bon device\n",
    "\n",
    "        # Passe avant\n",
    "        quantized_repr, contextualized_reps, loss = model(inputs)\n",
    "\n",
    "        # Ajout des représentations à la liste\n",
    "        all_quantized_reps.append(quantized_repr.cpu().numpy())\n",
    "        all_contextualized_reps.append(contextualized_reps.cpu().numpy())\n",
    "\n",
    "        # Accumuler la perte\n",
    "        total_loss += loss.item()\n",
    "\n",
    "# Calcul de la moyenne de la perte sur l'ensemble du dataset\n",
    "average_loss = total_loss / len(data_loader)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Average Loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_loss = total_loss / len(data_loader)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Average Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
