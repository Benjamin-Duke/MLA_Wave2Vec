{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from Modules import LoadingModule\n",
    "from Modules import Features_encoder\n",
    "from Modules import quantizationModule\n",
    "from Modules import wav2vec_transformer\n",
    "from Modules import ContrastiveLoss\n",
    "\n",
    "from Modules import TempLibriSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch_lightning in /home/jessy/.local/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: torch>=2.1.0 in /home/jessy/.local/lib/python3.10/site-packages (from pytorch_lightning) (2.5.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/jessy/.local/lib/python3.10/site-packages (from pytorch_lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.9.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/jessy/.local/lib/python3.10/site-packages (from pytorch_lightning) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/jessy/.local/lib/python3.10/site-packages (from pytorch_lightning) (0.11.9)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/jessy/.local/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.11.7)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (59.6.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.6.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jessy/.local/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/jessy/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jessy/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/jessy/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jessy/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jessy/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jessy/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jessy/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helloworld\n"
     ]
    }
   ],
   "source": [
    "print(\"helloworld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader module init\n",
    "StandardScalerTransform = LoadingModule.StandardScalerTransform\n",
    "LargeDataModule = LoadingModule.LargeDataModule(\"./data/Librispeech\", batch_size=16, num_workers=1, transform=StandardScalerTransform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temp import dataloader ### rendre compatible PLightning quand on aura le GPU\n",
    "# en attendant import manuel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "dataset = TempLibriSpeech.LibriSpeech(split=\"test-clean\", target_length=48000, device='cpu')\n",
    "dataset = TempLibriSpeech.LibriSpeech(split=\"train-clean-100\", target_length=480000, device='cuda')\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 1\n",
      "Audio shape: torch.Size([16, 48000])\n",
      "Texte: ('AND ONE MORE THIS MORNING', 'IN THE NATURE OF THINGS LUXURIES AND THE COMFORTS OF LIFE BELONG TO THE LEISURE CLASS', 'THE ORCHARD WAS SPARKLING AND RIPPLING IN THE SUN', 'THE STRONG POSITION HELD BY THE EDISON SYSTEM UNDER THE STRENUOUS COMPETITION THAT WAS ALREADY SPRINGING UP WAS ENORMOUSLY IMPROVED BY THE INTRODUCTION OF THE THREE WIRE SYSTEM AND IT GAVE AN IMMEDIATE IMPETUS TO INCANDESCENT LIGHTING', 'SO THERE CAME A STEP AND A LITTLE RUSTLING OF FEMININE DRAPERIES THE SMALL DOOR OPENED AND RACHEL ENTERED WITH HER HAND EXTENDED AND A PALE SMILE OF WELCOME', 'THE EUROPE THEY HAD COME FROM LAY OUT THERE BEYOND THE IRISH SEA EUROPE OF STRANGE TONGUES AND VALLEYED AND WOODBEGIRT AND CITADELLED AND OF ENTRENCHED AND MARSHALLED RACES', 'COME AND GET THE BOOLOOROO SHE SAID GOING TOWARD THE BENCHES', 'THEIR MASTERS SAID MISSUS NEVERBEND', 'PEARL SEEING THE ROSE BUSHES BEGAN TO CRY FOR A RED ROSE AND WOULD NOT BE PACIFIED', 'THIS HAS INDEED BEEN A HARASSING DAY CONTINUED THE YOUNG MAN HIS EYES FIXED UPON HIS FRIEND', 'FOR SOME TIME AFTER THAT I REMEMBERED NOTHING DISTINCTLY', 'HARANGUE THE TIRESOME PRODUCT OF A TIRELESS TONGUE', 'BE IT SAID TO THE HONOR OF SOME OF THE OFFICERS ENTRUSTED WITH THE TERRIBLE COMMISSION THAT WHEN THEY LEARNED ITS TRUE SIGNIFICANCE THEY RESIGNED THEIR AUTHORITY RATHER THAN HAVE ANYTHING TO DO WITH WHAT THEY DESIGNATED A COLD BLOODED BUTCHERY', 'YOU WILL CARRY OUT WITH YOU ONE HUNDRED MEN OF THE NORTH NORTH WEST BIRMINGHAM REGIMENT WHICH WILL PROBABLY SUFFICE FOR YOUR OWN SECURITY AS IT IS THOUGHT THAT IF MISTER NEVERBEND BE WITHDRAWN THE PEOPLE WILL REVERT EASILY TO THEIR OLD HABITS OF OBEDIENCE', 'A LITTLE ATTACK OF NERVES POSSIBLY', 'ROBIN ENTERED THE HUT DRAGGING THE UNWILLING ESQUIRE AFTER HIM')\n",
      "--------------------------------------------------\n",
      "Exemple 2\n",
      "Audio shape: torch.Size([16, 48000])\n",
      "Texte: ('SHE SENT ME THE PAGES IN QUESTION BEFORE SHE DIED', 'ITS CURTAINS WERE OF THICK AND FADED TAPESTRY', 'THAT IS TRUE BADAUDERIE', \"THERE BEFELL AN ANXIOUS INTERVIEW MISTRESS FITZOOTH ARGUING FOR AND AGAINST THE SQUIRE'S PROJECT IN A BREATH\", 'SUDDENLY THE ICHTHYOSAURUS AND THE PLESIOSAURUS DISAPPEAR BELOW LEAVING A WHIRLPOOL EDDYING IN THE WATER', 'RUTH ASKED THE ENTHUSIASTS IF THEY WOULD LIKE TO LIVE IN SUCH A SOUNDING MAUSOLEUM WITH ITS GREAT HALLS AND ECHOING ROOMS AND NO COMFORTABLE PLACE IN IT FOR THE ACCOMMODATION OF ANY BODY', 'THE YOUNG GIRLS HAD INDEED MADE THEMSELVES SMALL INDEED INVISIBLE', \"THERE WAS NO CHANCE TO ALTER HIS SLEEPING ROOM TO ONE NEARER TO GAMEWELL'S CHAMBER\", 'YES IT IS SUPPRESSED', 'HE WOULD BE LIKE A PHILOLOGIST REFUSING TO EXAMINE A FACT IN LANGUAGE A PHILOSOPHER HESITATING TO SCRUTINIZE A FACT IN HUMANITY', 'THE HAWK ALIGHTED ON THE DEAD BRANCH AND SAT UPRIGHT MOTIONLESS AS IF SURPRISED', 'BUT THEL IS LIKE A FAINT CLOUD KINDLED AT THE RISING SUN I VANISH FROM MY PEARLY THRONE AND WHO SHALL FIND MY PLACE', 'ON THE SIXTH OF APRIL EIGHTEEN THIRTY THE CHURCH OF JESUS CHRIST OF LATTER DAY SAINTS WAS FORMALLY ORGANIZED AND THUS TOOK ON A LEGAL EXISTENCE', 'LADY LARKSPUR STARTS SUDDENLY AND TURNS TOWARDS HIM', 'HUSBAND THE NEXT THING TO A WIFE', 'FOR ONCE IN A WAY I PROVED A TRUE PROPHET')\n",
      "Audio shape: torch.Size([16, 480000])\n",
      "Texte: ('HERE HE NOTICED A LITTLE MOUSE CREEPING WEARILY ALONG ON ITS HIND PAWS FOR ITS FRONT PAWS HAD BOTH BEEN BROKEN IN A TRAP FERKO FELT SO SORRY FOR THE LITTLE BEAST', 'AND HERE SHE SAT NOW KNITTING AND THE TABLE BEHIND HER WAS LAID FOR SUPPER MISSUS RACHEL BEFORE SHE HAD FAIRLY CLOSED THE DOOR', 'PERHAPS I THOUGHT QUICKLY THIS WAS WITH HER A SIGN OF GREETING I LIFTED MY OWN ARM AND RETURNED THE SALUTATION IF SALUTATION IT WERE AWARE OF A STRANGE RISING AND FALLING SOUND AS OF A DISTANT HUMMING IN MY EARS', 'ARE NOT COEFFICIENTS WITH WHICH EXPERIENCES COME TO US ABORIGINALLY STAMPED BUT ARE RATHER RESULTS OF A LATER CLASSIFICATION PERFORMED BY US FOR PARTICULAR NEEDS', 'WHILE HER FACE BORE PITEOUS TRACES OF THE LIFE EXPERIENCE CONCENTRATED IN THE TWENTY FOUR HOURS THAT NEW TERRIBLE LIFE LYING ON THE OTHER SIDE OF THE DEED WHICH FULFILLS A CRIMINAL DESIRE I WILL BEAR ANY PENANCE', 'WE MUST GET HIM OUT AT ONCE DECLARED MISTER JENKS I KNEW SOMETHING WOULD HAPPEN ON THIS VOYAGE CAME FROM MISTER PARKER I PREDICTED IT FROM THE FIRST TOM THOUGHT CONSIDERABLE', 'NOTHING CAN REPAIR THE INJURY IF YOU ONCE SUFFER IT TO COME UPON HIM HE WILL BE A BY WORD AMIDST MEN THROUGHOUT HIS LIFE YOU HAD BETTER HAVE WRITTEN TO THE LAW LORDS TO URGE ON THE DIVORCE HE RETURNED I CANNOT HELP THE DELAY', \"REALLY I DON'T KNOW PERHAPS BECAUSE I'M TOO UNIMPORTANT YES THAT MUST BE IT HE BEGAN TO FEEL A LITTLE BRIGHTER OBVIOUSLY THAT'S IT HE CARESSED A WHISKER WITH ONE OF HIS PAWS\", 'THE STANDARD OF THE SCHOOL WILL BE LOWERED THEREFORE I INTEND TO SIFT THIS MATTER TO THE BOTTOM AND FIND OUT WHAT MISCHIEVOUS INFLUENCE PROMPTED THIS ACT OF INSUBORDINATION REPORT SAYS THAT THIS MOVEMENT ORIGINATED IN THE JUNIOR CLASS', 'HE HAD NOT AS YET KNOWN ANY COMFORT AND WAS STILL FIRM IN HIS PURPOSE OF SELLING THE FARM HE HAD BEEN OUT HUNTING ONCE OR TWICE BUT FANCIED THAT PEOPLE LOOKED AT HIM WITH PECULIAR EYES', \"MANLY STRENGTH AND GRACE SHOWING IN EVERY LINE THE ROAD WAS NARROW AGAINST THE HILLSIDE AND HE HAD TO RIDE QUITE CLOSE SO I SAW HIS HANDSOME FACE PLAINLY AS SOON AS HE SAW ELIZABETH HE SPRANG FROM HIS SADDLE AND SAID LIZ'BETH LIZ'BETH\", 'FRUIT SHOOK OFF THE BRANCHES OF THE TREE IT GROWS UPON BY THE MOTION OF THE WATER AS THOSE IN OUR GARDENS ARE BY THAT OF THE WIND THE LOBSTER TREES APPEARED THE RICHEST BUT THE CRAB AND OYSTERS WERE THE TALLEST', 'HUMAN BEINGS AND WHAT THEY WANT AND DO', \"I DON'T THINK ANYTHING TAKES THE PLACE OF THE FARM WHERE ONE LIVED WHEN ONE WAS A CHILD OBSERVED REBECCA NEARLY BURSTING WITH PRIDE AT HAVING AT LAST SUCCESSFULLY USED THE INDEFINITE PRONOUN IN GENERAL CONVERSATION\", 'OFFERED HIM HIS ASSISTANCE AND INFORMED HIM THAT THE QUEEN WAS SAFE IN HIS CASTLE BUT COULD ONLY BE RESCUED BY ENCOUNTERING MALEAGANS LAUNCELOT DEMANDED THE BATTLE FOR THE NEXT DAY AND ACCORDINGLY IT TOOK PLACE AT THE FOOT OF THE TOWER', 'THE MORE EXCITED THEY BECAME SEEMS LIKE SOMETHIN ORTER BE DONE SAID MISTER HOBBS THINGS LIKE THEM ORTER BE HELD ON TO EARLS OR NO EARLS BUT THERE REALLY WAS NOTHING THEY COULD DO')\n",
      "--------------------------------------------------\n",
      "Exemple 2\n",
      "Audio shape: torch.Size([16, 480000])\n",
      "Texte: (\"AND WITH A LOW STARTLED CRY STARED ACROSS THE ROOM JIMMIE DALE WAS LEANING BACK AGAINST THE DOOR THAT WAS CLOSED NOW BEHIND HIM AND ON JIMMIE DALE'S FACE WAS A BLACK SILK MASK\", 'WHEN I HAD DONE SO HE MADE ME PUT THEM INTO MY LAP AND TOOK MY LITTLE DRAWER', 'AND IF BY LEASE OF STRENGTH THEY PASS ON TOWARD AN AGE OF FOUR YEARS IT IS BUT AN EVIDENCE OF THEIR EXCEPTIONAL VITALITY IT SEEMS TO BE TRUE THAT THE EXPERIENCES OF A LONG LIFE OF SIXTY OR EIGHTY YEARS IS CROWDED INTO A NARROW COMPASS OF FOUR YEARS', 'WENT OFF IMMEDIATELY TO CALL ON CHOKICHI AND SAID TO HIM OH MASTER CHOKICHI SUCH A TERRIBLE THING HAS HAPPENED PRAY LET ME TELL YOU ALL ABOUT IT INDEED WHAT CAN IT BE OH SIR ANSWERED KIHACHI', 'ADMINISTRATIVE AND JUDICIAL ORGANIZATION THE UNITY AND COMPLETENESS OF INSTRUCTION MARRIAGE THE FAMILY HEREDITY IN DIRECT AND COLLATERAL SUCCESSION THE RIGHT OF SALE AND EXCHANGE THE RIGHT TO MAKE A WILL AND EVEN BIRTHRIGHT', \"HERE HE TURNED AND EMBRACED HIS DAUGHTER AGAIN AND IF HIS EYE TRAVELLED OVER HER SHOULDER IN THE DIRECTION OF BELVANE'S GARDEN IT IS A SMALL MATTER AND ONE FOR WHICH THE ARCHITECT OF THE CASTLE NO DOUBT WAS PRINCIPALLY TO BLAME\", 'HE EVOLVED FROM ITS MORE INTIMATE DOMAIN EFFECTS IN SYMPATHY WITH THOSE OF THE ORCHESTRA YET PURELY INDIVIDUAL HE ENRICHED IT WITH NEW MELODIC HARMONIC AND RHYTHMIC DEVICES ADAPTED TO ITSELF ALONE', 'HIS MEN LAUGHED AND ONE CALLED TO ANOTHER AND SAID AND YOU THOUGHT OF FROST GIANTS THEN THEY SAILED ON FOR DAYS AND DAYS THEY MET MANY OF THESE ICEBERGS ON ONE OF THEM WAS A WHITE BEAR', 'HAD TURNED AND DANCED ABOUT ENOUGH THEY ORDERED THEIR SERVANTS TO BEAT HIM WITH STICKS TO CHANGE THE COURSE OF HIS IDEAS OTHERS HIT THE LION THAT IS THEY GAILY STOPPED A PASSENGER', \"I WISH I COULD TRULY SAY INHUMAN BUT CONVERSELY ANTS ARE ABSOLUTELY UNSELFISH WITHIN THE COMMUNITY THEY ARE SKILFUL INGENIOUS THEIR NESTS AND BUILDINGS ARE RELATIVELY LARGER THAN MAN'S\", 'EVEN NOW JEREMIAH WAS ASHAMED OF THEIR WANT OF CONFIDENCE IN ONE SO GOOD HE BELIEVED THAT THE INFORMATION THEY HAD RECEIVED WOULD ALL PROVE A MISTAKE FOUNDED ON ERRONEOUS GROUNDS IF NOT A PURE INVENTION OF AN ENEMY', 'THE KING ROSE IN HIS STIRRUPS AND MADE A LOW OBEISANCE TO THE WINDOW WHERE THEY WERE STANDING WE SHALL HAVE SOME COURT BEAUTIES BEVERLEY SAID THE KING LOOKING AT HIM OVER HIS SHOULDER AS SOON AS THE CEREMONIES WERE OVER', 'AH I HAD EIGHTY LOUIS BEFORE ME PUT DOWN THE SAME SUM SO THAT THEY WHO HAVE LOST MAY HAVE NOTHING TO COMPLAIN OF JUSTICE BEFORE EVERYTHING', 'LEFT HIS MINNOW BUCKET WHERE IT WAS MOUNTED HIS HORSE AND RODE UP THE PATH ABOUT HIM THE BEECH LEAVES GAVE BACK THE GOLD OF THE AUTUMN SUNLIGHT AND A LITTLE RAVINE HIGH UNDER THE CREST OF THE MOTTLED MOUNTAIN WAS ON FIRE WITH THE SCARLET OF MAPLE', \"KEPT FROM MYSELF DURING THIS INTERVAL THE MATTER IS OFTEN SUBSERVIENT TO THE MANNER ARTHUR'S FEELINGS WERE PLAYED UPON ALSO HE WEPT OFTEN CONFIDING TO ME HIS GRIEF AND HIS PLANS FOR THE FUTURE\", 'WERE THRONGED WITH PEOPLE OUT UPON THEIR SUNDAY PLEASURE BUT THE COLONEL WAS MUCH TOO BUSY TO TAKE ANY HEED OF THESE PHENOMENA AND ARRIVING AT KNIGHTSBRIDGE')\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, (audio, text) in enumerate(data_loader):\n",
    "    print(f\"Exemple {i+1}\")\n",
    "    print(f\"Audio shape: {audio.shape}\")\n",
    "    print(f\"Texte: {text}\")\n",
    "    print(\"-\" * 50)\n",
    "    if i == 1: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model dev ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model_W2V(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        #EAB\n",
    "        self.batch_size = 16\n",
    "        seq_length = 49 # In the paper the output of the encoder block has a frequency of 49Hz, we are assuming that each input is a 1s input \n",
    "        embed_size = 512\n",
    "        self.mask_prob = 0.15\n",
    "        self.mask_length = 512\n",
    "        num_heads = 8\n",
    "        dropout = 0.1\n",
    "        forward_expansion = 4\n",
    "        kernel_size = 31\n",
    "        groups = 16\n",
    "\n",
    "        #self.latent_reps = torch.rand(self.batch_size, seq_length, embed_size)\n",
    "        \n",
    "\n",
    "        super(Model_W2V, self).__init__()\n",
    "\n",
    "        self.FeaturesEncoder = Features_encoder.FeatureEncoder(input_channels=1, feature_dim=512)\n",
    "\n",
    "        self.masking = wav2vec_transformer.MaskingWithLearnableEmbedding(embed_size)\n",
    "        \n",
    "        self.TranformerBlock = wav2vec_transformer.TransformerBlockW(embed_size, num_heads, dropout, forward_expansion, kernel_size, groups)\n",
    "                                                                    # embed_size, num_heads, dropout, forward_expansion, kernel_size, groups\n",
    "        self.quantization = quantizationModule.QuantizationModule(num_codebooks=2, num_codes=320, code_dim=256, output_dim=512, temperature=1.0)\n",
    "\n",
    "        self.quantization = quantizationModule.QuantizationModule(num_codebooks=2, num_codes=256)\n",
    "\n",
    "        self.LossItem = ContrastiveLoss.LossW2V(1)\n",
    "        self.LossItem = ContrastiveLoss.LossW2V(1500)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(next(self.parameters()).device)\n",
    "\n",
    "        \n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        #print(x.shape)\n",
    "        x = self.FeaturesEncoder(x)\n",
    "        #print(x.shape)\n",
    "        quantized_repr = self.quantization(x)\n",
    "\n",
    "        masked_reps, mask, mask_indices = self.masking(x, self.mask_prob, self.mask_length)\n",
    "        contextualized_reps = self.TranformerBlock(masked_reps, masked_reps, masked_reps, mask_indices)\n",
    "                                                # value, key, query, mask=None\n",
    "\n",
    "\n",
    "        #print(\"Debug\", contextualized_reps.shape, quantized_repr.shape, mask.shape)\n",
    "        loss = self.LossItem.compute_loss(contextualized_reps, quantized_repr, mask_indices, self.batch_size)\n",
    "\n",
    "        \n",
    "        return x, contextualized_reps, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, dataset, epochs, learning_rate, device):\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=model.batch_size, shuffle=True)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        num_batches = len(dataloader) - 1\n",
    "\n",
    "        for batch_idx, (inputs, _) in enumerate(tqdm( data_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "            if batch_idx >= num_batches:\n",
    "                break  # S'arrêter avant la dernière itération\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            _,_, loss = model(inputs)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{batch_idx+1}/{num_batches}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessy/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Epoch 1/1:   0%|          | 0/164 [00:00<?, ?it/s]"
      "Epoch 1/50:   0%|          | 0/1784 [00:00<?, ?it/s]"

     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 48000])\n",
      "torch.Size([16, 4801, 512])\n",
      "torch.Size([16, 601, 512])\n"

      "torch.Size([16, 96001, 512])\n",
      "torch.Size([16, 48001, 512])\n",
      "torch.Size([16, 24001, 512])\n",
      "torch.Size([16, 12001, 512])\n",
      "torch.Size([16, 6001, 512])\n",
      "torch.Size([16, 3001, 512])\n",
      "End torch.Size([16, 1501, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/164 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 151, 512])\n",
      "torch.Size([16, 151, 512])\n",
      "la 2 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (512) must match the existing size (64) at non-singleton dimension 1.  Target sizes: [10, 512].  Tensor sizes: [64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Model_W2V()\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m inputs, _ \u001b[38;5;241m=\u001b[39m batch \n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m _, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m, in \u001b[0;36mModel_W2V.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     40\u001b[0m quantized_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantization(x)\n\u001b[0;32m---> 42\u001b[0m masked_reps, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m contextualized_reps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTranformerBlock(masked_reps, masked_reps, masked_reps, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLossItem\u001b[38;5;241m.\u001b[39mcompute_loss(contextualized_reps, quantized_repr, mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/W2V/MLA_Wave2Vec/Modules/wav2vec_transformer.py:35\u001b[0m, in \u001b[0;36mMaskingWithLearnableEmbedding.forward\u001b[0;34m(self, latent_reps, mask_prob, mask_length)\u001b[0m\n\u001b[1;32m     33\u001b[0m         start \u001b[38;5;241m=\u001b[39m idx\n\u001b[1;32m     34\u001b[0m         end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m+\u001b[39m mask_length, seq_length)\n\u001b[0;32m---> 35\u001b[0m         \u001b[43mmasked_reps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_embedding\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m masked_reps, mask\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (512) must match the existing size (64) at non-singleton dimension 1.  Target sizes: [10, 512].  Tensor sizes: [64]"
=======
      "Epoch 1/50:   0%|          | 1/1784 [00:03<1:35:12,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/1783], Loss: 176125.2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;66;03m#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Model_W2V()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     18\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm( data_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches:\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# S'arrêter avant la dernière itération\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/W2V/MLA_Wave2Vec/Modules/TempLibriSpeech.py:18\u001b[0m, in \u001b[0;36mLibriSpeech.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m---> 18\u001b[0m     audio, sample_rate, text, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sample_rate \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m16000\u001b[39m\n\u001b[1;32m     20\u001b[0m     audio \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchaudio/datasets/librispeech.py:170\u001b[0m, in \u001b[0;36mLIBRISPEECH.__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the n-th sample from the dataset.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m        Utterance ID\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_metadata(n)\n\u001b[0;32m--> 170\u001b[0m waveform \u001b[38;5;241m=\u001b[39m \u001b[43m_load_waveform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_archive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (waveform,) \u001b[38;5;241m+\u001b[39m metadata[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchaudio/datasets/utils.py:51\u001b[0m, in \u001b[0;36m_load_waveform\u001b[0;34m(root, filename, exp_sample_rate)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_waveform\u001b[39m(\n\u001b[1;32m     46\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     47\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     48\u001b[0m     exp_sample_rate: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     49\u001b[0m ):\n\u001b[1;32m     50\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, filename)\n\u001b[0;32m---> 51\u001b[0m     waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exp_sample_rate \u001b[38;5;241m!=\u001b[39m sample_rate:\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample rate should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_sample_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchaudio/_backend/utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchaudio/_backend/soundfile.py:27\u001b[0m, in \u001b[0;36mSoundfileBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     19\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m,\n\u001b[1;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundfile_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchaudio/_backend/soundfile_backend.py:230\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    227\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m _SUBTYPE2DTYPE[file_\u001b[38;5;241m.\u001b[39msubtype]\n\u001b[1;32m    229\u001b[0m     frames \u001b[38;5;241m=\u001b[39m file_\u001b[38;5;241m.\u001b[39m_prepare_read(frame_offset, \u001b[38;5;28;01mNone\u001b[39;00m, num_frames)\n\u001b[0;32m--> 230\u001b[0m     waveform \u001b[38;5;241m=\u001b[39m \u001b[43mfile_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     sample_rate \u001b[38;5;241m=\u001b[39m file_\u001b[38;5;241m.\u001b[39msamplerate\n\u001b[1;32m    233\u001b[0m waveform \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(waveform)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py:895\u001b[0m, in \u001b[0;36mSoundFile.read\u001b[0;34m(self, frames, dtype, always_2d, fill_value, out)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frames \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m frames \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(out):\n\u001b[1;32m    894\u001b[0m         frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[0;32m--> 895\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_array_io\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m>\u001b[39m frames:\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py:1344\u001b[0m, in \u001b[0;36mSoundFile._array_io\u001b[0;34m(self, action, array, frames)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39msizeof(ctype)\n\u001b[1;32m   1343\u001b[0m cdata \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mcast(ctype \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m, array\u001b[38;5;241m.\u001b[39m__array_interface__[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 1344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cdata_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py:1353\u001b[0m, in \u001b[0;36mSoundFile._cdata_io\u001b[0;34m(self, action, data, ctype, frames)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1352\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_snd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m action \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m ctype)\n\u001b[0;32m-> 1353\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m _error_check(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_errorcode)\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> sauvegarde-gpu
     ]
    }
   ],
   "source": [
    "\n",
    "device = 'cuda'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model_W2V().to(device)\n",
    "\n",
    "\n",
    "train_model(model, dataset, epochs=50, learning_rate=1e-2, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('FeaturesEncoder.conv1.weight',\n",
       "              tensor([[[-0.1463,  0.2508, -0.1200,  ..., -0.0632, -0.1366,  0.0094]],\n",
       "              \n",
       "                      [[-0.0458, -0.0471, -0.0215,  ..., -0.0267, -0.2376,  0.1238]],\n",
       "              \n",
       "                      [[ 0.0772,  0.3316,  0.2077,  ..., -0.0687, -0.1749, -0.2195]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1758, -0.0749,  0.0339,  ...,  0.1812, -0.2428,  0.1554]],\n",
       "              \n",
       "                      [[ 0.2522,  0.2532,  0.2398,  ..., -0.0427, -0.1971, -0.3545]],\n",
       "              \n",
       "                      [[-0.0133, -0.2136, -0.2750,  ...,  0.2352,  0.1483,  0.0329]]],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv1.bias',\n",
       "              tensor([ 0.3877,  0.2848, -0.2335,  0.2381, -0.1377,  0.1949,  0.3273, -0.3072,\n",
       "                       0.1638, -0.1533,  0.3015, -0.2764, -0.0703, -0.2150,  0.2227, -0.1171,\n",
       "                      -0.1098,  0.0913, -0.2743,  0.1474,  0.2150, -0.1331,  0.3415, -0.2936,\n",
       "                       0.0255, -0.1557,  0.1563, -0.0187,  0.0629,  0.1726,  0.2654, -0.2691,\n",
       "                      -0.3604, -0.2551,  0.2623, -0.0438, -0.1607,  0.3192, -0.3071, -0.1136,\n",
       "                      -0.2453, -0.0475, -0.1381,  0.3114,  0.2414, -0.0883,  0.1024,  0.2174,\n",
       "                      -0.0341,  0.3843, -0.0637, -0.1188, -0.1525, -0.0168, -0.2006, -0.2833,\n",
       "                       0.0833,  0.1475,  0.0402, -0.2929, -0.2924,  0.2532, -0.1696,  0.0616,\n",
       "                       0.0141,  0.2856,  0.1045,  0.0374, -0.1188, -0.2204,  0.0881,  0.1273,\n",
       "                       0.1916, -0.2083,  0.0794, -0.0424, -0.0855, -0.0778,  0.1297,  0.1764,\n",
       "                      -0.2475,  0.1679, -0.1324, -0.3557,  0.2543, -0.3266,  0.0650, -0.2638,\n",
       "                      -0.1693,  0.1803,  0.2286,  0.2986,  0.2038,  0.2578,  0.2781,  0.1869,\n",
       "                      -0.2447, -0.0085,  0.3661, -0.0710,  0.1481, -0.1623, -0.2135,  0.2794,\n",
       "                      -0.1652,  0.0828,  0.0194, -0.2523,  0.3001,  0.1032, -0.1029,  0.1024,\n",
       "                      -0.1971, -0.0315,  0.1046,  0.2328,  0.0818, -0.0640,  0.0054, -0.1343,\n",
       "                       0.2898, -0.0364,  0.3992,  0.1436, -0.3122, -0.1254,  0.2234, -0.2605,\n",
       "                       0.1558,  0.1439,  0.1711, -0.1009,  0.0020, -0.2421, -0.2518, -0.0602,\n",
       "                      -0.0849, -0.1706,  0.2247, -0.3501, -0.1647, -0.1028,  0.3954,  0.1769,\n",
       "                       0.3714,  0.0367, -0.0087, -0.0392, -0.0368,  0.1980, -0.1461, -0.0157,\n",
       "                      -0.0769,  0.2564, -0.1139, -0.3124, -0.0748, -0.2326, -0.0104, -0.2894,\n",
       "                       0.1393, -0.0844,  0.0420, -0.0902,  0.0653,  0.0752, -0.1169,  0.2818,\n",
       "                       0.1529, -0.3376, -0.1070, -0.3019, -0.1183,  0.0859,  0.0285, -0.0311,\n",
       "                      -0.1639, -0.0786, -0.0057, -0.0863, -0.2213,  0.1771, -0.3753,  0.0746,\n",
       "                      -0.0400,  0.2061,  0.1887, -0.1005,  0.3251, -0.3182,  0.0281,  0.2234,\n",
       "                      -0.0078,  0.0355, -0.0050,  0.0209,  0.2359,  0.2317, -0.2076, -0.0862,\n",
       "                      -0.1209, -0.3473,  0.0177, -0.0640, -0.0628, -0.1555,  0.0027, -0.0487,\n",
       "                       0.2428, -0.2087, -0.1567, -0.1536,  0.2340, -0.1438,  0.3205,  0.0746,\n",
       "                       0.2234, -0.0279,  0.2908, -0.2104, -0.0851,  0.2616, -0.2270, -0.2520,\n",
       "                       0.1690,  0.0950,  0.0076, -0.0926, -0.3604,  0.0220, -0.2225,  0.3069,\n",
       "                      -0.1907,  0.0395,  0.2484,  0.0104, -0.3150, -0.2409, -0.0019, -0.1933,\n",
       "                       0.1963,  0.0379, -0.1316,  0.0722, -0.2889,  0.0946,  0.1596, -0.2262,\n",
       "                      -0.0624,  0.3503,  0.2477,  0.0644, -0.1328,  0.1543,  0.0364, -0.1414,\n",
       "                       0.0897,  0.0642,  0.2993,  0.3256,  0.1433,  0.0952, -0.0485,  0.2855,\n",
       "                       0.1533,  0.3671,  0.0780, -0.0242,  0.0279,  0.0959,  0.1831,  0.1745,\n",
       "                       0.0055, -0.1911, -0.1168,  0.0680, -0.0601,  0.2771,  0.1793,  0.1523,\n",
       "                       0.2057, -0.0395,  0.1460, -0.1503, -0.2457, -0.0776, -0.0757,  0.0894,\n",
       "                      -0.0196,  0.3268, -0.0714, -0.3679, -0.1034,  0.1820, -0.1005,  0.2486,\n",
       "                      -0.3595, -0.1439,  0.0907, -0.0098, -0.2806,  0.1945, -0.2512,  0.2406,\n",
       "                      -0.1874,  0.0108, -0.0855,  0.2688, -0.3199, -0.1210,  0.2854, -0.0190,\n",
       "                      -0.0295,  0.0736,  0.2160,  0.2058,  0.1245,  0.0227,  0.0594,  0.1592,\n",
       "                       0.1872,  0.1457, -0.0661,  0.2008, -0.0894, -0.0167,  0.1888, -0.2098,\n",
       "                       0.1792, -0.0733,  0.0778,  0.1894, -0.3041,  0.0723, -0.0434, -0.0512,\n",
       "                       0.2722,  0.1140, -0.1260, -0.0654, -0.0871, -0.2490,  0.1126, -0.1486,\n",
       "                       0.1977, -0.0224, -0.0042, -0.0514, -0.0441, -0.0885, -0.2759,  0.1452,\n",
       "                       0.0141,  0.2310,  0.1193, -0.0626, -0.0924, -0.0686,  0.3493, -0.2384,\n",
       "                       0.1978,  0.1309, -0.0195, -0.0174,  0.0060,  0.1988, -0.0248,  0.0080,\n",
       "                       0.0337,  0.0005, -0.1569,  0.2558, -0.1164,  0.1637,  0.3598, -0.1183,\n",
       "                       0.0564, -0.0424, -0.2404,  0.1728, -0.0299, -0.0442,  0.0108, -0.3216,\n",
       "                       0.2491, -0.1081, -0.1130, -0.0284,  0.2743, -0.0329, -0.0849, -0.2996,\n",
       "                      -0.0984,  0.0383,  0.0654,  0.1567, -0.0892,  0.1985, -0.0935, -0.0227,\n",
       "                      -0.0458, -0.0104,  0.2407, -0.0351, -0.0242,  0.1777,  0.1907, -0.2513,\n",
       "                      -0.0792,  0.1404, -0.1949,  0.1102,  0.0765, -0.2023, -0.1038, -0.0265,\n",
       "                      -0.0517, -0.1822,  0.1733,  0.0337, -0.0739, -0.0311, -0.3924,  0.0474,\n",
       "                       0.2356,  0.0847, -0.0993,  0.1722, -0.0933,  0.0907, -0.2226, -0.0024,\n",
       "                       0.0102,  0.0720,  0.1018, -0.1144,  0.0490, -0.0284,  0.3703, -0.0698,\n",
       "                       0.4004, -0.3582, -0.2339, -0.1604,  0.1622, -0.2637, -0.0975,  0.1299,\n",
       "                       0.1690, -0.1786, -0.1669,  0.1017,  0.0618, -0.0856,  0.3678, -0.1023,\n",
       "                       0.0356,  0.1328,  0.2221,  0.1728,  0.1415,  0.0688,  0.0241, -0.0115,\n",
       "                      -0.0938, -0.1146, -0.0362,  0.0144, -0.2700,  0.0428, -0.0946, -0.1203,\n",
       "                      -0.2981,  0.1830,  0.2434,  0.0406, -0.2308,  0.2692, -0.1971,  0.0456,\n",
       "                      -0.1235, -0.1130, -0.1627,  0.2998, -0.3242,  0.1881,  0.2079, -0.0910,\n",
       "                      -0.2214,  0.0155, -0.2264, -0.0118, -0.0282,  0.2461,  0.1456, -0.1283,\n",
       "                      -0.1590, -0.0744,  0.1738,  0.2400,  0.2011,  0.2607, -0.2348, -0.2703,\n",
       "                       0.1387, -0.0644, -0.1904, -0.0360,  0.2094, -0.1141, -0.0526,  0.3025],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm1.weight',\n",
       "              tensor([1.0877, 1.0752, 1.0823, 1.0877, 1.0742, 1.0815, 1.0826, 1.0844, 0.9772,\n",
       "                      0.9439, 1.0064, 1.0816, 1.0642, 0.9225, 0.9385, 1.0222, 0.9161, 0.9340,\n",
       "                      1.0105, 0.9244, 1.0878, 1.0720, 1.0611, 1.0876, 0.9171, 0.9161, 0.9733,\n",
       "                      0.9133, 0.9199, 1.0070, 0.9958, 1.0834, 1.0854, 1.0148, 0.9513, 0.9236,\n",
       "                      0.9159, 1.0853, 1.0820, 0.9159, 1.0148, 1.0879, 0.9803, 1.0276, 0.9372,\n",
       "                      0.9477, 1.0788, 0.9630, 0.9222, 1.0858, 1.0174, 1.0877, 0.9122, 0.9234,\n",
       "                      1.0861, 1.0072, 1.0779, 1.0114, 0.9591, 1.0870, 1.0873, 1.0638, 0.9804,\n",
       "                      0.9186, 0.9760, 1.0870, 1.0845, 0.9368, 0.9201, 0.9840, 1.0503, 0.9837,\n",
       "                      1.0240, 0.9215, 0.9933, 1.0732, 1.0853, 0.9129, 0.9916, 0.9958, 1.0146,\n",
       "                      1.0843, 0.9602, 1.0849, 1.0851, 1.0847, 0.9702, 1.0874, 1.0499, 0.9574,\n",
       "                      0.9248, 0.9826, 0.9799, 0.9427, 1.0821, 1.0464, 1.0810, 0.9887, 1.0844,\n",
       "                      1.0453, 0.9597, 1.0749, 1.0851, 1.0321, 0.9893, 1.0876, 0.9815, 1.0836,\n",
       "                      1.0592, 1.0876, 1.0874, 1.0535, 1.0002, 0.9802, 0.9861, 0.9314, 0.9140,\n",
       "                      1.0687, 0.9188, 0.9633, 1.0824, 1.0206, 1.0874, 0.9295, 1.0611, 1.0831,\n",
       "                      0.9317, 1.0856, 0.9916, 0.9354, 0.9239, 1.0601, 0.9147, 1.0856, 1.0833,\n",
       "                      1.0346, 1.0323, 1.0876, 1.0797, 1.0798, 1.0759, 0.9435, 1.0871, 0.9790,\n",
       "                      1.0678, 1.0334, 0.9422, 0.9121, 0.9355, 1.0704, 1.0792, 0.9241, 1.0234,\n",
       "                      1.0789, 1.0600, 1.0866, 1.0655, 1.0727, 0.9230, 1.0320, 0.9951, 0.9798,\n",
       "                      1.0516, 1.0694, 0.9706, 0.9161, 1.0651, 0.9852, 0.9780, 1.0871, 0.9332,\n",
       "                      1.0414, 1.0566, 0.9223, 0.9167, 0.9538, 0.9858, 0.9400, 0.9282, 1.0870,\n",
       "                      0.9137, 0.9739, 1.0875, 1.0027, 0.9819, 0.9895, 0.9493, 1.0362, 1.0747,\n",
       "                      1.0859, 0.9213, 1.0459, 0.9131, 0.9266, 0.9266, 0.9324, 1.0288, 1.0213,\n",
       "                      1.0800, 0.9451, 1.0848, 1.0724, 0.9405, 0.9220, 0.9537, 1.0878, 0.9764,\n",
       "                      0.9125, 1.0245, 0.9291, 0.9130, 1.0867, 0.9851, 0.9679, 1.0250, 0.9411,\n",
       "                      1.0864, 0.9226, 1.0829, 1.0809, 0.9630, 1.0129, 0.9659, 1.0821, 1.0019,\n",
       "                      0.9128, 0.9198, 1.0461, 1.0242, 1.0126, 0.9201, 1.0487, 0.9228, 0.9560,\n",
       "                      1.0594, 0.9187, 1.0128, 0.9856, 1.0168, 1.0846, 0.9958, 0.9476, 1.0835,\n",
       "                      1.0355, 1.0654, 1.0225, 0.9222, 0.9964, 0.9796, 1.0726, 0.9357, 0.9246,\n",
       "                      1.0677, 0.9996, 0.9761, 1.0792, 0.9822, 0.9873, 1.0861, 1.0841, 1.0539,\n",
       "                      1.0836, 0.9141, 1.0877, 1.0285, 1.0878, 0.9856, 1.0156, 0.9212, 0.9172,\n",
       "                      0.9275, 0.9470, 0.9124, 0.9805, 1.0807, 1.0869, 0.9312, 0.9941, 1.0807,\n",
       "                      0.9135, 1.0177, 0.9458, 0.9197, 1.0763, 0.9898, 1.0873, 1.0166, 1.0047,\n",
       "                      0.9147, 1.0367, 0.9932, 1.0857, 1.0147, 0.9479, 1.0740, 1.0609, 1.0878,\n",
       "                      1.0863, 1.0124, 0.9123, 0.9978, 1.0180, 1.0432, 1.0877, 1.0183, 0.9145,\n",
       "                      0.9384, 1.0481, 1.0847, 0.9147, 0.9932, 0.9299, 0.9981, 1.0097, 1.0871,\n",
       "                      1.0111, 0.9127, 0.9124, 1.0630, 1.0380, 1.0874, 0.9984, 0.9220, 0.9497,\n",
       "                      1.0569, 0.9522, 0.9488, 0.9122, 0.9224, 0.9296, 0.9952, 1.0877, 1.0239,\n",
       "                      1.0349, 1.0786, 0.9157, 1.0862, 1.0819, 1.0717, 0.9855, 0.9682, 1.0773,\n",
       "                      0.9158, 1.0852, 1.0870, 0.9830, 0.9130, 0.9118, 1.0223, 1.0851, 1.0578,\n",
       "                      0.9965, 0.9126, 1.0833, 0.9466, 0.9355, 1.0797, 1.0163, 1.0788, 0.9886,\n",
       "                      0.9512, 1.0790, 0.9132, 0.9776, 0.9158, 1.0822, 0.9190, 0.9122, 0.9763,\n",
       "                      0.9246, 1.0809, 1.0874, 0.9394, 0.9771, 1.0873, 1.0152, 0.9552, 1.0809,\n",
       "                      1.0123, 1.0208, 0.9808, 0.9314, 0.9129, 1.0834, 0.9682, 1.0138, 1.0619,\n",
       "                      0.9122, 1.0863, 1.0260, 1.0773, 1.0844, 0.9401, 1.0123, 0.9167, 0.9380,\n",
       "                      1.0715, 1.0140, 0.9393, 0.9792, 0.9844, 0.9124, 1.0792, 0.9121, 0.9126,\n",
       "                      0.9402, 0.9124, 1.0876, 1.0179, 0.9981, 1.0099, 0.9138, 0.9767, 1.0634,\n",
       "                      0.9437, 0.9403, 0.9336, 0.9869, 1.0035, 0.9212, 1.0187, 1.0094, 1.0877,\n",
       "                      0.9141, 0.9912, 0.9828, 1.0181, 1.0130, 0.9719, 0.9781, 0.9763, 0.9135,\n",
       "                      1.0486, 0.9305, 1.0140, 1.0118, 0.9565, 1.0656, 1.0828, 0.9638, 1.0878,\n",
       "                      1.0827, 0.9767, 0.9292, 1.0598, 1.0235, 0.9513, 0.9371, 1.0097, 0.9923,\n",
       "                      1.0131, 0.9495, 0.9132, 1.0366, 1.0872, 0.9151, 0.9191, 1.0395, 0.9320,\n",
       "                      0.9778, 0.9157, 1.0161, 0.9188, 0.9996, 1.0800, 0.9783, 0.9782, 1.0521,\n",
       "                      1.0878, 1.0265, 1.0804, 0.9270, 1.0462, 1.0447, 1.0875, 0.9875, 1.0878,\n",
       "                      0.9879, 1.0854, 0.9125, 1.0811, 1.0866, 1.0869, 1.0876, 1.0869, 1.0411,\n",
       "                      0.9618, 0.9987, 1.0711, 1.0496, 0.9184, 0.9124, 0.9657, 0.9712, 0.9192,\n",
       "                      1.0865, 1.0135, 1.0870, 0.9206, 0.9491, 1.0674, 1.0862, 1.0873, 1.0830,\n",
       "                      0.9180, 1.0843, 0.9175, 0.9178, 0.9148, 1.0788, 0.9416, 1.0502],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm1.bias',\n",
       "              tensor([ 0.0878,  0.0717, -0.0877,  0.0872, -0.0639,  0.0803,  0.0832, -0.0835,\n",
       "                      -0.0820,  0.0550,  0.0069, -0.0819, -0.0881,  0.0237, -0.0617, -0.0223,\n",
       "                       0.0877, -0.0673, -0.0118, -0.0769,  0.0875, -0.0683,  0.0615, -0.0878,\n",
       "                       0.0876,  0.0839, -0.0296, -0.0851, -0.0816,  0.0039, -0.0045, -0.0826,\n",
       "                      -0.0862, -0.0144, -0.0498, -0.0861,  0.0855,  0.0872, -0.0232,  0.0875,\n",
       "                      -0.0170,  0.0038,  0.0163,  0.0293, -0.0631,  0.0479,  0.0222, -0.0333,\n",
       "                       0.0158,  0.0852, -0.0020, -0.0864,  0.0870, -0.0854, -0.0857, -0.0068,\n",
       "                       0.0877,  0.0114, -0.0161, -0.0877, -0.0876,  0.0633,  0.0230, -0.0201,\n",
       "                      -0.0226,  0.0868,  0.0873, -0.0655,  0.0829,  0.0068,  0.0497, -0.0109,\n",
       "                       0.0238,  0.0802, -0.0019, -0.0818,  0.0175, -0.0208, -0.0077, -0.0039,\n",
       "                      -0.0876,  0.0831,  0.0364, -0.0849,  0.0834, -0.0849,  0.0002, -0.0875,\n",
       "                      -0.0547, -0.0407, -0.0763, -0.0023, -0.0161, -0.0568,  0.0831,  0.0506,\n",
       "                      -0.0846, -0.0062,  0.0842,  0.0810, -0.0373, -0.0760, -0.0875, -0.0860,\n",
       "                      -0.0850,  0.0869,  0.0876, -0.0839,  0.0593,  0.0793, -0.0756,  0.0498,\n",
       "                      -0.0128,  0.0174, -0.0131, -0.0688, -0.0846, -0.0124, -0.0874,  0.0309,\n",
       "                       0.0815, -0.0171,  0.0870, -0.0686, -0.0610, -0.0761, -0.0685, -0.0831,\n",
       "                      -0.0097, -0.0660, -0.0775, -0.0600,  0.0804, -0.0854, -0.0832, -0.0423,\n",
       "                      -0.0382, -0.0763,  0.0822, -0.0786, -0.0673,  0.0560,  0.0871, -0.0201,\n",
       "                       0.0673,  0.0182, -0.0487, -0.0244, -0.0854,  0.0703, -0.0840, -0.0877,\n",
       "                      -0.0810,  0.0795, -0.0600, -0.0863, -0.0737, -0.0710, -0.0203, -0.0317,\n",
       "                      -0.0017, -0.0460,  0.0810, -0.0806, -0.0008, -0.0867, -0.0632, -0.0140,\n",
       "                      -0.0179, -0.0863,  0.0682, -0.0433, -0.0587, -0.0795, -0.0801,  0.0508,\n",
       "                       0.0778,  0.0600, -0.0765, -0.0216,  0.0858, -0.0234, -0.0877, -0.0013,\n",
       "                       0.0430, -0.0114, -0.0494, -0.0502,  0.0736, -0.0857, -0.0835,  0.0479,\n",
       "                      -0.0872,  0.0829, -0.0820, -0.0783,  0.0235,  0.0271, -0.0815,  0.0530,\n",
       "                      -0.0722, -0.0713, -0.0581,  0.0794, -0.0857, -0.0875, -0.0241, -0.0833,\n",
       "                       0.0272,  0.0717,  0.0878, -0.0674, -0.0065,  0.0331,  0.0258, -0.0574,\n",
       "                       0.0878, -0.0079,  0.0849, -0.0797, -0.0766,  0.0107,  0.0312, -0.0810,\n",
       "                       0.0098, -0.0865,  0.0877, -0.0525, -0.0802, -0.0050,  0.0794,  0.0498,\n",
       "                       0.0787, -0.0293,  0.0595, -0.0089, -0.0165,  0.0104, -0.0033, -0.0875,\n",
       "                      -0.0005, -0.0424, -0.0795, -0.0858, -0.0650,  0.0186, -0.0784, -0.0005,\n",
       "                       0.0761,  0.0715, -0.0644, -0.0784, -0.0647,  0.0115,  0.0164, -0.0715,\n",
       "                       0.0239,  0.0243,  0.0848,  0.0826,  0.0546,  0.0810, -0.0329,  0.0059,\n",
       "                       0.0312,  0.0877,  0.0236, -0.0228, -0.0856, -0.0853, -0.0731, -0.0526,\n",
       "                      -0.0037,  0.0189, -0.0801,  0.0874,  0.0232, -0.0034,  0.0813, -0.0849,\n",
       "                       0.0237,  0.0563, -0.0821, -0.0705,  0.0119,  0.0448, -0.0836,  0.0874,\n",
       "                      -0.0877,  0.0418, -0.0876, -0.0873, -0.0848, -0.0512, -0.0713,  0.0610,\n",
       "                      -0.0877, -0.0873,  0.0276,  0.0862, -0.0023,  0.0233, -0.0445,  0.0877,\n",
       "                      -0.0813,  0.0877,  0.0625,  0.0499, -0.0840,  0.0871, -0.0031, -0.0358,\n",
       "                       0.0098,  0.0857,  0.0878,  0.0149, -0.0846, -0.0877,  0.0805,  0.0449,\n",
       "                       0.0871, -0.0005,  0.0832, -0.0483,  0.0857,  0.0433, -0.0498,  0.0878,\n",
       "                      -0.0768, -0.0456,  0.0030,  0.0861, -0.0238,  0.0320,  0.0152,  0.0861,\n",
       "                       0.0874,  0.0846, -0.0674,  0.0063, -0.0742, -0.0751, -0.0858, -0.0746,\n",
       "                       0.0876,  0.0394,  0.0850, -0.0541, -0.0058, -0.0067, -0.0564, -0.0012,\n",
       "                      -0.0865,  0.0862, -0.0265,  0.0801, -0.0860,  0.0797,  0.0205,  0.0080,\n",
       "                      -0.0465,  0.0877, -0.0223,  0.0812, -0.0185,  0.0788, -0.0873, -0.0877,\n",
       "                       0.0816, -0.0811, -0.0800,  0.0874, -0.0593, -0.0236,  0.0875, -0.0799,\n",
       "                      -0.0319,  0.0248, -0.0268,  0.0775,  0.0068, -0.0445,  0.0208, -0.0811,\n",
       "                      -0.0289, -0.0851, -0.0614, -0.0839,  0.0847, -0.0228, -0.0701, -0.0868,\n",
       "                      -0.0601,  0.0855, -0.0840, -0.0622, -0.0686,  0.0176,  0.0610,  0.0199,\n",
       "                      -0.0092, -0.0873,  0.0761, -0.0100, -0.0218, -0.0597, -0.0877, -0.0872,\n",
       "                      -0.0872, -0.0115, -0.0833,  0.0237, -0.0234, -0.0624,  0.0562, -0.0649,\n",
       "                      -0.0867,  0.0106, -0.0008, -0.0241, -0.0810,  0.0817, -0.0876,  0.0859,\n",
       "                      -0.0054, -0.0106, -0.0787,  0.0191, -0.0821, -0.0272,  0.0231,  0.0877,\n",
       "                      -0.0176, -0.0696,  0.0876, -0.0857, -0.0331, -0.0862,  0.0835,  0.0286,\n",
       "                       0.0873, -0.0833,  0.0214,  0.0717,  0.0598, -0.0785,  0.0452, -0.0631,\n",
       "                       0.0201,  0.0038, -0.0060, -0.0495, -0.0874, -0.0271,  0.0875, -0.0463,\n",
       "                       0.0861,  0.0430, -0.0687, -0.0088, -0.0768,  0.0364,  0.0781,  0.0849,\n",
       "                      -0.0835,  0.0143,  0.0877,  0.0175, -0.0868,  0.0152, -0.0227,  0.0761,\n",
       "                      -0.0488,  0.0480,  0.0866, -0.0097, -0.0844, -0.0126, -0.0804, -0.0848,\n",
       "                      -0.0848, -0.0220, -0.0867,  0.0866, -0.0876,  0.0430, -0.0270,  0.0390,\n",
       "                      -0.0820, -0.0111,  0.0798, -0.0861,  0.0192, -0.0249, -0.0806, -0.0825,\n",
       "                      -0.0138, -0.0821, -0.0819, -0.0501,  0.0663,  0.0856, -0.0840, -0.0866,\n",
       "                      -0.0822, -0.0154,  0.0228,  0.0828, -0.0860, -0.0175, -0.0782,  0.0532],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv2.weight',\n",
       "              tensor([[[-0.0074,  0.0024, -0.0189],\n",
       "                       [-0.0331,  0.0003,  0.0026],\n",
       "                       [ 0.0234,  0.0107, -0.0011],\n",
       "                       ...,\n",
       "                       [ 0.0392,  0.0040,  0.0348],\n",
       "                       [ 0.0600,  0.0738,  0.0502],\n",
       "                       [-0.0386,  0.0164,  0.0037]],\n",
       "              \n",
       "                      [[-0.0392, -0.0019, -0.0183],\n",
       "                       [-0.0306, -0.0056, -0.0039],\n",
       "                       [ 0.0407,  0.0359,  0.0785],\n",
       "                       ...,\n",
       "                       [ 0.0898,  0.0833,  0.0192],\n",
       "                       [ 0.0928,  0.0635,  0.0702],\n",
       "                       [-0.0437, -0.0943, -0.0426]],\n",
       "              \n",
       "                      [[ 0.0825,  0.0996,  0.0732],\n",
       "                       [ 0.1003,  0.0845,  0.0897],\n",
       "                       [-0.0709, -0.0673, -0.0973],\n",
       "                       ...,\n",
       "                       [-0.0941, -0.1027, -0.0808],\n",
       "                       [ 0.0718,  0.0676,  0.0402],\n",
       "                       [ 0.0743,  0.0891,  0.0655]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0798,  0.1035,  0.1090],\n",
       "                       [ 0.0746,  0.0684,  0.0912],\n",
       "                       [-0.1064, -0.1089, -0.0699],\n",
       "                       ...,\n",
       "                       [-0.0743, -0.1007, -0.0986],\n",
       "                       [-0.0802,  0.0373,  0.0402],\n",
       "                       [ 0.0794,  0.0834,  0.0947]],\n",
       "              \n",
       "                      [[-0.0414, -0.0629, -0.0206],\n",
       "                       [-0.0581, -0.0133, -0.0229],\n",
       "                       [ 0.0616,  0.0373,  0.0609],\n",
       "                       ...,\n",
       "                       [ 0.0258,  0.0441,  0.0342],\n",
       "                       [-0.0771, -0.0792,  0.0578],\n",
       "                       [-0.0184, -0.0327, -0.0525]],\n",
       "              \n",
       "                      [[-0.0084, -0.0034, -0.0191],\n",
       "                       [-0.0150, -0.0138, -0.0253],\n",
       "                       [-0.0070, -0.0048,  0.0341],\n",
       "                       ...,\n",
       "                       [ 0.0201,  0.0307, -0.0158],\n",
       "                       [ 0.0630,  0.0985,  0.0844],\n",
       "                       [-0.0165, -0.0097, -0.0182]]], device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv2.bias',\n",
       "              tensor([-0.0264, -0.0346,  0.0878, -0.0623, -0.0625, -0.0868,  0.0972, -0.0798,\n",
       "                      -0.0222, -0.0253, -0.0543, -0.0489, -0.0663,  0.1020, -0.0305,  0.0248,\n",
       "                      -0.0247,  0.0616, -0.0661, -0.0236, -0.0091,  0.0617,  0.0677, -0.0660,\n",
       "                      -0.0870, -0.0324, -0.0895,  0.0357,  0.1051,  0.0805, -0.0542,  0.1071,\n",
       "                       0.0710, -0.1053,  0.0021,  0.0054,  0.0695, -0.0348, -0.0463,  0.0794,\n",
       "                      -0.0350, -0.0085, -0.0127, -0.0283, -0.0208, -0.0258, -0.0434, -0.0298,\n",
       "                      -0.0792,  0.0574, -0.0289,  0.0075, -0.0254, -0.0495, -0.0667, -0.0761,\n",
       "                      -0.0876, -0.0083, -0.0187, -0.0716,  0.0899, -0.0725,  0.0851, -0.0506,\n",
       "                      -0.0406, -0.0220,  0.0752, -0.0868, -0.0247, -0.0465, -0.0120, -0.0627,\n",
       "                      -0.0182, -0.0761,  0.0010, -0.0808, -0.0139, -0.0536,  0.0936, -0.0518,\n",
       "                       0.1047,  0.0957,  0.0752, -0.0129, -0.0121,  0.0602,  0.1116, -0.0253,\n",
       "                      -0.1012, -0.0180,  0.0013, -0.0783, -0.0046, -0.0732, -0.0127, -0.0267,\n",
       "                      -0.0546,  0.0055,  0.0638,  0.0635,  0.0873,  0.1104, -0.0803,  0.0862,\n",
       "                       0.0622,  0.0060,  0.0018, -0.0626, -0.0360, -0.0130, -0.0810, -0.0649,\n",
       "                      -0.0574, -0.0358, -0.0616, -0.0139, -0.0859, -0.0653, -0.0776,  0.0433,\n",
       "                      -0.0042, -0.0519, -0.0606, -0.0399,  0.0866, -0.0204,  0.0268,  0.0232,\n",
       "                      -0.0141,  0.0088, -0.0323, -0.0398,  0.0161, -0.0405, -0.0328,  0.0575,\n",
       "                       0.0640, -0.0896, -0.0779, -0.0345, -0.0443, -0.0721, -0.0729, -0.0812,\n",
       "                       0.0978, -0.0344, -0.0418,  0.0813, -0.0250,  0.0089,  0.0865, -0.0888,\n",
       "                      -0.0110, -0.0816, -0.0452, -0.0369,  0.0654,  0.1036,  0.0603, -0.0044,\n",
       "                      -0.0825, -0.0587, -0.0782, -0.0397, -0.0439,  0.0309,  0.1013,  0.0859,\n",
       "                      -0.0724, -0.0390, -0.0741, -0.0346, -0.0774, -0.0216,  0.0942, -0.0447,\n",
       "                       0.0659, -0.0776, -0.0136, -0.0264,  0.0042, -0.0562, -0.0401,  0.0715,\n",
       "                      -0.0376,  0.1007, -0.0431, -0.0556, -0.0434, -0.0494, -0.0640, -0.0533,\n",
       "                       0.0599, -0.0243, -0.0550, -0.0397,  0.1077, -0.0097,  0.0972, -0.0597,\n",
       "                      -0.0596, -0.0932, -0.0402,  0.0703, -0.0572, -0.0640, -0.0400,  0.0910,\n",
       "                      -0.0387, -0.0569, -0.0710,  0.0232,  0.0813, -0.0224, -0.0547, -0.0358,\n",
       "                       0.0777,  0.0706,  0.0563, -0.0193,  0.1125, -0.0525, -0.0808,  0.0719,\n",
       "                       0.1039, -0.0201, -0.0681,  0.0962,  0.0970, -0.0125, -0.0592,  0.0059,\n",
       "                       0.0898,  0.0122, -0.0308,  0.0217,  0.0229, -0.0392,  0.0003, -0.0035,\n",
       "                      -0.0491, -0.0198, -0.0229,  0.0647, -0.0498,  0.0967, -0.0280,  0.0899,\n",
       "                      -0.0389, -0.0202, -0.0301, -0.0647, -0.0016,  0.0063, -0.0755,  0.0949,\n",
       "                      -0.0192, -0.0214,  0.1032, -0.0438, -0.0867, -0.0764, -0.0843,  0.0725,\n",
       "                       0.0996, -0.0744,  0.0680,  0.0811, -0.0187,  0.0754, -0.0419, -0.0527,\n",
       "                      -0.0216, -0.0599, -0.0345, -0.0145, -0.0342, -0.0123,  0.0899, -0.0465,\n",
       "                      -0.0211, -0.0019,  0.0819, -0.0815, -0.0353, -0.0367, -0.0170, -0.0635,\n",
       "                      -0.0154,  0.0684, -0.0064, -0.0363, -0.0345,  0.1004,  0.0726,  0.0901,\n",
       "                       0.0747, -0.0294, -0.0389, -0.0464, -0.0234,  0.1084,  0.0302,  0.0987,\n",
       "                       0.0720, -0.0219, -0.0027, -0.0475, -0.0036, -0.0528,  0.1004,  0.0831,\n",
       "                      -0.0948, -0.0591, -0.0282, -0.0158, -0.0838,  0.0839, -0.0627, -0.0865,\n",
       "                      -0.0526, -0.0118, -0.0617, -0.0590, -0.0123, -0.0312, -0.0981,  0.0830,\n",
       "                       0.0926, -0.0230, -0.0047,  0.1080, -0.0080,  0.0579,  0.1050, -0.0539,\n",
       "                       0.0606, -0.0373, -0.0548, -0.0562, -0.0354, -0.0300,  0.0742,  0.0789,\n",
       "                      -0.0116,  0.0184,  0.0825,  0.0837, -0.0089, -0.0750, -0.0258, -0.0532,\n",
       "                       0.0989, -0.0775, -0.0407,  0.1060, -0.0573,  0.0255,  0.0065, -0.0036,\n",
       "                       0.0834, -0.0379, -0.0319,  0.0135, -0.0674, -0.0734, -0.0413,  0.0036,\n",
       "                      -0.0692, -0.0389,  0.0579, -0.0097, -0.0393, -0.0769, -0.0033, -0.0122,\n",
       "                      -0.0509, -0.0464, -0.0094,  0.1000,  0.0267, -0.0406, -0.0312,  0.0020,\n",
       "                      -0.0427, -0.0240, -0.0105,  0.0955,  0.0683, -0.0044, -0.0565, -0.0707,\n",
       "                       0.1092, -0.0282, -0.0397,  0.0977,  0.0725, -0.0482, -0.0624, -0.0477,\n",
       "                       0.0072, -0.0235, -0.0389,  0.0706, -0.0195,  0.0740, -0.0814, -0.0630,\n",
       "                      -0.0398, -0.0766, -0.0436, -0.0163, -0.0832, -0.0103, -0.0562, -0.0515,\n",
       "                      -0.0259,  0.1021,  0.0829, -0.0525,  0.0828,  0.0783, -0.0243, -0.0542,\n",
       "                      -0.0468, -0.0470, -0.0783, -0.0692, -0.0462, -0.0724,  0.0760,  0.1119,\n",
       "                      -0.0634, -0.0536, -0.0661, -0.0810, -0.0950,  0.0954, -0.0156, -0.0750,\n",
       "                      -0.0311, -0.0285, -0.0651, -0.0754, -0.0672, -0.0731, -0.0458,  0.0664,\n",
       "                      -0.0157,  0.0791, -0.0650,  0.0696, -0.0125, -0.0431,  0.1026,  0.0919,\n",
       "                      -0.0386,  0.0949, -0.0638, -0.0017, -0.0600, -0.0566,  0.0632, -0.0094,\n",
       "                      -0.0496, -0.0746,  0.0842, -0.0711, -0.0237, -0.0251, -0.0624,  0.0939,\n",
       "                       0.0941, -0.0308,  0.0102, -0.0755,  0.0780,  0.0700, -0.0409,  0.0110,\n",
       "                       0.0520, -0.0129, -0.0850,  0.0868,  0.0820, -0.0757, -0.0242,  0.0048,\n",
       "                       0.0970, -0.0517, -0.0209,  0.0013, -0.0264, -0.0692, -0.0419, -0.0446,\n",
       "                       0.1032, -0.0756, -0.0004, -0.0154, -0.0366, -0.0443, -0.0827,  0.1026,\n",
       "                       0.0836, -0.0800, -0.0049,  0.0633, -0.0255,  0.0652, -0.0627,  0.0127],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm2.weight',\n",
       "              tensor([0.9758, 0.9775, 1.0780, 0.9760, 1.0201, 1.0228, 1.0788, 1.0152, 0.9228,\n",
       "                      0.9313, 1.0255, 1.0195, 1.0088, 1.0778, 0.9765, 0.9777, 0.9752, 1.0244,\n",
       "                      1.0161, 0.9245, 0.9264, 1.0783, 1.0249, 0.9758, 1.0184, 0.9260, 1.0816,\n",
       "                      0.9761, 1.0777, 1.0754, 1.0216, 1.0778, 1.0774, 1.0233, 0.9757, 0.9758,\n",
       "                      1.0197, 0.9200, 1.0205, 1.0781, 0.9242, 0.9760, 0.9207, 0.9779, 0.9759,\n",
       "                      0.9324, 0.9213, 0.9761, 1.0243, 1.0776, 0.9766, 0.9283, 0.9779, 0.9898,\n",
       "                      1.0789, 1.0191, 1.0071, 0.9798, 0.9751, 1.0181, 1.0750, 1.0169, 1.0781,\n",
       "                      0.9977, 0.9775, 0.9758, 1.0761, 1.0182, 0.9775, 1.0063, 0.9756, 1.0159,\n",
       "                      0.9760, 1.0238, 0.9775, 0.9826, 0.9262, 1.0202, 1.0236, 0.9772, 1.0780,\n",
       "                      1.0738, 1.0262, 0.9759, 0.9515, 1.0742, 1.0721, 0.9763, 0.9737, 0.9239,\n",
       "                      0.9757, 1.0223, 0.9762, 0.9798, 0.9762, 0.9263, 1.0152, 0.9749, 1.0773,\n",
       "                      1.0788, 1.0789, 1.0774, 1.0135, 1.0784, 1.0246, 0.9241, 0.9756, 1.0245,\n",
       "                      0.9995, 0.9762, 1.0791, 1.0785, 1.0181, 0.9261, 1.0226, 0.9246, 0.9985,\n",
       "                      0.9758, 0.9759, 1.0206, 0.9764, 0.9788, 0.9777, 0.9250, 1.0787, 0.9246,\n",
       "                      0.9261, 0.9758, 0.9763, 0.9238, 0.9244, 0.9984, 0.9758, 0.9229, 0.9270,\n",
       "                      1.0711, 1.0800, 1.0242, 1.0216, 0.9222, 0.9250, 1.0082, 1.0143, 1.0199,\n",
       "                      1.0786, 0.9163, 0.9211, 1.0766, 0.9757, 0.9250, 1.0792, 1.0205, 0.9255,\n",
       "                      1.0175, 0.9277, 0.9774, 1.0740, 1.0792, 1.0798, 0.9759, 1.0235, 0.9763,\n",
       "                      0.9218, 0.9282, 0.9124, 0.9762, 1.0737, 1.0788, 1.0143, 0.9258, 0.9993,\n",
       "                      0.9304, 1.0218, 0.9783, 1.0799, 1.0097, 1.0774, 1.0228, 0.9267, 0.9776,\n",
       "                      0.9777, 1.0110, 1.0026, 1.0763, 1.0119, 1.0783, 0.9775, 0.9766, 0.9222,\n",
       "                      1.0107, 1.0228, 0.9758, 1.0769, 0.9760, 0.9758, 1.0234, 1.0772, 0.9253,\n",
       "                      1.0777, 0.9782, 0.9199, 1.0788, 1.0199, 1.0791, 0.9768, 0.9761, 0.9242,\n",
       "                      1.0774, 0.9765, 1.0222, 1.0157, 1.0183, 1.0228, 0.9265, 0.9758, 1.0791,\n",
       "                      1.0242, 1.0774, 1.0800, 0.9256, 1.0783, 1.0768, 1.0173, 1.0770, 0.9792,\n",
       "                      0.9759, 1.0155, 1.0767, 1.0772, 0.9762, 1.0103, 0.9305, 1.0766, 0.9280,\n",
       "                      0.9769, 0.9765, 0.9281, 0.9789, 0.9265, 0.9269, 0.9765, 0.9299, 0.9289,\n",
       "                      1.0787, 0.9214, 1.0778, 0.9247, 1.0767, 0.9759, 0.9758, 0.9223, 0.9757,\n",
       "                      0.9290, 0.9232, 1.0844, 1.0782, 0.9794, 0.9240, 1.0765, 0.9790, 0.9975,\n",
       "                      1.0169, 1.0149, 1.0767, 1.0786, 1.0193, 1.0747, 1.0788, 0.9297, 1.0759,\n",
       "                      1.0055, 0.9771, 0.9813, 0.9225, 0.9758, 0.9736, 0.9757, 0.9294, 1.0775,\n",
       "                      1.0765, 0.9762, 0.9285, 1.0766, 1.0238, 0.9269, 0.9756, 0.9770, 1.0165,\n",
       "                      0.9310, 1.0776, 0.9757, 0.9280, 0.9759, 1.0781, 1.0702, 1.0785, 1.0782,\n",
       "                      0.9257, 0.9224, 0.9782, 0.9272, 1.0739, 0.9781, 1.0782, 1.0776, 0.9251,\n",
       "                      0.9275, 0.9950, 0.9191, 0.9995, 1.0774, 1.0773, 1.0245, 1.0240, 0.9295,\n",
       "                      0.9280, 1.0244, 1.0714, 1.0119, 1.0794, 0.9205, 0.9762, 1.0234, 1.0783,\n",
       "                      0.9210, 0.9783, 1.0003, 1.0762, 1.0799, 0.9267, 0.9281, 1.0788, 0.9238,\n",
       "                      1.0798, 1.0776, 0.9920, 0.9784, 1.0078, 0.9782, 1.0160, 0.9763, 0.9264,\n",
       "                      1.0779, 1.0781, 0.9352, 0.9767, 1.0778, 1.0778, 0.9262, 1.0087, 0.9286,\n",
       "                      0.9841, 1.0764, 1.0049, 0.9873, 1.0774, 1.0158, 0.9759, 0.9758, 0.9168,\n",
       "                      1.0754, 0.9153, 0.9756, 0.9767, 0.9757, 1.0173, 0.9766, 1.0839, 1.0241,\n",
       "                      1.0240, 1.0795, 0.9260, 1.0238, 1.0145, 0.9762, 0.9522, 1.0132, 0.9760,\n",
       "                      0.9758, 1.0758, 0.9235, 0.9236, 0.9764, 0.9267, 0.9212, 0.9780, 0.9286,\n",
       "                      1.0776, 1.0735, 0.9249, 1.0226, 0.9764, 1.0774, 0.9244, 1.0166, 1.0794,\n",
       "                      1.0764, 0.9780, 1.0232, 1.0210, 0.9782, 0.9293, 0.9243, 1.0783, 0.9252,\n",
       "                      1.0770, 1.0088, 0.9956, 0.9246, 1.0033, 1.0089, 0.9298, 0.9839, 0.9303,\n",
       "                      0.9778, 1.0771, 0.9761, 1.0788, 0.9740, 1.0215, 1.0784, 1.0740, 0.9769,\n",
       "                      1.0082, 0.9336, 0.9271, 1.0229, 1.0136, 0.9251, 1.0193, 1.0756, 1.0786,\n",
       "                      1.0240, 0.9769, 1.0188, 1.0226, 1.0785, 1.0792, 0.9233, 1.0242, 0.9298,\n",
       "                      0.9288, 1.0113, 0.9765, 0.9820, 1.0144, 1.0182, 1.0780, 0.9249, 1.0771,\n",
       "                      1.0066, 1.0809, 0.9766, 0.9710, 1.0709, 1.0772, 0.9171, 1.0785, 1.0010,\n",
       "                      0.9183, 1.0880, 0.9780, 1.0765, 0.9761, 0.9753, 0.9862, 1.0773, 0.9899,\n",
       "                      0.9292, 0.9765, 1.0236, 1.0787, 1.0776, 0.9198, 0.9253, 1.0002, 1.0244,\n",
       "                      1.0765, 1.0824, 0.9677, 0.9728, 0.9762, 1.0210, 1.0800, 1.0782, 1.0204,\n",
       "                      0.9717, 0.9237, 1.0784, 0.9981, 0.9243, 0.9754, 0.9786, 0.9760, 0.9250,\n",
       "                      0.9762, 1.0782, 0.9892, 0.9304, 0.9759, 0.9237, 1.0063, 0.9834, 1.0255,\n",
       "                      1.0778, 0.9219, 0.9264, 1.0238, 0.9245, 1.0726, 0.9754, 0.9721],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm2.bias',\n",
       "              tensor([ 0.0246, -0.0226,  0.0773,  0.0211, -0.0838, -0.0819,  0.0793, -0.0833,\n",
       "                       0.0762, -0.0240, -0.0229, -0.0816, -0.0877,  0.0769,  0.0199, -0.0218,\n",
       "                       0.0226,  0.0766, -0.0877, -0.0241, -0.0231,  0.0780,  0.0779,  0.0223,\n",
       "                      -0.0833, -0.0242, -0.0815,  0.0769,  0.0788,  0.0777, -0.0861,  0.0784,\n",
       "                       0.0769, -0.0241,  0.0731,  0.0242,  0.0756,  0.0243, -0.0835,  0.0789,\n",
       "                      -0.0228,  0.0241, -0.0225,  0.0235,  0.0240, -0.0221, -0.0083,  0.0245,\n",
       "                      -0.0772,  0.0790,  0.0174, -0.0243, -0.0239, -0.0871, -0.0245, -0.0878,\n",
       "                      -0.0826,  0.0800,  0.0248, -0.0808,  0.0786, -0.0834,  0.0779, -0.0876,\n",
       "                       0.0234,  0.0233,  0.0785, -0.0863,  0.0237, -0.0876,  0.0245, -0.0812,\n",
       "                       0.0236, -0.0806,  0.0223, -0.0023, -0.0228, -0.0866,  0.0769,  0.0180,\n",
       "                       0.0773,  0.0781,  0.0794,  0.0243, -0.0229,  0.0753,  0.0774,  0.0242,\n",
       "                      -0.0227, -0.0245,  0.0243, -0.0814,  0.0236,  0.0064,  0.0243, -0.0246,\n",
       "                      -0.0830, -0.0257,  0.0777,  0.0802,  0.0796,  0.0782, -0.0843,  0.0790,\n",
       "                       0.0771, -0.0246,  0.0247, -0.0243, -0.0855,  0.0227, -0.0821, -0.0801,\n",
       "                      -0.0878, -0.0236, -0.0817, -0.0234, -0.0860,  0.0214,  0.0161,  0.0191,\n",
       "                      -0.0219, -0.0867,  0.0230, -0.0230,  0.0792, -0.0244, -0.0236,  0.0238,\n",
       "                       0.0239, -0.0242, -0.0241, -0.0877, -0.0242, -0.0234, -0.0241,  0.0747,\n",
       "                       0.0759, -0.0231, -0.0772,  0.0241,  0.0747, -0.0864, -0.0818, -0.0836,\n",
       "                       0.0781,  0.0221,  0.0243,  0.0765,  0.0242, -0.0243,  0.0794, -0.0815,\n",
       "                      -0.0243, -0.0875, -0.0224,  0.0243,  0.0781,  0.0783,  0.0788,  0.0752,\n",
       "                      -0.0246,  0.0226, -0.0233, -0.0227,  0.0125, -0.0234,  0.0763,  0.0787,\n",
       "                      -0.0875,  0.0188, -0.0877, -0.0240, -0.0837, -0.0238,  0.0828, -0.0869,\n",
       "                       0.0784, -0.0868, -0.0223,  0.0201, -0.0231, -0.0847, -0.0878,  0.0782,\n",
       "                      -0.0876,  0.0775, -0.0235,  0.0239,  0.0243, -0.0864, -0.0842,  0.0219,\n",
       "                       0.0831,  0.0224,  0.0239, -0.0834,  0.0784, -0.0239,  0.0779,  0.0239,\n",
       "                       0.0187, -0.0805, -0.0818,  0.0780,  0.0236,  0.0220, -0.0240,  0.0777,\n",
       "                       0.0239, -0.0829, -0.0877,  0.0723,  0.0771, -0.0222,  0.0229, -0.0878,\n",
       "                       0.0759,  0.0782,  0.0800, -0.0222,  0.0776, -0.0786, -0.0831,  0.0766,\n",
       "                       0.0761,  0.0243, -0.0875,  0.0782,  0.0782,  0.0244, -0.0838, -0.0234,\n",
       "                       0.0776, -0.0243,  0.0241,  0.0226, -0.0230, -0.0877, -0.0225, -0.0242,\n",
       "                       0.0239, -0.0231, -0.0243,  0.0791,  0.0215,  0.0783,  0.0744,  0.0754,\n",
       "                       0.0200,  0.0244,  0.0238,  0.0210, -0.0240, -0.0237, -0.0819,  0.0780,\n",
       "                       0.0786, -0.0236,  0.0784, -0.0232, -0.0877, -0.0849, -0.0848,  0.0774,\n",
       "                       0.0788, -0.0803,  0.0767,  0.0788, -0.0238,  0.0746, -0.0828,  0.0237,\n",
       "                      -0.0232,  0.0232,  0.0231, -0.0244,  0.0241, -0.0231,  0.0772, -0.0853,\n",
       "                       0.0239, -0.0226,  0.0779, -0.0235, -0.0231,  0.0244,  0.0242, -0.0859,\n",
       "                      -0.0216,  0.0781,  0.0244, -0.0238,  0.0228,  0.0788,  0.0760,  0.0774,\n",
       "                       0.0758, -0.0233, -0.0329,  0.0241, -0.0240,  0.0771, -0.0196,  0.0780,\n",
       "                       0.0787, -0.0239, -0.0246, -0.0868,  0.0243, -0.0877,  0.0775,  0.0768,\n",
       "                      -0.0242, -0.0244, -0.0232, -0.0243, -0.0242,  0.0774, -0.0846, -0.0808,\n",
       "                      -0.0238,  0.0241, -0.0820, -0.0840, -0.0225, -0.0239, -0.0231,  0.0768,\n",
       "                       0.0795, -0.0226, -0.0242,  0.0785, -0.0240,  0.0799,  0.0773, -0.0874,\n",
       "                      -0.0085, -0.0872,  0.0228, -0.0852,  0.0229, -0.0231,  0.0789,  0.0789,\n",
       "                      -0.0228, -0.0242,  0.0782,  0.0790, -0.0244, -0.0827, -0.0232, -0.0876,\n",
       "                       0.0775, -0.0871, -0.0877,  0.0779, -0.0835,  0.0235,  0.0239,  0.0785,\n",
       "                       0.0757,  0.0241,  0.0242,  0.0231,  0.0213, -0.0861,  0.0241, -0.0250,\n",
       "                      -0.0779, -0.0836,  0.0797, -0.0219, -0.0832, -0.0825,  0.0241, -0.0239,\n",
       "                      -0.0875,  0.0228, -0.0224,  0.0762, -0.0244, -0.0231, -0.0244, -0.0220,\n",
       "                       0.0875, -0.0239, -0.0240,  0.0779,  0.0781, -0.0228, -0.0843,  0.0212,\n",
       "                       0.0778, -0.0243, -0.0866,  0.0794,  0.0776, -0.0220, -0.0757, -0.0825,\n",
       "                      -0.0236, -0.0228, -0.0227,  0.0794,  0.0698,  0.0784, -0.0870,  0.0213,\n",
       "                      -0.0235, -0.0849, -0.0855, -0.0230, -0.0874, -0.0227,  0.0233, -0.0800,\n",
       "                       0.0214,  0.0780, -0.0062, -0.0830,  0.0781,  0.0775, -0.0244, -0.0877,\n",
       "                      -0.0222, -0.0225, -0.0852, -0.0872, -0.0225, -0.0823,  0.0770,  0.0778,\n",
       "                      -0.0820,  0.0216, -0.0875, -0.0846, -0.0232,  0.0790,  0.0238, -0.0817,\n",
       "                      -0.0230, -0.0227, -0.0852,  0.0181,  0.0196, -0.0872, -0.0828,  0.0759,\n",
       "                      -0.0227,  0.0779, -0.0877,  0.0795,  0.0240, -0.0869,  0.0774,  0.0777,\n",
       "                       0.0030,  0.0793, -0.0864,  0.0795, -0.0226,  0.0233,  0.0788,  0.0242,\n",
       "                       0.0165, -0.0861,  0.0771, -0.0521, -0.0234,  0.0240, -0.0816,  0.0780,\n",
       "                       0.0778, -0.0226, -0.0243, -0.0878,  0.0785,  0.0743, -0.0832, -0.0247,\n",
       "                      -0.0242,  0.0244, -0.0863,  0.0795,  0.0790, -0.0830,  0.0243, -0.0235,\n",
       "                       0.0782, -0.0865,  0.0242,  0.0748,  0.0224,  0.0224, -0.0233,  0.0219,\n",
       "                       0.0780, -0.0853, -0.0241,  0.0240, -0.0237, -0.0820, -0.0877,  0.0782,\n",
       "                       0.0801, -0.0227, -0.0224,  0.0768, -0.0233,  0.0776,  0.0232, -0.0242],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv3.weight',\n",
       "              tensor([[[ 0.1002,  0.0548,  0.0282],\n",
       "                       [-0.0100, -0.0364, -0.0845],\n",
       "                       [-0.0114, -0.0927, -0.0775],\n",
       "                       ...,\n",
       "                       [-0.0671, -0.0481, -0.0893],\n",
       "                       [ 0.0235,  0.0652,  0.0206],\n",
       "                       [-0.0141, -0.0587, -0.1001]],\n",
       "              \n",
       "                      [[-0.0837, -0.0724, -0.0895],\n",
       "                       [ 0.0088,  0.0147, -0.0036],\n",
       "                       [ 0.0919,  0.0740,  0.0893],\n",
       "                       ...,\n",
       "                       [ 0.0780,  0.0554,  0.0553],\n",
       "                       [-0.1123, -0.0957, -0.0629],\n",
       "                       [ 0.0379,  0.0174, -0.0025]],\n",
       "              \n",
       "                      [[ 0.0252,  0.0958,  0.0613],\n",
       "                       [-0.0013, -0.0030, -0.0021],\n",
       "                       [-0.0240, -0.0445, -0.0103],\n",
       "                       ...,\n",
       "                       [-0.0665, -0.0382, -0.0355],\n",
       "                       [ 0.0796,  0.0735,  0.0548],\n",
       "                       [ 0.0024, -0.0030, -0.0489]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0306,  0.0352,  0.0177],\n",
       "                       [-0.0577, -0.0959, -0.0768],\n",
       "                       [-0.0873, -0.0587, -0.0895],\n",
       "                       ...,\n",
       "                       [-0.0350, -0.0031, -0.0377],\n",
       "                       [ 0.0335,  0.0134,  0.0305],\n",
       "                       [-0.0928, -0.0953, -0.0782]],\n",
       "              \n",
       "                      [[-0.1033, -0.0817, -0.1012],\n",
       "                       [ 0.0025,  0.0304,  0.0080],\n",
       "                       [ 0.0798,  0.0735,  0.1104],\n",
       "                       ...,\n",
       "                       [ 0.0787,  0.0561,  0.0900],\n",
       "                       [-0.0845, -0.0978, -0.0997],\n",
       "                       [ 0.0217,  0.0184,  0.0384]],\n",
       "              \n",
       "                      [[ 0.0901,  0.0764,  0.0266],\n",
       "                       [-0.0289, -0.0544, -0.0393],\n",
       "                       [-0.0761, -0.0404, -0.0146],\n",
       "                       ...,\n",
       "                       [-0.0963, -0.0056, -0.0781],\n",
       "                       [ 0.0173,  0.0589,  0.0666],\n",
       "                       [-0.0995, -0.0390, -0.0336]]], device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv3.bias',\n",
       "              tensor([-2.3443e-03,  1.1065e-01, -8.8695e-02, -9.1538e-02, -1.0077e-01,\n",
       "                      -9.0861e-02, -4.3892e-02,  5.7841e-03, -7.6262e-02,  9.5923e-02,\n",
       "                      -1.0266e-01, -7.1783e-02, -7.3740e-02, -6.6416e-02, -1.0287e-01,\n",
       "                       1.0574e-01, -1.0299e-01,  7.6603e-02,  9.3499e-02, -1.8444e-02,\n",
       "                       9.6692e-02,  1.0132e-01, -1.6269e-02, -5.1279e-02, -1.5576e-02,\n",
       "                      -8.3187e-02,  9.8423e-02, -4.3797e-02, -7.2415e-03, -5.6179e-02,\n",
       "                      -2.7654e-02,  1.0400e-01, -6.5049e-02,  9.4818e-02,  2.0314e-02,\n",
       "                      -1.0807e-01,  8.4024e-02, -1.8097e-02,  7.5889e-02,  8.8161e-02,\n",
       "                       9.9044e-02, -6.2905e-02,  8.5092e-04,  8.3263e-02,  6.8137e-02,\n",
       "                       6.6142e-02,  6.5240e-02,  7.1836e-02, -5.9362e-02,  2.9185e-05,\n",
       "                       9.3285e-02, -7.7406e-02,  9.9097e-02, -3.3344e-03, -5.9894e-02,\n",
       "                       8.6551e-02, -5.5496e-03,  3.6318e-02, -4.5112e-02, -1.9954e-02,\n",
       "                      -2.5804e-02, -6.7004e-02, -9.3877e-02,  1.0407e-01, -6.2132e-02,\n",
       "                      -4.6990e-02, -5.2293e-02, -9.8449e-02,  1.1047e-01, -2.9976e-02,\n",
       "                       9.6229e-02, -2.9591e-03,  6.5179e-02,  1.0462e-01,  4.0737e-02,\n",
       "                      -8.2200e-02, -6.0421e-02,  8.2454e-02,  8.9967e-02,  5.1202e-02,\n",
       "                      -8.1078e-02, -7.8705e-02, -9.7603e-02, -6.9225e-02, -7.7913e-02,\n",
       "                      -9.5217e-02,  8.9091e-02, -2.5758e-02, -9.7922e-02, -2.8472e-02,\n",
       "                      -8.7718e-02, -5.3106e-02,  8.4875e-02, -7.9959e-02, -2.0050e-02,\n",
       "                      -9.9997e-02, -5.9345e-03, -6.6174e-02,  7.3023e-02, -9.1909e-02,\n",
       "                      -1.7923e-02, -7.0884e-02,  4.7990e-03, -2.6510e-02, -3.8808e-02,\n",
       "                      -1.0280e-01, -2.5019e-02, -2.3972e-02, -4.1902e-02,  1.0460e-01,\n",
       "                      -9.9889e-03,  1.0202e-01, -7.2400e-02, -9.2863e-02,  9.3197e-02,\n",
       "                      -7.8424e-02,  8.7837e-02, -7.8636e-02, -8.1583e-02,  8.0071e-02,\n",
       "                      -5.7771e-02,  6.2592e-02, -6.0054e-02, -9.6226e-03, -9.0330e-02,\n",
       "                      -8.1257e-02, -9.6281e-02,  7.1664e-03, -7.5487e-02, -2.7845e-02,\n",
       "                      -6.6546e-02, -2.8603e-02, -7.4180e-02, -6.9465e-02, -5.2820e-02,\n",
       "                      -3.9460e-02, -1.6517e-02, -9.0361e-02,  4.8394e-03, -1.0814e-02,\n",
       "                      -7.0256e-02, -8.3577e-02, -9.7775e-02, -5.7168e-02, -1.1747e-02,\n",
       "                      -8.7237e-02, -7.8731e-02,  2.0934e-02,  2.5385e-02, -5.8743e-02,\n",
       "                      -6.4942e-02, -8.0042e-02, -9.2293e-02,  6.8430e-02, -8.0640e-02,\n",
       "                      -1.1062e-01, -8.5356e-02, -3.0981e-02, -4.5023e-02,  6.0964e-03,\n",
       "                       9.3185e-02,  6.8223e-02, -4.7328e-02, -1.0052e-01, -8.9880e-02,\n",
       "                      -9.3603e-02, -7.6608e-02, -4.6660e-02, -2.5718e-02,  9.1502e-02,\n",
       "                      -5.6924e-02, -9.2832e-02, -8.6511e-02, -1.0238e-02, -3.5378e-02,\n",
       "                      -6.1152e-02,  9.6529e-02,  9.6995e-02, -1.0714e-01, -9.1629e-02,\n",
       "                       1.1090e-01, -5.4824e-02,  8.6057e-02, -8.1576e-02, -6.9254e-02,\n",
       "                      -3.3758e-02,  1.1233e-01, -5.0340e-02,  7.2754e-02, -1.3012e-02,\n",
       "                       7.4628e-02, -7.2062e-02, -7.9765e-02, -8.4331e-02, -7.4527e-02,\n",
       "                      -9.0613e-02, -6.7606e-02, -3.2853e-02, -8.1204e-02, -7.2685e-03,\n",
       "                      -6.6798e-02,  7.5353e-03, -9.9355e-02,  1.0109e-02, -7.4683e-04,\n",
       "                      -6.0102e-02,  1.0845e-01, -2.2934e-02, -8.0608e-02, -9.1700e-02,\n",
       "                      -5.7806e-02,  7.4223e-02,  1.0953e-01,  8.8808e-02, -5.1579e-02,\n",
       "                      -4.2421e-02,  8.3691e-02, -9.6843e-02,  6.6228e-02, -2.2418e-02,\n",
       "                      -6.5977e-02,  6.0900e-02,  9.8393e-02, -5.8232e-02, -4.5542e-02,\n",
       "                       6.2238e-02,  7.5304e-02, -5.4905e-03,  6.5586e-02, -5.9882e-03,\n",
       "                      -8.0716e-02, -9.3380e-03, -6.1771e-02,  7.0441e-02, -2.7072e-02,\n",
       "                      -5.5538e-02, -4.5991e-02, -1.3920e-03, -5.3458e-02, -7.8791e-02,\n",
       "                      -4.9349e-02,  3.4921e-02, -9.8754e-02, -5.2511e-02, -1.7527e-02,\n",
       "                      -8.5461e-02, -7.7427e-02, -5.7001e-02, -6.7360e-02, -8.0489e-02,\n",
       "                      -2.4533e-02,  1.7445e-02, -9.2956e-02,  6.5791e-02, -1.0918e-01,\n",
       "                      -7.7747e-02, -3.1358e-03, -2.2471e-03,  6.3809e-02, -1.0079e-01,\n",
       "                      -7.7621e-02, -6.2924e-02, -8.3384e-03,  8.5172e-02, -9.2696e-02,\n",
       "                      -8.2416e-03, -8.2206e-02,  9.1085e-02, -9.0482e-02, -3.8272e-02,\n",
       "                      -5.3996e-02,  8.6246e-02,  6.1954e-02,  1.0405e-01, -5.0423e-02,\n",
       "                      -7.0726e-02, -7.3932e-05, -1.7130e-02, -8.6685e-02, -2.9916e-02,\n",
       "                       7.5967e-02,  7.7149e-02, -6.1393e-02, -6.3507e-02, -7.2977e-02,\n",
       "                      -7.4705e-02, -7.2114e-02, -7.5421e-02,  8.4844e-02, -6.4411e-02,\n",
       "                       2.6589e-03,  5.0234e-02, -1.3395e-02, -8.8859e-02, -7.4602e-02,\n",
       "                       8.9085e-02, -6.1952e-02, -2.8929e-02, -2.0831e-02, -9.3993e-02,\n",
       "                       1.0781e-01, -7.2602e-02, -8.3216e-02, -7.8961e-02,  6.8742e-02,\n",
       "                      -9.0375e-02, -1.6388e-02,  7.8199e-02,  7.4107e-02, -7.4370e-03,\n",
       "                      -7.7965e-02, -4.1596e-02,  6.7115e-02, -4.6340e-02,  8.5612e-02,\n",
       "                      -1.2290e-02, -7.6639e-02, -6.5677e-02, -9.7231e-02, -2.8724e-02,\n",
       "                      -7.9671e-02, -2.5538e-02, -1.6586e-02, -8.6137e-03,  2.8002e-03,\n",
       "                       6.2506e-02,  7.1164e-02, -6.2857e-02, -7.2826e-03, -9.3184e-02,\n",
       "                      -9.5044e-02, -9.3762e-02, -7.9051e-02,  1.0453e-01,  8.4681e-02,\n",
       "                       6.7614e-02, -3.1756e-02,  9.4649e-02,  5.8189e-03,  1.0044e-01,\n",
       "                      -7.3536e-02, -3.1825e-02,  6.9037e-02, -7.4413e-02,  6.6410e-02,\n",
       "                      -6.1437e-02,  9.8416e-02, -5.5028e-02, -7.8242e-02, -1.0450e-01,\n",
       "                       9.8085e-02,  8.3093e-02,  1.2898e-02, -7.7048e-02, -1.4545e-02,\n",
       "                       7.3115e-02, -7.9273e-02, -7.2988e-02,  7.5961e-02,  7.0049e-02,\n",
       "                      -3.7595e-02,  6.5714e-02,  7.8287e-03, -5.9878e-02, -6.5625e-02,\n",
       "                       9.6071e-02, -5.1669e-02,  7.6720e-02, -8.3844e-02,  4.5041e-02,\n",
       "                      -6.0676e-02, -5.7611e-02, -5.4870e-02, -4.3285e-04, -9.7143e-02,\n",
       "                      -9.0704e-02, -5.3505e-02, -2.3822e-02,  8.6549e-02, -5.6821e-02,\n",
       "                       7.9436e-02, -3.4324e-02, -8.9496e-02, -3.2173e-02,  9.6059e-02,\n",
       "                      -7.1682e-02, -6.8938e-02, -2.5307e-02,  3.9142e-02, -9.8744e-02,\n",
       "                       8.8073e-02, -7.1215e-02, -4.1120e-02,  9.5001e-02, -3.4195e-02,\n",
       "                      -1.0749e-01,  7.6018e-02,  6.3532e-02, -3.5021e-02, -8.6960e-02,\n",
       "                      -5.6401e-02, -7.0652e-02,  8.3773e-02, -6.3873e-02, -2.5145e-02,\n",
       "                       6.2996e-02,  1.0193e-01, -5.1517e-02, -1.9750e-02, -1.0464e-01,\n",
       "                      -8.6907e-02,  9.2495e-02, -8.2736e-03,  8.0431e-02, -7.1333e-02,\n",
       "                       9.4055e-02, -6.4505e-03, -8.0869e-02, -1.1102e-01, -1.0579e-01,\n",
       "                      -3.1934e-02, -3.7398e-02, -8.7405e-02, -3.2522e-02, -1.8777e-02,\n",
       "                      -9.7815e-02, -7.0738e-03,  7.1054e-02, -1.6181e-02,  5.5944e-02,\n",
       "                      -2.2486e-02, -4.4082e-02, -1.0233e-01, -8.3473e-02, -8.9223e-02,\n",
       "                      -1.0577e-03, -4.2979e-02, -1.3149e-02, -9.8877e-02, -8.0047e-02,\n",
       "                      -2.5365e-02, -3.0205e-02, -7.5650e-02, -4.6294e-02,  9.5897e-02,\n",
       "                       8.9161e-02,  1.0317e-01, -8.9295e-02, -4.6300e-02, -4.1384e-02,\n",
       "                      -7.7046e-02, -7.1379e-02, -9.2940e-02, -1.0107e-01, -2.0003e-02,\n",
       "                       8.3808e-02,  4.2797e-03, -5.0824e-02,  3.1171e-02, -5.5629e-02,\n",
       "                      -9.9826e-02, -8.4054e-02, -6.7284e-02,  1.0666e-01,  1.0747e-01,\n",
       "                      -7.6902e-02, -9.6905e-02, -9.8816e-02,  2.0847e-02, -9.3319e-02,\n",
       "                       6.2165e-02,  1.0248e-01, -7.1185e-02,  8.0992e-02,  1.0146e-01,\n",
       "                      -9.3857e-02, -1.1228e-01, -7.5934e-02, -2.3830e-02, -4.3209e-02,\n",
       "                       8.6965e-02, -6.9922e-02, -4.8467e-02, -3.6766e-02, -6.5744e-02,\n",
       "                       5.8170e-02, -6.7260e-02,  2.7793e-02,  9.1410e-02, -7.6245e-02,\n",
       "                      -2.6750e-02, -4.4267e-02,  1.9313e-04,  8.3243e-02,  8.2665e-02,\n",
       "                      -7.5833e-02, -6.4959e-02, -8.3615e-02, -3.2805e-02, -1.4416e-02,\n",
       "                      -6.6431e-02, -5.1802e-02, -3.5503e-02, -8.4445e-02,  1.0472e-01,\n",
       "                      -1.4607e-02, -4.2366e-02,  8.5398e-02,  9.7535e-02, -7.6508e-03,\n",
       "                       9.2520e-02, -9.9728e-02], device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm3.weight',\n",
       "              tensor([0.9213, 1.0822, 0.9336, 0.9129, 1.0812, 0.9747, 0.9349, 0.9256, 0.9188,\n",
       "                      1.0772, 0.9797, 0.9678, 0.9783, 0.9513, 0.9122, 0.9886, 1.0791, 1.0805,\n",
       "                      1.0775, 0.9291, 1.0761, 1.0274, 0.9215, 0.9865, 0.9302, 0.9338, 1.0785,\n",
       "                      0.9345, 0.9777, 0.9773, 0.9139, 1.0776, 0.9398, 1.0750, 0.9205, 1.0031,\n",
       "                      0.9224, 0.9780, 1.0793, 1.0831, 1.0794, 0.9961, 0.9764, 1.0771, 1.0675,\n",
       "                      1.0861, 0.9950, 1.0814, 0.9764, 0.9178, 1.0842, 0.9769, 1.0788, 1.0832,\n",
       "                      0.9774, 0.9163, 0.9234, 0.9365, 0.9332, 1.0237, 0.9220, 1.0848, 0.9929,\n",
       "                      1.0822, 0.9248, 0.9822, 0.9764, 1.0167, 1.0800, 0.9166, 1.0814, 0.9799,\n",
       "                      1.0778, 0.9942, 0.9977, 1.0832, 0.9859, 0.9765, 1.0740, 1.0076, 1.0805,\n",
       "                      0.9195, 0.9211, 0.9776, 1.0235, 1.0775, 1.0794, 0.9388, 1.0137, 0.9208,\n",
       "                      0.9948, 0.9161, 0.9923, 0.9421, 0.9215, 1.0250, 0.9226, 0.9492, 1.0799,\n",
       "                      1.0800, 0.9216, 0.9803, 0.9503, 0.9226, 1.0699, 1.0256, 0.9268, 1.0815,\n",
       "                      0.9196, 1.0834, 0.9272, 1.0789, 1.0791, 0.9212, 1.0800, 1.0239, 0.9219,\n",
       "                      0.9634, 1.0040, 0.9905, 0.9418, 1.0203, 0.9195, 0.9172, 0.9552, 0.9131,\n",
       "                      0.9405, 0.9164, 1.0793, 0.9204, 1.0217, 0.9120, 0.9303, 0.9777, 0.9829,\n",
       "                      0.9234, 0.9763, 0.9158, 0.9279, 1.0249, 0.9776, 0.9121, 0.9174, 0.9158,\n",
       "                      0.9206, 0.9944, 0.9420, 1.0715, 0.9190, 0.9161, 1.0068, 0.9179, 0.9863,\n",
       "                      1.0870, 0.9173, 1.0076, 0.9362, 0.9265, 0.9683, 0.9237, 1.0729, 1.0793,\n",
       "                      1.0224, 1.0854, 1.0006, 0.9781, 0.9764, 0.9957, 0.9250, 1.0800, 0.9164,\n",
       "                      0.9212, 0.9554, 0.9238, 0.9740, 0.9216, 1.0793, 1.0770, 1.0815, 1.0167,\n",
       "                      1.0827, 0.9280, 1.0776, 0.9559, 0.9139, 0.9268, 1.0792, 0.9406, 1.0825,\n",
       "                      0.9749, 1.0786, 1.0827, 0.9674, 0.9559, 1.0109, 0.9845, 1.0238, 0.9224,\n",
       "                      0.9903, 0.9244, 0.9329, 1.0317, 1.0801, 0.9377, 0.9793, 1.0859, 1.0785,\n",
       "                      0.9778, 0.9163, 0.9739, 1.0815, 1.0225, 1.0778, 1.0775, 0.9785, 0.9123,\n",
       "                      1.0823, 1.0862, 1.0877, 0.9224, 1.0794, 1.0789, 1.0791, 0.9509, 0.9268,\n",
       "                      1.0806, 1.0781, 0.9245, 0.9919, 0.9900, 1.0797, 0.9691, 0.9762, 1.0807,\n",
       "                      0.9763, 0.9246, 0.9239, 0.9317, 0.9726, 0.9129, 0.9358, 1.0253, 0.9149,\n",
       "                      0.9770, 0.9328, 0.9124, 1.0864, 0.9692, 1.0048, 1.0221, 0.9139, 0.9287,\n",
       "                      0.9759, 0.9314, 1.0830, 1.0783, 0.9352, 0.9238, 1.0802, 1.0162, 0.9657,\n",
       "                      1.0236, 0.9518, 1.0350, 0.9205, 0.9763, 0.9207, 1.0799, 0.9990, 0.9774,\n",
       "                      0.9276, 0.9199, 1.0874, 1.0793, 0.9424, 0.9793, 0.9209, 0.9291, 0.9152,\n",
       "                      1.0046, 1.0829, 1.0881, 0.9802, 0.9786, 0.9784, 0.9570, 0.9318, 0.9128,\n",
       "                      1.0762, 0.9761, 0.9366, 0.9974, 1.0188, 0.9325, 0.9758, 1.0772, 0.9779,\n",
       "                      0.9787, 1.0172, 1.0860, 1.0740, 1.0197, 0.9786, 1.0796, 1.0754, 0.9799,\n",
       "                      0.9228, 0.9809, 1.0842, 0.9207, 0.9733, 0.9289, 1.0822, 0.9766, 1.0821,\n",
       "                      0.9233, 0.9400, 0.9180, 0.9872, 0.9320, 1.0190, 1.0222, 0.9764, 0.9214,\n",
       "                      0.9227, 1.0877, 1.0779, 0.9557, 0.9764, 0.9886, 0.9161, 0.9764, 1.0109,\n",
       "                      1.0809, 1.0818, 1.0834, 0.9209, 1.0836, 0.9707, 1.0753, 1.0103, 0.9226,\n",
       "                      1.0305, 1.0160, 1.0782, 0.9205, 1.0831, 1.0107, 0.9906, 1.0166, 1.0778,\n",
       "                      1.0894, 0.9282, 0.9647, 0.9261, 0.9917, 0.9984, 0.9238, 1.0778, 1.0797,\n",
       "                      0.9886, 1.0792, 0.9266, 0.9810, 1.0833, 1.0451, 0.9780, 1.0852, 0.9767,\n",
       "                      1.0255, 0.9130, 1.0795, 0.9247, 0.9163, 0.9710, 0.9180, 0.9771, 0.9300,\n",
       "                      1.0569, 0.9401, 1.0155, 0.9784, 1.0785, 0.9769, 1.0796, 0.9477, 0.9713,\n",
       "                      0.9217, 0.9806, 1.0796, 1.0843, 0.9694, 0.9762, 1.0199, 1.0234, 1.0822,\n",
       "                      1.0777, 1.0783, 0.9778, 1.0078, 0.9135, 1.0430, 1.0840, 0.9768, 0.9767,\n",
       "                      1.0795, 1.0798, 0.9781, 0.9160, 0.9585, 0.9781, 1.0870, 0.9303, 1.0784,\n",
       "                      0.9691, 1.0876, 0.9263, 1.0859, 0.9758, 0.9997, 0.9209, 0.9766, 0.9168,\n",
       "                      0.9773, 0.9216, 1.0810, 0.9252, 1.0795, 0.9756, 1.0294, 0.9219, 0.9800,\n",
       "                      0.9236, 1.0839, 0.9131, 1.0233, 0.9753, 0.9226, 0.9801, 0.9121, 0.9241,\n",
       "                      0.9768, 0.9166, 0.9770, 0.9814, 0.9841, 0.9789, 0.9758, 0.9292, 0.9319,\n",
       "                      1.0005, 0.9337, 0.9780, 0.9799, 0.9212, 1.0756, 1.0198, 0.9137, 0.9841,\n",
       "                      0.9918, 0.9128, 1.0239, 0.9783, 1.0760, 1.0803, 1.0799, 0.9775, 0.9791,\n",
       "                      0.9108, 0.9182, 1.0787, 1.0791, 0.9750, 1.0795, 1.0843, 0.9728, 0.9770,\n",
       "                      1.0224, 0.9242, 0.9250, 1.0795, 0.9374, 0.9244, 0.9308, 0.9336, 1.0747,\n",
       "                      0.9676, 0.9790, 1.0854, 0.9754, 0.9177, 0.9416, 0.9246, 0.9896, 1.0875,\n",
       "                      0.9779, 0.9145, 1.0000, 0.9320, 0.9207, 0.9767, 0.9768, 0.9759, 0.9364,\n",
       "                      1.0801, 0.9352, 0.9289, 1.0827, 1.0785, 0.9190, 1.0768, 0.9218],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm3.bias',\n",
       "              tensor([-0.0244,  0.0802, -0.0183,  0.0173, -0.0785, -0.0721, -0.0449, -0.0216,\n",
       "                       0.0058,  0.0781,  0.0230, -0.0832, -0.0040, -0.0731,  0.0747,  0.0805,\n",
       "                      -0.0816,  0.0798,  0.0790,  0.0231,  0.0802,  0.0760, -0.0229, -0.0786,\n",
       "                      -0.0210, -0.0347,  0.0810, -0.0562, -0.0200,  0.0208,  0.0234,  0.0788,\n",
       "                      -0.0595,  0.0783, -0.0140, -0.0826,  0.0815, -0.0218,  0.0799,  0.0799,\n",
       "                       0.0796, -0.0854,  0.0235,  0.0788,  0.0763,  0.0828,  0.0821,  0.0803,\n",
       "                       0.0232, -0.0232,  0.0826,  0.0198,  0.0770, -0.0192,  0.0228,  0.0769,\n",
       "                      -0.0246, -0.0192, -0.0301, -0.0242, -0.0238, -0.0811,  0.0174,  0.0821,\n",
       "                       0.0225,  0.0029, -0.0330, -0.0830,  0.0792,  0.0459,  0.0801, -0.0209,\n",
       "                       0.0780,  0.0817,  0.0838, -0.0802, -0.0677,  0.0771,  0.0793,  0.0731,\n",
       "                      -0.0794, -0.0153,  0.0150,  0.0231, -0.0793, -0.0769,  0.0792, -0.0222,\n",
       "                      -0.0881, -0.0249, -0.0843,  0.0191,  0.0776, -0.0605,  0.0245,  0.0019,\n",
       "                      -0.0233, -0.0677,  0.0783, -0.0322, -0.0247,  0.0036, -0.0197, -0.0229,\n",
       "                      -0.0264, -0.0877, -0.0209, -0.0237, -0.0249,  0.0820, -0.0154,  0.0801,\n",
       "                      -0.0774, -0.0758,  0.0795, -0.0776,  0.0794, -0.0798, -0.0876,  0.0781,\n",
       "                      -0.0603,  0.0785,  0.0241, -0.0198, -0.0666, -0.0040, -0.0604,  0.0231,\n",
       "                      -0.0782, -0.0251, -0.0882,  0.0205, -0.0173,  0.0206, -0.0845,  0.0220,\n",
       "                       0.0234,  0.0124, -0.0231, -0.0261,  0.0228,  0.0210,  0.0137,  0.0013,\n",
       "                      -0.0250, -0.0844, -0.0620,  0.0326,  0.0240,  0.0142, -0.0876,  0.0060,\n",
       "                      -0.0880,  0.0812,  0.0142,  0.0043, -0.0581, -0.0230,  0.0233, -0.0239,\n",
       "                       0.0733,  0.0795, -0.0265, -0.0807,  0.0073, -0.0672,  0.0185, -0.0810,\n",
       "                      -0.0228,  0.0805,  0.0183,  0.0254, -0.0667, -0.0240, -0.0214,  0.0171,\n",
       "                       0.0789,  0.0770, -0.0795, -0.0879,  0.0799, -0.0203,  0.0789, -0.0745,\n",
       "                      -0.0117,  0.0221,  0.0799, -0.0618,  0.0777, -0.0246,  0.0800, -0.0843,\n",
       "                      -0.0727, -0.0729, -0.0871, -0.0800, -0.0773, -0.0217, -0.0823, -0.0227,\n",
       "                      -0.0467,  0.0853, -0.0792, -0.0226, -0.0192, -0.0846,  0.0798, -0.0214,\n",
       "                      -0.0085, -0.0664, -0.0775,  0.0788,  0.0785,  0.0788,  0.0131, -0.0078,\n",
       "                       0.0804, -0.0764,  0.0830, -0.0249, -0.0781,  0.0787,  0.0817, -0.0799,\n",
       "                      -0.0228,  0.0794,  0.0785, -0.0237,  0.0776,  0.0822, -0.0791, -0.0242,\n",
       "                       0.0200,  0.0768,  0.0236, -0.0274, -0.0238, -0.0224, -0.0763,  0.0159,\n",
       "                      -0.0502,  0.0244,  0.0055, -0.0071, -0.0227, -0.0267, -0.0825, -0.0761,\n",
       "                      -0.0877, -0.0785,  0.0236, -0.0212, -0.0782,  0.0787, -0.0794, -0.0772,\n",
       "                      -0.0201, -0.0189,  0.0802, -0.0861, -0.0724, -0.0881,  0.0800,  0.0842,\n",
       "                       0.0201,  0.0234, -0.0219,  0.0794, -0.0875, -0.0233, -0.0572,  0.0782,\n",
       "                       0.0802,  0.0790, -0.0647, -0.0512, -0.0243, -0.0203,  0.0031, -0.0165,\n",
       "                       0.0800,  0.0807,  0.0220,  0.0232,  0.0227, -0.0776, -0.0350, -0.0059,\n",
       "                       0.0777, -0.0754, -0.0190,  0.0269,  0.0911, -0.0506,  0.0225,  0.0776,\n",
       "                      -0.0444,  0.0216, -0.0258, -0.0870,  0.0781, -0.0852, -0.0742, -0.0803,\n",
       "                       0.0778,  0.0228, -0.0235,  0.0779,  0.0824, -0.0247, -0.0208, -0.0235,\n",
       "                       0.0811,  0.0233,  0.0820, -0.0232, -0.0601, -0.0377,  0.0186, -0.0163,\n",
       "                      -0.0828, -0.0233,  0.0234,  0.0240, -0.0222,  0.0783,  0.0780, -0.0775,\n",
       "                       0.0237, -0.0879,  0.0114, -0.0689, -0.0804,  0.0801,  0.0800,  0.0795,\n",
       "                      -0.0250,  0.0803, -0.0246,  0.0795, -0.0880, -0.0242,  0.0819, -0.0852,\n",
       "                       0.0806, -0.0775,  0.0803, -0.0872, -0.0862, -0.0875,  0.0790,  0.0795,\n",
       "                       0.0843, -0.0680, -0.0209,  0.0709, -0.0862, -0.0741,  0.0787,  0.0796,\n",
       "                       0.0773,  0.0791, -0.0221, -0.0004, -0.0865,  0.0798,  0.0194,  0.0806,\n",
       "                       0.0200,  0.0843,  0.0069, -0.0803, -0.0264, -0.0237, -0.0852, -0.0543,\n",
       "                       0.0221, -0.0202,  0.0794, -0.0599,  0.0793,  0.0230, -0.0779,  0.0757,\n",
       "                       0.0802, -0.0675, -0.0755, -0.0253,  0.0282, -0.0788,  0.0813, -0.0870,\n",
       "                      -0.0220,  0.0836, -0.0266, -0.0874,  0.0788,  0.0789,  0.0229, -0.0841,\n",
       "                       0.0088, -0.0322,  0.0809, -0.0664,  0.0231,  0.0800,  0.0770, -0.0553,\n",
       "                      -0.0261, -0.0863,  0.0238,  0.0828, -0.0219,  0.0812, -0.0818,  0.0821,\n",
       "                      -0.0224, -0.0804, -0.0792,  0.0139, -0.0241,  0.0234, -0.0421, -0.0238,\n",
       "                      -0.0234, -0.0782,  0.0232,  0.0810,  0.0227,  0.0863, -0.0223, -0.0553,\n",
       "                       0.0234, -0.0824, -0.0048, -0.0261,  0.0244, -0.0239,  0.0220,  0.0153,\n",
       "                      -0.0218, -0.0234,  0.0080,  0.0230,  0.0781,  0.0791,  0.0788, -0.0712,\n",
       "                      -0.0224, -0.0220,  0.0193, -0.0339,  0.0222,  0.0149, -0.0251,  0.0803,\n",
       "                       0.0814,  0.0180,  0.0798, -0.0877,  0.0175, -0.0276,  0.0136,  0.0786,\n",
       "                       0.0785, -0.0811, -0.0788,  0.0078, -0.0236,  0.0013,  0.0797,  0.0790,\n",
       "                      -0.0750,  0.0770,  0.0804, -0.0789,  0.0231, -0.0763, -0.0238, -0.0230,\n",
       "                       0.0797, -0.0540, -0.0229, -0.0221, -0.0569,  0.0782, -0.0764,  0.0240,\n",
       "                       0.0804,  0.0186, -0.0252, -0.0618, -0.0214,  0.0805,  0.0825,  0.0155,\n",
       "                      -0.0328,  0.0117, -0.0179, -0.0236,  0.0178,  0.0229,  0.0236, -0.0571,\n",
       "                       0.0785, -0.0224, -0.0213,  0.0775,  0.0775, -0.0245,  0.0803, -0.0728],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv4.weight',\n",
       "              tensor([[[-0.0381,  0.0056,  0.0003],\n",
       "                       [ 0.0868,  0.0751,  0.0627],\n",
       "                       [ 0.0212,  0.0093,  0.0109],\n",
       "                       ...,\n",
       "                       [-0.0615, -0.0571, -0.0522],\n",
       "                       [ 0.0649,  0.0440,  0.0703],\n",
       "                       [-0.0267, -0.0258, -0.0354]],\n",
       "              \n",
       "                      [[-0.0253, -0.0101, -0.0388],\n",
       "                       [ 0.0446,  0.0914,  0.0775],\n",
       "                       [-0.0009,  0.0155,  0.0025],\n",
       "                       ...,\n",
       "                       [-0.0200, -0.0330, -0.0547],\n",
       "                       [ 0.0575,  0.0751,  0.0529],\n",
       "                       [ 0.0042, -0.0270, -0.0580]],\n",
       "              \n",
       "                      [[ 0.0115,  0.0420,  0.0947],\n",
       "                       [ 0.0244,  0.0547,  0.0337],\n",
       "                       [ 0.0307,  0.0829,  0.0756],\n",
       "                       ...,\n",
       "                       [ 0.0033,  0.0537,  0.0753],\n",
       "                       [ 0.0725, -0.0016, -0.0011],\n",
       "                       [ 0.0579,  0.0710,  0.0328]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0574, -0.0214, -0.0202],\n",
       "                       [-0.0395, -0.0339, -0.0638],\n",
       "                       [-0.0838, -0.0134,  0.0013],\n",
       "                       ...,\n",
       "                       [-0.0302, -0.0436, -0.0892],\n",
       "                       [-0.0741, -0.0642, -0.0871],\n",
       "                       [-0.0705, -0.0168, -0.0798]],\n",
       "              \n",
       "                      [[ 0.0099, -0.0146,  0.0037],\n",
       "                       [ 0.0761,  0.0702,  0.0510],\n",
       "                       [-0.0134,  0.0014,  0.0058],\n",
       "                       ...,\n",
       "                       [-0.0529, -0.0344, -0.0445],\n",
       "                       [ 0.0660,  0.0905,  0.0828],\n",
       "                       [-0.0258, -0.0199, -0.0489]],\n",
       "              \n",
       "                      [[-0.0721, -0.0652,  0.0763],\n",
       "                       [ 0.0278,  0.0531,  0.0288],\n",
       "                       [-0.0812, -0.0835, -0.0066],\n",
       "                       ...,\n",
       "                       [-0.0799, -0.0657, -0.0783],\n",
       "                       [ 0.0058,  0.0327,  0.0432],\n",
       "                       [-0.0635, -0.0596, -0.0135]]], device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv4.bias',\n",
       "              tensor([ 8.3701e-02,  6.3273e-02,  3.8574e-03,  9.4504e-03, -9.6145e-02,\n",
       "                      -6.5276e-02, -9.2634e-02,  4.8820e-02,  9.4640e-02, -8.1489e-02,\n",
       "                       6.7796e-02, -9.8833e-02, -1.0972e-01,  8.1509e-02, -8.2481e-02,\n",
       "                      -8.6699e-02, -1.2728e-02, -5.7161e-02, -1.3732e-02,  1.2582e-02,\n",
       "                       4.3621e-02,  6.7617e-02,  7.4570e-02, -8.9966e-02, -6.4111e-03,\n",
       "                      -6.3517e-02, -7.6605e-02,  6.2442e-02,  2.9592e-02,  2.0512e-02,\n",
       "                      -5.0169e-02,  1.2518e-02,  3.2830e-02,  1.4962e-02,  6.3723e-02,\n",
       "                      -7.9182e-02,  2.3202e-02, -7.4906e-02,  9.6166e-02,  1.6932e-03,\n",
       "                      -9.5691e-02,  4.3871e-02,  5.0201e-02,  6.0350e-02,  4.0481e-02,\n",
       "                       1.0593e-01, -9.4181e-02,  2.9534e-02,  2.5519e-02, -2.0860e-03,\n",
       "                       6.2824e-02,  7.6511e-02,  9.6841e-02, -1.0421e-01, -4.7763e-03,\n",
       "                       6.9963e-03,  3.0523e-02,  9.0903e-02,  9.8658e-02,  1.0828e-01,\n",
       "                       4.0807e-02,  7.9328e-02, -1.0804e-01,  4.5389e-02, -9.6024e-02,\n",
       "                       8.1401e-02, -7.0210e-02,  5.1578e-02, -7.1553e-04, -1.0253e-01,\n",
       "                       3.2668e-02,  3.7896e-03,  6.0573e-02,  7.0056e-02,  3.8755e-02,\n",
       "                       6.7307e-02, -7.7500e-02,  1.8115e-03,  1.4196e-02,  3.9904e-02,\n",
       "                      -1.0017e-01,  2.4898e-02, -8.4229e-02,  8.6659e-02, -9.3709e-02,\n",
       "                      -8.0754e-02,  4.4948e-02,  8.6066e-02,  9.4629e-02, -5.6763e-02,\n",
       "                      -7.6997e-02,  3.8581e-02, -9.2995e-02,  1.5916e-02, -6.2257e-02,\n",
       "                      -1.1571e-03, -8.3611e-02,  1.9596e-03,  5.9394e-02, -6.1418e-02,\n",
       "                       8.0487e-02,  1.4228e-02,  3.9997e-02,  4.4161e-02, -4.6812e-02,\n",
       "                       4.9429e-02, -6.4394e-04,  2.4780e-02,  1.9217e-02, -2.7253e-02,\n",
       "                      -9.0069e-02,  5.6553e-02,  4.4679e-02,  7.2284e-02,  3.4611e-02,\n",
       "                      -1.0942e-01,  1.2263e-04,  2.0229e-02,  1.0293e-01,  3.3424e-02,\n",
       "                       7.4867e-02,  7.7602e-02,  9.0161e-03,  1.0029e-01,  9.7219e-02,\n",
       "                       1.0001e-01,  2.4007e-03,  5.1121e-02,  3.7367e-03,  4.3696e-02,\n",
       "                      -6.8753e-02,  4.4442e-02,  6.7678e-02,  4.1692e-02, -1.1117e-01,\n",
       "                      -1.7924e-02, -1.9703e-02, -1.0830e-01,  3.3329e-02,  9.8426e-02,\n",
       "                      -7.5969e-02, -6.8264e-02,  6.5534e-02,  3.7857e-02, -1.0239e-01,\n",
       "                      -1.0412e-01,  7.4265e-02, -1.1196e-01,  3.7624e-02,  5.7246e-02,\n",
       "                      -8.6490e-02, -8.8168e-02,  4.9670e-02,  2.5057e-02,  8.6924e-02,\n",
       "                       6.2399e-02, -7.6946e-02, -5.9782e-02,  7.6260e-02,  1.0629e-01,\n",
       "                       1.0599e-01,  3.8546e-02,  8.8054e-02,  1.9658e-02, -1.0753e-01,\n",
       "                       7.5526e-02,  6.4195e-02,  9.2933e-02,  1.3014e-02,  2.9164e-02,\n",
       "                       3.5467e-03,  6.6801e-02, -3.1995e-02,  5.9966e-02, -3.0613e-02,\n",
       "                      -6.1142e-02,  4.9344e-02,  2.1465e-02, -1.9999e-02,  8.2148e-02,\n",
       "                       6.5076e-02,  8.4736e-02, -1.0145e-01,  2.0600e-02,  1.0033e-01,\n",
       "                       6.3013e-02,  2.7940e-03, -1.9311e-03,  3.7309e-02,  3.1829e-02,\n",
       "                       3.9907e-03, -1.6058e-02,  2.2231e-02,  5.7647e-02, -7.8554e-02,\n",
       "                       3.4724e-02,  4.3726e-02, -9.1137e-02,  4.4211e-02,  3.4246e-02,\n",
       "                      -1.6899e-02, -7.4151e-02, -7.6887e-02,  6.2884e-02,  4.7909e-02,\n",
       "                       6.6356e-02,  4.5230e-02, -3.0138e-02, -8.8470e-03, -8.3404e-02,\n",
       "                       7.0030e-02, -6.4512e-03,  1.2926e-02,  2.6461e-02,  2.1138e-02,\n",
       "                       1.0647e-02,  1.1140e-01,  2.2208e-02,  2.1275e-04,  1.6284e-02,\n",
       "                       1.7845e-03, -4.0381e-02,  7.1180e-02,  1.1736e-02,  8.9763e-02,\n",
       "                      -6.7756e-02,  8.0287e-02, -8.7942e-02,  7.6339e-02, -2.2113e-02,\n",
       "                       5.6217e-02,  8.4176e-02,  2.4142e-02,  9.7630e-02, -1.0428e-01,\n",
       "                       3.2937e-02,  1.2833e-02,  6.3576e-02, -7.7131e-03,  8.2216e-02,\n",
       "                       4.1818e-02,  1.3962e-02,  8.2483e-02,  8.6262e-02,  7.6944e-02,\n",
       "                      -1.0635e-01, -6.7766e-02, -6.9657e-02, -1.0441e-01,  3.2389e-02,\n",
       "                      -6.6382e-02,  6.4926e-02, -1.8855e-02, -9.8803e-02,  9.4276e-02,\n",
       "                      -6.9523e-02,  2.2576e-02,  5.4104e-02, -8.6258e-02,  5.2118e-02,\n",
       "                      -3.6081e-02,  1.0166e-01,  3.3954e-03, -1.0039e-01,  2.2200e-02,\n",
       "                       6.9650e-02, -1.0534e-01,  7.3888e-02,  2.2597e-02,  7.9258e-04,\n",
       "                       4.9554e-03,  3.2714e-02,  1.5071e-02,  8.8758e-02, -8.5933e-02,\n",
       "                       6.8422e-02,  1.0313e-01,  7.9077e-02,  4.7488e-02, -1.0799e-01,\n",
       "                       1.0215e-01, -2.2295e-02,  8.9080e-02,  5.4903e-02,  3.7341e-03,\n",
       "                       5.3570e-02,  4.5678e-02,  8.7459e-02, -8.1639e-02,  9.0468e-02,\n",
       "                       7.1701e-02, -3.9277e-02,  5.3524e-02,  5.4088e-02, -8.6137e-02,\n",
       "                       1.7782e-02,  8.3621e-02, -7.4749e-02, -5.9777e-02,  9.9139e-02,\n",
       "                       1.6340e-02, -2.2077e-02,  1.0414e-02,  3.6908e-02, -3.7531e-02,\n",
       "                       3.0686e-02,  2.8881e-03,  6.8383e-02, -8.0720e-02,  2.8719e-02,\n",
       "                       1.3759e-02, -9.8898e-02,  8.5433e-02,  9.7003e-03, -1.0946e-01,\n",
       "                      -4.0967e-03,  9.9470e-02,  4.3874e-02,  3.6818e-02,  2.9608e-02,\n",
       "                      -8.1175e-02, -7.5046e-02,  6.5952e-02, -9.3242e-02,  3.2925e-02,\n",
       "                       2.6078e-02, -6.5158e-02, -7.4018e-02,  1.0264e-01,  1.1741e-02,\n",
       "                       8.5532e-02, -8.4481e-02,  1.2684e-03,  5.3781e-02,  8.7838e-02,\n",
       "                      -1.0943e-01,  1.7421e-02,  8.3506e-02, -6.6513e-02,  3.6305e-02,\n",
       "                       3.6500e-02,  9.0135e-02,  5.7573e-02,  3.9611e-02, -7.7103e-02,\n",
       "                       1.3010e-02,  4.1334e-02,  5.5167e-02, -6.0408e-02,  9.9025e-02,\n",
       "                       7.8845e-04,  6.2453e-02, -8.5150e-02, -2.1497e-02,  4.5422e-02,\n",
       "                      -9.7763e-02,  7.9293e-02,  7.3933e-02,  5.9939e-02,  3.4235e-02,\n",
       "                       2.6264e-02, -3.9647e-03,  5.6562e-02, -8.0073e-02, -1.0593e-01,\n",
       "                       2.7520e-02,  4.8281e-02,  1.5614e-02,  6.5838e-02, -1.0111e-01,\n",
       "                      -1.0035e-01, -1.0700e-01,  7.8941e-02, -3.0076e-02,  3.7720e-02,\n",
       "                      -8.8564e-02,  4.9295e-02,  4.8863e-02,  9.7205e-02,  5.1573e-02,\n",
       "                      -1.0083e-01, -2.4865e-02,  5.8784e-02,  6.9844e-02,  6.3181e-02,\n",
       "                       6.1042e-02,  7.1112e-02,  6.1172e-02,  3.1179e-02,  9.3162e-02,\n",
       "                      -7.0145e-02,  5.0481e-02,  5.7231e-02,  1.7405e-02, -9.9399e-02,\n",
       "                       5.5380e-04,  9.1076e-02,  3.8573e-02,  4.1022e-02, -9.5409e-02,\n",
       "                      -7.2535e-03, -7.1283e-03,  1.7348e-02,  4.9515e-03,  2.5388e-02,\n",
       "                       6.7530e-02, -9.8220e-02, -6.3890e-02,  7.1168e-02, -9.2568e-02,\n",
       "                       1.7117e-02,  6.7605e-02, -1.0469e-01,  1.1543e-02, -8.3574e-02,\n",
       "                       7.9209e-03,  1.0405e-01, -9.3529e-02,  3.7726e-02, -4.1141e-02,\n",
       "                      -3.3788e-02,  3.8367e-03,  2.4150e-03,  7.7902e-02,  1.0151e-01,\n",
       "                      -3.4426e-02,  5.7682e-02, -6.9153e-02,  9.5077e-02, -9.3362e-02,\n",
       "                       4.8451e-02,  2.6338e-02, -8.6911e-02, -1.1174e-03, -8.6142e-02,\n",
       "                      -3.2598e-02,  7.8521e-02,  1.5248e-02, -8.4117e-03, -8.6267e-02,\n",
       "                      -1.0538e-03,  4.1952e-02,  5.1773e-05, -7.5792e-02, -6.8327e-02,\n",
       "                       2.9052e-03,  4.4590e-02,  6.9224e-02, -8.2440e-02, -5.5276e-02,\n",
       "                       3.7937e-02, -9.2568e-02,  5.9924e-02, -6.5193e-02, -9.2334e-02,\n",
       "                       7.7556e-02, -1.9291e-02, -7.9294e-02,  1.0908e-02,  2.8680e-02,\n",
       "                       3.3014e-02,  5.6908e-02,  4.5432e-03, -6.5340e-02,  4.8868e-02,\n",
       "                      -6.3830e-02,  8.0870e-02,  8.1043e-02, -5.0363e-02,  4.2627e-02,\n",
       "                       8.7444e-02, -2.2443e-02,  9.9578e-02,  6.7953e-02,  2.1475e-02,\n",
       "                       1.7954e-02, -6.5351e-02,  4.7043e-02,  4.7363e-02,  8.3859e-02,\n",
       "                       9.1300e-02, -1.8325e-02, -9.1304e-02,  7.8064e-03, -1.0745e-01,\n",
       "                       3.7001e-02,  8.6739e-02,  1.3182e-02,  2.9135e-02,  2.7959e-02,\n",
       "                       5.3664e-02,  4.4663e-03,  2.2403e-02, -6.8343e-02, -9.2668e-02,\n",
       "                       7.4091e-02, -1.1133e-02, -7.6739e-02, -8.4517e-02,  9.0428e-02,\n",
       "                       7.6455e-02, -6.4246e-02,  7.6797e-04,  2.5523e-02,  5.0276e-02,\n",
       "                      -3.6400e-02, -7.5510e-02,  6.7987e-03, -7.0069e-02, -8.0316e-02,\n",
       "                       5.9431e-02,  3.5120e-02], device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm4.weight',\n",
       "              tensor([0.9952, 0.9984, 1.0239, 1.0220, 1.0813, 0.9210, 0.9216, 0.9831, 0.9872,\n",
       "                      0.9200, 1.0182, 0.9213, 0.9205, 1.0062, 0.9199, 0.9220, 1.0278, 0.9176,\n",
       "                      1.0237, 1.0793, 1.0330, 0.9184, 0.9370, 0.9198, 1.0281, 0.9773, 0.9219,\n",
       "                      1.0951, 1.0765, 1.0807, 0.9305, 1.0575, 1.0797, 1.0820, 0.9914, 0.9205,\n",
       "                      1.0809, 0.9206, 0.9027, 1.0794, 0.9202, 0.9985, 1.0791, 0.9975, 1.0786,\n",
       "                      1.0938, 0.9199, 1.0190, 1.0803, 1.0147, 1.0331, 0.9960, 1.0020, 0.9207,\n",
       "                      1.0801, 1.0277, 1.0287, 1.0108, 0.9935, 0.9045, 1.0232, 0.9935, 0.9207,\n",
       "                      1.0810, 0.9208, 0.9940, 0.9212, 1.0801, 1.0265, 0.9209, 1.0807, 1.0251,\n",
       "                      0.9899, 1.0014, 1.0699, 0.9975, 0.9206, 1.0792, 1.0287, 1.0798, 0.9203,\n",
       "                      1.0753, 0.9178, 0.9955, 0.9221, 0.9777, 1.0156, 0.9864, 0.9183, 0.9191,\n",
       "                      1.0251, 0.9762, 0.9239, 1.0244, 0.9215, 1.0802, 0.9741, 1.0690, 1.0293,\n",
       "                      0.9183, 0.9944, 1.0789, 1.0235, 1.0227, 0.9760, 1.0792, 1.0802, 1.0779,\n",
       "                      1.0778, 1.0249, 0.9198, 0.9916, 0.9211, 1.0138, 1.0244, 0.9204, 1.0297,\n",
       "                      1.0800, 0.9917, 1.0809, 0.9939, 1.0093, 1.0701, 0.9293, 1.0227, 0.9949,\n",
       "                      1.0787, 0.9139, 1.0805, 1.0347, 0.9224, 1.0167, 0.9831, 1.0245, 0.9210,\n",
       "                      1.0262, 1.0220, 0.9198, 1.0207, 0.9076, 0.9246, 0.9208, 1.0134, 1.0796,\n",
       "                      0.9202, 0.9210, 1.0026, 0.9202, 1.0761, 1.0196, 0.9746, 0.9216, 1.0345,\n",
       "                      1.0327, 0.9972, 0.9825, 0.9201, 1.0867, 1.0077, 0.9855, 0.9946, 1.0217,\n",
       "                      0.9919, 1.0796, 0.9212, 0.9022, 0.9132, 0.9801, 1.0760, 1.0798, 1.0168,\n",
       "                      1.0741, 1.0265, 1.0625, 1.0480, 0.9215, 1.0869, 1.0218, 1.0807, 1.0943,\n",
       "                      1.0168, 0.9835, 0.9196, 1.0795, 0.9077, 0.9809, 1.0799, 1.0711, 1.0793,\n",
       "                      1.0799, 1.0698, 1.0220, 1.0807, 0.9817, 0.9206, 1.0234, 1.0196, 0.9213,\n",
       "                      1.0810, 1.0802, 1.0820, 0.9208, 0.9211, 0.9966, 1.0797, 1.0298, 1.0336,\n",
       "                      1.0235, 1.0217, 0.9206, 0.9839, 1.0769, 1.0679, 1.0807, 1.0325, 1.0806,\n",
       "                      1.0074, 1.0297, 1.0229, 1.0229, 1.0752, 1.0266, 0.9099, 0.9229, 0.9632,\n",
       "                      0.9212, 1.0790, 0.9207, 0.9850, 1.0228, 1.0238, 1.0113, 1.0793, 0.9823,\n",
       "                      0.9217, 1.0161, 1.0799, 0.9908, 1.0235, 0.9951, 1.0791, 1.0227, 0.9786,\n",
       "                      1.0189, 0.9898, 0.9208, 0.9225, 0.9208, 0.9199, 1.0788, 0.9215, 0.9111,\n",
       "                      1.0226, 0.9243, 0.9863, 0.9199, 1.0805, 1.0342, 0.9736, 0.9832, 1.0220,\n",
       "                      0.9876, 1.0319, 0.9742, 1.0802, 0.9847, 0.9215, 1.0050, 1.0809, 1.0823,\n",
       "                      1.0808, 1.0794, 1.0792, 0.9944, 0.9189, 1.0008, 0.9898, 0.9065, 1.0805,\n",
       "                      0.9208, 0.9293, 1.0251, 0.9826, 0.9139, 1.0802, 1.0340, 0.9674, 0.9074,\n",
       "                      0.9202, 0.9835, 0.9859, 1.0233, 0.9852, 0.9971, 0.9222, 1.0279, 0.9806,\n",
       "                      0.9212, 0.9200, 0.9935, 1.0801, 1.0241, 1.0804, 1.0491, 1.0195, 1.0173,\n",
       "                      1.0260, 0.9648, 0.9750, 1.0451, 1.0809, 0.9187, 0.9794, 1.0231, 0.9208,\n",
       "                      1.0213, 1.0761, 1.0025, 1.0771, 1.0157, 0.9220, 0.9202, 0.8977, 0.9162,\n",
       "                      1.0800, 1.0809, 1.0275, 0.9208, 0.9124, 1.0237, 0.9398, 0.9187, 1.0799,\n",
       "                      0.9975, 0.9923, 0.9205, 1.0798, 0.9952, 0.9213, 1.0807, 1.0793, 0.9836,\n",
       "                      1.0772, 1.0794, 0.9218, 1.0810, 1.0806, 0.9866, 0.9185, 1.0047, 1.0245,\n",
       "                      0.9944, 0.9210, 1.0210, 1.0175, 0.9217, 1.0159, 0.9920, 1.0191, 1.0296,\n",
       "                      1.0771, 1.0310, 1.0046, 0.9190, 0.9204, 1.0806, 0.9978, 1.0802, 1.0078,\n",
       "                      0.9218, 0.9675, 0.9214, 0.9804, 1.0269, 1.0780, 0.9210, 1.0300, 1.0283,\n",
       "                      0.9314, 1.0167, 0.9213, 1.0770, 1.0186, 0.9900, 1.0000, 0.9154, 1.0038,\n",
       "                      1.1016, 1.0806, 0.9790, 0.9211, 1.0194, 0.9789, 1.0213, 0.9208, 1.0200,\n",
       "                      0.9787, 1.0195, 1.0306, 0.9193, 1.0199, 1.0238, 1.0205, 1.0797, 1.0194,\n",
       "                      0.9884, 0.9191, 0.9199, 0.9876, 0.9196, 1.0294, 0.9901, 0.9216, 1.0509,\n",
       "                      0.9219, 1.0337, 0.9788, 0.9213, 1.0817, 1.0203, 1.0794, 1.0616, 1.0806,\n",
       "                      0.9923, 1.0117, 1.0220, 0.9998, 0.9630, 1.1069, 0.9217, 0.9857, 1.0226,\n",
       "                      0.9183, 1.0750, 0.9761, 1.0209, 0.9791, 1.0582, 1.0489, 0.9193, 1.0805,\n",
       "                      1.0809, 1.0230, 0.9189, 0.9171, 1.0807, 1.0193, 0.9572, 0.9235, 0.9759,\n",
       "                      1.0794, 0.9208, 1.0195, 0.9206, 0.9226, 0.9449, 1.0232, 0.9207, 1.0515,\n",
       "                      1.0783, 1.0820, 0.9071, 1.0253, 0.9216, 1.0780, 0.9202, 0.9914, 1.0028,\n",
       "                      1.0215, 1.0780, 0.9848, 1.0824, 0.9048, 1.0281, 1.0244, 1.0344, 0.9214,\n",
       "                      1.0784, 1.0185, 1.0096, 0.9903, 1.0817, 0.9207, 1.0800, 0.9207, 1.0805,\n",
       "                      0.9792, 1.0173, 1.0791, 1.0217, 1.0802, 1.0793, 1.0802, 0.9158, 0.9212,\n",
       "                      0.9168, 1.0247, 0.9208, 0.9208, 0.9833, 0.9824, 0.9215, 0.9787, 1.0224,\n",
       "                      0.9871, 1.0782, 0.9212, 1.0806, 0.9214, 0.9211, 1.0657, 1.0543],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm4.bias',\n",
       "              tensor([ 0.0919,  0.0923,  0.0683,  0.0206, -0.0292, -0.0797, -0.0788,  0.0895,\n",
       "                       0.0885, -0.0810, -0.0306, -0.0798, -0.0795,  0.0922, -0.0798, -0.0783,\n",
       "                      -0.0355, -0.0808, -0.0332,  0.0278,  0.0800,  0.0768,  0.0826, -0.0802,\n",
       "                      -0.0367, -0.0784, -0.0786,  0.0425, -0.0230,  0.0325, -0.0192, -0.0265,\n",
       "                       0.0271,  0.0288,  0.0899, -0.0801,  0.0318, -0.0792,  0.0224,  0.0253,\n",
       "                      -0.0795, -0.0328,  0.0313,  0.0918,  0.0302,  0.0217, -0.0798, -0.0224,\n",
       "                       0.0329, -0.0287,  0.0811,  0.0899,  0.0929, -0.0797,  0.0280,  0.0260,\n",
       "                       0.0834,  0.0908,  0.0941,  0.0747, -0.0292,  0.0895, -0.0797,  0.0317,\n",
       "                      -0.0792,  0.0915, -0.0790,  0.0444, -0.0280, -0.0800,  0.0343,  0.0284,\n",
       "                       0.0896,  0.0904, -0.0281,  0.0920, -0.0797,  0.0257,  0.0247,  0.0267,\n",
       "                      -0.0805,  0.0359, -0.0804,  0.0891, -0.0781, -0.0711, -0.0301,  0.0879,\n",
       "                       0.0789, -0.0775, -0.0831,  0.0737, -0.0775,  0.0489, -0.0787,  0.0254,\n",
       "                      -0.0783, -0.0335,  0.1041, -0.0784,  0.0885,  0.0298,  0.0227,  0.0785,\n",
       "                      -0.0639,  0.0303,  0.0283,  0.0204,  0.0257, -0.0301, -0.0796,  0.0904,\n",
       "                       0.0755,  0.0823,  0.0227, -0.0795,  0.0245,  0.0301,  0.0891,  0.0328,\n",
       "                       0.0871,  0.0936,  0.0198,  0.0720,  0.0841,  0.0899,  0.0251,  0.0840,\n",
       "                       0.0316,  0.0568, -0.0783,  0.0281,  0.0906, -0.0269, -0.0794, -0.0310,\n",
       "                      -0.0305, -0.0805,  0.0217,  0.0805, -0.0774, -0.0795, -0.0277,  0.0275,\n",
       "                      -0.0802, -0.0791,  0.0942, -0.0801, -0.0327, -0.0266, -0.0799, -0.0790,\n",
       "                       0.0348,  0.0274,  0.0940,  0.0903, -0.0803, -0.0806,  0.0920,  0.0902,\n",
       "                       0.0896, -0.0280,  0.0919,  0.0294, -0.0789,  0.0811,  0.0804,  0.0867,\n",
       "                       0.0409,  0.0288, -0.0281, -0.0281, -0.0232, -0.0265,  0.0207, -0.0792,\n",
       "                      -0.0201, -0.0275, -0.0231, -0.0134, -0.0284,  0.0876, -0.0800,  0.0285,\n",
       "                       0.0795,  0.0859,  0.0251,  0.0239,  0.0320,  0.0262, -0.0299, -0.0297,\n",
       "                       0.0330,  0.0863, -0.0792, -0.0306, -0.0301, -0.0788,  0.0341,  0.0313,\n",
       "                      -0.0348, -0.0795, -0.0793,  0.0906,  0.0268,  0.0102,  0.0818, -0.0317,\n",
       "                      -0.0325, -0.0795,  0.0883,  0.0230,  0.0721,  0.0316,  0.0330,  0.0330,\n",
       "                       0.0955,  0.0268, -0.0343, -0.0298, -0.0259, -0.0305,  0.0812,  0.0668,\n",
       "                       0.0651, -0.0791, -0.0213, -0.0797,  0.0890, -0.0345, -0.0309,  0.0926,\n",
       "                       0.0297,  0.0884, -0.0785, -0.0287,  0.0294,  0.0882,  0.0234,  0.0918,\n",
       "                       0.0314, -0.0293,  0.0868,  0.0723,  0.0914, -0.0806, -0.0764, -0.0793,\n",
       "                      -0.0797,  0.0331, -0.0783,  0.0804, -0.0312, -0.0780, -0.0366, -0.0799,\n",
       "                       0.0292,  0.0370, -0.0797,  0.0889, -0.0340,  0.0874,  0.0259, -0.0781,\n",
       "                       0.0312,  0.0872, -0.0789, -0.0194,  0.0330, -0.0228,  0.0334,  0.0279,\n",
       "                       0.0317,  0.0927, -0.0791,  0.0926,  0.0896,  0.0789,  0.0265, -0.0792,\n",
       "                       0.0984, -0.0258,  0.0914,  0.0663,  0.0344,  0.0793,  0.0730,  0.0725,\n",
       "                      -0.0794,  0.0902,  0.0870, -0.0314,  0.0886,  0.0908, -0.0786,  0.0286,\n",
       "                       0.0889, -0.0791, -0.0796,  0.0920,  0.0310, -0.0327,  0.0263, -0.0270,\n",
       "                      -0.0315, -0.0296, -0.0309,  0.0799, -0.0780, -0.0222,  0.0339, -0.0801,\n",
       "                      -0.0365,  0.0215, -0.0793, -0.0374,  0.0832,  0.0080,  0.0252, -0.0251,\n",
       "                      -0.0788, -0.0796,  0.0511, -0.0631,  0.0325,  0.0338, -0.0841, -0.0797,\n",
       "                       0.0751, -0.0298,  0.0972, -0.0802,  0.0278,  0.0904,  0.0918, -0.0796,\n",
       "                       0.0551,  0.0933, -0.0792,  0.0339,  0.0741,  0.0869, -0.0050,  0.0348,\n",
       "                      -0.0783,  0.0339,  0.0323, -0.0275, -0.0808,  0.0895, -0.0301,  0.0897,\n",
       "                      -0.0789, -0.0345, -0.0307, -0.0785,  0.0929,  0.0892, -0.0284,  0.0415,\n",
       "                       0.0260,  0.0254,  0.0933, -0.0806, -0.0799,  0.0337,  0.0930,  0.0299,\n",
       "                       0.0911, -0.0790, -0.0804, -0.0791,  0.0858, -0.0291,  0.0268, -0.0785,\n",
       "                       0.0846,  0.0286,  0.1000,  0.0928, -0.0787, -0.0254, -0.0281,  0.0906,\n",
       "                       0.0919,  0.0787,  0.0918,  0.0095,  0.0300,  0.0884, -0.0792, -0.0260,\n",
       "                      -0.0349, -0.0268, -0.0793, -0.0280,  0.0863, -0.0297,  0.0281, -0.0808,\n",
       "                      -0.0343, -0.0305, -0.0315,  0.0275, -0.0287,  0.0892, -0.0807, -0.0796,\n",
       "                       0.0894, -0.0801,  0.0292,  0.0890, -0.0789, -0.0291, -0.0203,  0.0380,\n",
       "                       0.0850, -0.0789, -0.0289, -0.0295, -0.0271, -0.0291,  0.0297,  0.0901,\n",
       "                       0.0912, -0.0346,  0.0917, -0.0802,  0.0275, -0.0789,  0.0895,  0.0233,\n",
       "                      -0.0802,  0.0234, -0.0720, -0.0351,  0.0886, -0.0296,  0.0243, -0.0797,\n",
       "                      -0.0296,  0.0313,  0.0243, -0.0809, -0.0805,  0.0265, -0.0238, -0.0322,\n",
       "                      -0.0776, -0.0806,  0.0338, -0.0793, -0.0125, -0.0792, -0.0784,  0.1059,\n",
       "                      -0.0296, -0.0790,  0.0818,  0.0340,  0.0263,  0.0780, -0.0296, -0.0789,\n",
       "                      -0.0232, -0.0793,  0.0893,  0.0918, -0.0355,  0.0034,  0.0906, -0.0243,\n",
       "                       0.0671,  0.0078,  0.0257,  0.0338, -0.0789,  0.0287, -0.0013,  0.0923,\n",
       "                       0.0893, -0.0229, -0.0792,  0.0286, -0.0796,  0.0336,  0.0875, -0.0310,\n",
       "                       0.0333,  0.0546,  0.0344,  0.0269,  0.0302, -0.0818, -0.0791,  0.0780,\n",
       "                       0.0243, -0.0792, -0.0791,  0.0907,  0.0874, -0.0786,  0.0642, -0.0295,\n",
       "                       0.0891, -0.0342, -0.0791,  0.0303, -0.0779, -0.0523,  0.0471, -0.0363],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv5.weight',\n",
       "              tensor([[[ 0.0310,  0.0214,  0.0317],\n",
       "                       [ 0.0173,  0.0231,  0.0216],\n",
       "                       [-0.0428, -0.0024, -0.0412],\n",
       "                       ...,\n",
       "                       [-0.0180, -0.0522, -0.0871],\n",
       "                       [ 0.0377,  0.0358,  0.0620],\n",
       "                       [ 0.0490,  0.0620,  0.0775]],\n",
       "              \n",
       "                      [[ 0.0376,  0.0846,  0.0636],\n",
       "                       [ 0.0511,  0.0435,  0.0914],\n",
       "                       [-0.0547, -0.0677, -0.1011],\n",
       "                       ...,\n",
       "                       [ 0.0794, -0.0263, -0.0520],\n",
       "                       [ 0.0132,  0.0191,  0.0431],\n",
       "                       [ 0.0178,  0.0125,  0.0227]],\n",
       "              \n",
       "                      [[ 0.0831,  0.0751,  0.0884],\n",
       "                       [ 0.0771,  0.0510,  0.0603],\n",
       "                       [-0.0375, -0.0746, -0.0959],\n",
       "                       ...,\n",
       "                       [ 0.0561, -0.0010,  0.0176],\n",
       "                       [ 0.0349,  0.0179,  0.0717],\n",
       "                       [ 0.0017,  0.0032,  0.0355]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0762,  0.0967,  0.0915],\n",
       "                       [ 0.0896,  0.0887,  0.0887],\n",
       "                       [-0.0723, -0.0850, -0.0732],\n",
       "                       ...,\n",
       "                       [-0.0032, -0.0205, -0.0048],\n",
       "                       [-0.0189,  0.1025,  0.0985],\n",
       "                       [-0.0074, -0.0299, -0.0257]],\n",
       "              \n",
       "                      [[ 0.0358,  0.0922,  0.0804],\n",
       "                       [ 0.0623,  0.0978,  0.0609],\n",
       "                       [-0.1110, -0.0957, -0.1034],\n",
       "                       ...,\n",
       "                       [-0.0891, -0.0802, -0.0891],\n",
       "                       [ 0.0407,  0.0809,  0.0689],\n",
       "                       [ 0.0489,  0.0514,  0.0297]],\n",
       "              \n",
       "                      [[ 0.0144,  0.0230,  0.0461],\n",
       "                       [ 0.0131,  0.0138,  0.0354],\n",
       "                       [-0.0064, -0.0482, -0.0268],\n",
       "                       ...,\n",
       "                       [-0.0957, -0.0296, -0.0475],\n",
       "                       [ 0.0589,  0.0614,  0.0265],\n",
       "                       [ 0.0922,  0.0976,  0.0708]]], device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv5.bias',\n",
       "              tensor([-8.9524e-02,  1.1110e-01,  9.6599e-02, -6.2400e-02, -8.3730e-02,\n",
       "                      -5.2598e-02, -3.2848e-03,  2.5418e-02, -7.0713e-02,  1.6247e-02,\n",
       "                       5.8006e-02, -1.4622e-02, -9.6964e-02,  2.5515e-02, -5.2519e-02,\n",
       "                      -7.1365e-02,  2.3960e-02,  1.6374e-02,  2.8987e-03, -8.6094e-02,\n",
       "                       6.2583e-02, -8.6937e-02,  8.0716e-02,  2.5523e-02,  3.1034e-02,\n",
       "                      -6.8649e-02, -2.9776e-02, -6.9757e-02,  2.2514e-02,  2.6386e-02,\n",
       "                       1.2923e-02,  1.4488e-03, -9.2267e-02, -2.4127e-02,  2.6665e-02,\n",
       "                      -4.0398e-02,  1.0067e-03, -1.5811e-02, -1.9564e-02, -1.0209e-01,\n",
       "                       3.7377e-02, -8.1581e-02,  9.5883e-03,  3.0807e-02,  5.6771e-02,\n",
       "                       2.5495e-02,  4.3100e-04, -6.5290e-02, -8.8062e-02,  2.9241e-02,\n",
       "                       3.3699e-02,  2.5008e-02, -3.1428e-02,  4.3593e-02, -8.0903e-02,\n",
       "                      -1.1784e-02, -1.1186e-02,  4.9737e-02,  3.9429e-02, -8.1979e-02,\n",
       "                      -6.1082e-03,  3.1201e-02,  2.8093e-02, -8.0217e-02, -9.9652e-02,\n",
       "                      -9.1850e-02,  1.0470e-02, -8.9023e-03, -8.1411e-02, -1.2574e-02,\n",
       "                       1.2637e-02, -9.5660e-03,  1.2362e-02, -8.9956e-04,  5.1546e-02,\n",
       "                      -6.1764e-02,  8.2899e-02,  3.4983e-02,  2.4398e-02, -1.3169e-02,\n",
       "                      -1.1801e-03, -9.8116e-02,  2.0159e-02, -1.1994e-02, -1.9133e-02,\n",
       "                      -6.6344e-02, -3.7299e-03, -1.3820e-02, -1.9796e-03,  4.2853e-02,\n",
       "                       8.1802e-03,  1.4581e-02,  4.2295e-02,  4.1057e-02,  4.4894e-05,\n",
       "                       9.0797e-02,  2.5511e-02, -8.0904e-04,  2.4910e-02,  1.8424e-02,\n",
       "                       3.3405e-02,  3.8419e-02,  2.5883e-03,  2.0063e-02, -9.3089e-02,\n",
       "                       1.2644e-02,  1.7224e-02,  7.9213e-02, -6.2378e-02, -6.0491e-02,\n",
       "                      -9.7640e-02, -2.7717e-03, -1.0275e-01, -6.0270e-03, -6.6504e-02,\n",
       "                      -1.3887e-02, -4.3308e-03,  1.6072e-02, -6.5997e-02, -6.1605e-02,\n",
       "                      -2.7320e-03, -3.1007e-02, -8.6443e-02,  1.1121e-03,  7.8249e-03,\n",
       "                      -2.2322e-02, -8.1675e-03,  7.1363e-03, -7.5106e-02,  3.7610e-03,\n",
       "                       2.0365e-02,  1.0998e-02,  8.9134e-02,  2.0514e-02, -7.3378e-02,\n",
       "                       2.9745e-02,  7.6350e-02,  3.9002e-02, -9.8392e-02,  8.9467e-03,\n",
       "                      -9.5671e-04,  4.4232e-02,  4.0773e-02, -9.1566e-02, -3.3430e-02,\n",
       "                       1.8350e-04, -2.5387e-02, -4.6590e-03,  4.1400e-02,  2.0620e-02,\n",
       "                      -8.0072e-02, -9.0373e-02,  5.9210e-02, -6.9538e-02,  4.6530e-03,\n",
       "                       2.3806e-02,  7.6778e-03, -4.3785e-02,  4.5803e-02,  4.4369e-02,\n",
       "                       5.4010e-02,  8.7103e-02, -1.0234e-01, -6.5090e-02, -1.4285e-02,\n",
       "                       3.8077e-02,  9.4604e-03, -5.4307e-02, -1.7314e-02,  3.7199e-02,\n",
       "                      -2.0399e-02,  3.3126e-02, -7.6045e-02,  3.9037e-02, -1.1600e-03,\n",
       "                      -9.0411e-02, -5.3623e-02,  5.5751e-02,  1.2223e-02,  6.8729e-03,\n",
       "                       4.3277e-02,  1.4566e-02,  9.0961e-02,  1.7292e-02,  6.6124e-03,\n",
       "                       3.6631e-02,  1.3221e-03,  9.4351e-03, -9.7628e-02, -7.2338e-03,\n",
       "                      -1.2246e-02, -4.3066e-03,  3.5721e-02, -7.4317e-02,  2.6565e-02,\n",
       "                      -7.7130e-02,  2.2167e-02,  3.5598e-02, -8.6225e-02,  3.2313e-02,\n",
       "                       1.2037e-02, -6.5981e-02,  3.9252e-02, -1.6741e-02, -7.3141e-03,\n",
       "                       1.0417e-01, -2.7960e-02,  3.4837e-02,  9.2561e-02,  4.2216e-02,\n",
       "                       1.0170e-01, -6.2055e-02, -1.9380e-02, -8.8382e-02, -8.1426e-02,\n",
       "                       2.8768e-02,  2.5989e-02, -1.2085e-02, -8.3238e-02, -6.9182e-03,\n",
       "                       4.1562e-02,  1.6716e-03, -6.7879e-02,  1.3101e-02, -5.4133e-03,\n",
       "                       2.9529e-02,  2.9428e-02, -5.1145e-02, -8.1489e-02,  7.6147e-02,\n",
       "                      -6.6687e-02, -7.6827e-02,  2.4880e-02, -4.5962e-03, -7.4270e-02,\n",
       "                      -4.2797e-03, -9.1191e-02,  2.3737e-02, -5.2020e-02, -8.8914e-02,\n",
       "                       3.7996e-02,  2.0401e-02,  3.8039e-02, -1.1002e-02,  3.4737e-02,\n",
       "                      -3.2593e-02,  3.5713e-02,  5.0491e-03,  1.1356e-01,  6.7703e-04,\n",
       "                       3.8051e-02, -6.0815e-02, -8.2953e-02,  5.5235e-03, -5.8280e-02,\n",
       "                      -3.7844e-02,  1.9393e-02,  3.7021e-02, -1.0842e-02, -9.7923e-02,\n",
       "                       6.3972e-02,  5.9239e-02,  3.7622e-02, -1.0584e-02,  1.1436e-02,\n",
       "                      -1.9060e-02, -9.5756e-03,  2.0319e-02, -6.3107e-03, -8.2657e-02,\n",
       "                      -8.3544e-02,  6.9806e-02, -1.5441e-02, -6.3510e-02,  1.0052e-01,\n",
       "                       3.3366e-02,  2.6171e-02,  4.1782e-02, -8.6756e-02, -8.7556e-02,\n",
       "                       3.3715e-02, -6.0962e-02,  6.5621e-02,  8.9119e-02, -5.2082e-02,\n",
       "                      -9.2598e-02, -1.1744e-02, -1.4871e-02,  2.4674e-02, -3.9269e-03,\n",
       "                       2.6148e-02,  1.0108e-01,  1.0628e-02,  1.6061e-03,  2.4904e-02,\n",
       "                       3.2095e-02,  3.2681e-02,  4.7446e-02,  2.8145e-02,  1.1599e-04,\n",
       "                       6.1513e-02, -3.5132e-02, -7.0863e-02,  1.0943e-03, -7.5019e-02,\n",
       "                       4.0272e-02, -6.0037e-02,  3.5527e-02,  3.3418e-02, -1.6323e-02,\n",
       "                       3.1350e-02, -5.9547e-02,  6.2444e-02,  4.1810e-02,  7.8356e-02,\n",
       "                      -8.3658e-02,  5.1710e-03, -6.4165e-02,  2.2855e-02,  1.0942e-01,\n",
       "                      -2.4884e-03,  4.3235e-02,  3.6108e-02,  2.6907e-02,  3.5795e-03,\n",
       "                      -1.0055e-01,  3.6240e-02,  3.0093e-02, -5.9096e-02,  5.1952e-02,\n",
       "                       6.8150e-02, -1.6890e-03,  1.3100e-02, -6.5668e-02,  9.2064e-02,\n",
       "                       9.8775e-02,  3.3667e-02,  3.3826e-02,  9.1847e-02,  3.0495e-02,\n",
       "                      -4.3528e-03, -1.7141e-02,  7.2924e-03, -7.1010e-02, -1.1406e-02,\n",
       "                      -5.1753e-03,  8.8588e-02,  3.6644e-02,  2.5083e-03,  6.4538e-02,\n",
       "                      -7.4470e-02,  3.8424e-02, -1.0296e-01,  2.3996e-02, -5.9465e-02,\n",
       "                       1.9149e-03, -3.2804e-02,  8.2154e-02, -8.4694e-02,  1.7532e-02,\n",
       "                      -3.1983e-02,  2.9716e-02,  9.9247e-02,  2.2209e-02,  4.3884e-02,\n",
       "                      -1.2794e-03, -3.5078e-02,  1.9114e-02,  1.8235e-02,  1.7774e-02,\n",
       "                       1.0668e-01, -2.5131e-02,  4.4875e-02, -1.0775e-02, -1.2528e-02,\n",
       "                      -8.7488e-05,  3.9202e-02,  9.3968e-02,  7.3292e-02,  3.7096e-02,\n",
       "                      -5.8119e-02,  1.2391e-02,  1.5351e-02,  2.5877e-02,  8.5086e-02,\n",
       "                       3.3564e-02,  6.4117e-02, -9.3533e-02,  2.3603e-02, -7.7159e-02,\n",
       "                       1.0285e-01, -9.5834e-02, -1.7423e-03, -5.4789e-02,  1.0616e-01,\n",
       "                       2.1244e-02,  8.3815e-02,  9.2158e-02,  6.3760e-03, -1.8890e-02,\n",
       "                       2.7540e-02,  4.8090e-03, -9.8466e-02, -4.8814e-02,  4.2532e-02,\n",
       "                       2.6872e-02,  1.3216e-02,  7.1879e-02,  1.8503e-02, -9.3095e-02,\n",
       "                      -8.8150e-02, -8.4739e-02, -4.0913e-02, -8.6394e-02,  2.4847e-02,\n",
       "                      -1.5094e-02,  1.5540e-02,  9.8062e-02, -1.3967e-03,  5.5676e-02,\n",
       "                       9.4420e-02,  2.5497e-02,  3.8595e-02, -7.5107e-04, -8.3277e-02,\n",
       "                      -8.3375e-02,  6.9904e-02,  2.9638e-02,  4.9727e-03,  4.8972e-02,\n",
       "                       4.5527e-02,  2.3231e-02, -1.4145e-02, -9.3482e-02, -1.0747e-01,\n",
       "                       2.2216e-03,  4.3454e-02,  2.1145e-02, -9.2039e-03,  7.0232e-03,\n",
       "                      -7.2300e-02, -7.0115e-02, -8.0520e-02,  3.3774e-02,  1.8072e-02,\n",
       "                       7.1282e-02,  1.8307e-02, -7.5623e-02,  3.7303e-02,  1.0172e-01,\n",
       "                       2.2768e-02, -7.8656e-02,  4.4021e-02,  4.1180e-02,  7.4501e-03,\n",
       "                       1.0297e-02, -2.5972e-03, -7.5881e-02,  1.8351e-03, -6.4311e-03,\n",
       "                       1.0740e-03, -5.6933e-02,  2.5930e-02,  1.6139e-02, -4.3209e-03,\n",
       "                      -8.1410e-02,  8.6827e-03, -8.8974e-02, -6.3302e-02, -2.9992e-02,\n",
       "                       7.4665e-02,  3.6731e-02, -5.5937e-02, -6.4436e-03,  5.9605e-02,\n",
       "                       2.6657e-02,  2.0684e-02,  1.2570e-02,  4.2851e-02,  3.2087e-02,\n",
       "                      -8.3077e-02,  6.8054e-02, -1.0192e-01,  3.1466e-02, -6.0744e-02,\n",
       "                       9.8820e-02,  2.0690e-02,  5.3770e-02,  5.0825e-02, -7.4664e-02,\n",
       "                       3.6759e-03, -6.1244e-02,  2.9051e-02,  5.5887e-02,  3.3562e-02,\n",
       "                      -7.8327e-02,  3.6028e-02,  1.2887e-02, -8.6401e-02, -9.5686e-02,\n",
       "                      -1.7210e-02, -1.3979e-02, -6.6405e-02,  2.2200e-02, -5.8108e-02,\n",
       "                      -3.8058e-03, -8.0515e-02, -6.7020e-03, -6.7564e-02,  4.7614e-03,\n",
       "                       1.2911e-03, -6.1095e-02], device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm5.weight',\n",
       "              tensor([0.9413, 0.9809, 0.9541, 0.9818, 0.9196, 0.9752, 0.9483, 1.1076, 0.9772,\n",
       "                      1.0275, 1.0936, 0.9210, 0.9682, 1.0235, 0.9295, 0.9388, 1.0219, 1.0228,\n",
       "                      0.9745, 0.9773, 1.1009, 0.9773, 0.9404, 1.0108, 1.0835, 0.9775, 0.9293,\n",
       "                      0.9775, 1.0800, 1.0234, 1.0247, 1.0243, 0.9772, 0.9094, 1.0009, 1.0199,\n",
       "                      0.9226, 1.0895, 0.9734, 0.9679, 1.0887, 0.9797, 1.0798, 1.0220, 1.0867,\n",
       "                      1.0827, 1.0992, 0.9780, 0.9776, 1.0895, 1.0235, 1.0805, 1.0202, 1.0226,\n",
       "                      0.9243, 0.9281, 0.9566, 1.1007, 1.0220, 0.9791, 1.0235, 1.0242, 1.0910,\n",
       "                      0.9774, 0.9776, 0.9767, 1.0237, 1.0217, 0.9325, 1.0227, 0.9268, 1.0240,\n",
       "                      0.9776, 1.0225, 1.1022, 0.9280, 0.9651, 0.9225, 1.0240, 1.0980, 1.0196,\n",
       "                      0.9723, 0.9941, 0.9662, 1.0268, 0.9312, 0.9198, 0.9894, 1.0236, 1.0033,\n",
       "                      1.0699, 1.0233, 0.9979, 1.0895, 1.0232, 0.9359, 1.0730, 1.0057, 1.0219,\n",
       "                      1.0208, 0.9842, 0.9805, 1.0284, 1.0234, 0.9818, 0.9365, 1.0239, 0.9506,\n",
       "                      0.9305, 0.9787, 1.0259, 1.0236, 0.9765, 1.0242, 0.9808, 1.0235, 1.0220,\n",
       "                      0.9357, 0.9516, 0.9818, 1.0211, 0.9752, 0.9842, 1.0233, 1.0226, 0.9231,\n",
       "                      0.9806, 1.0234, 1.0309, 1.0197, 0.9741, 0.9525, 0.9328, 1.0240, 0.9350,\n",
       "                      0.9696, 0.9807, 1.0936, 0.9771, 0.9368, 1.0236, 0.9858, 0.9820, 0.9777,\n",
       "                      1.0503, 0.9509, 1.0227, 1.0234, 1.0720, 1.0864, 0.9788, 0.9250, 0.9990,\n",
       "                      0.9774, 1.0838, 1.0239, 1.0700, 1.0151, 0.9830, 1.0926, 1.0693, 0.9681,\n",
       "                      0.9777, 0.9765, 0.9717, 1.0235, 1.0235, 0.9758, 1.0958, 1.1060, 1.0211,\n",
       "                      1.0737, 0.9783, 1.0237, 1.0220, 0.9769, 0.9759, 1.0469, 1.0216, 1.0868,\n",
       "                      1.0923, 0.9229, 0.9531, 0.9365, 1.0234, 1.0235, 0.9653, 0.9378, 0.9775,\n",
       "                      0.9145, 1.1146, 1.0241, 1.0869, 0.9779, 1.0847, 0.9280, 0.9677, 1.0216,\n",
       "                      0.9765, 1.0237, 1.0227, 0.9318, 0.9250, 1.0230, 1.0232, 0.9324, 1.0913,\n",
       "                      1.0234, 0.9800, 0.9814, 0.9785, 0.9760, 0.9738, 0.9788, 0.9264, 1.0951,\n",
       "                      1.0217, 1.0223, 0.9778, 0.9013, 0.9358, 0.9157, 0.9781, 1.0407, 1.0789,\n",
       "                      1.0241, 1.0958, 0.9787, 0.9365, 0.9466, 0.9767, 0.9579, 1.0032, 1.0838,\n",
       "                      0.9323, 1.0308, 0.9294, 1.0846, 0.9780, 0.9770, 0.9865, 1.0229, 1.0352,\n",
       "                      1.0420, 1.1077, 0.9621, 1.0745, 1.0230, 0.9368, 1.0223, 0.9454, 0.9776,\n",
       "                      0.9790, 1.0243, 0.9258, 1.0240, 0.9874, 1.0215, 0.9809, 0.9763, 0.9539,\n",
       "                      0.9352, 1.0229, 0.9303, 1.0236, 1.1039, 1.0907, 0.9786, 1.0193, 0.9774,\n",
       "                      0.9780, 1.0806, 0.9238, 0.9816, 0.9779, 0.9946, 1.0624, 1.0236, 0.9226,\n",
       "                      0.9779, 0.9212, 0.9372, 0.9816, 0.9278, 0.9772, 0.9743, 1.0240, 0.9236,\n",
       "                      1.0243, 1.0260, 1.0108, 0.9814, 1.0714, 1.0228, 1.0237, 0.9913, 0.9020,\n",
       "                      1.0921, 1.0776, 1.0237, 0.9772, 0.9439, 0.9325, 1.0534, 0.9204, 1.0635,\n",
       "                      0.9783, 1.0642, 1.0222, 0.9868, 1.0864, 0.9256, 0.9250, 1.0723, 0.9464,\n",
       "                      0.9777, 1.0237, 0.9770, 1.0926, 0.9828, 0.9256, 1.0645, 1.0941, 1.0241,\n",
       "                      0.9400, 0.9834, 1.0860, 1.0212, 0.9345, 0.9219, 0.9394, 1.0728, 1.0224,\n",
       "                      0.9774, 0.9255, 0.9224, 0.9289, 1.0613, 0.9537, 0.9561, 1.0238, 0.9786,\n",
       "                      1.0241, 0.9802, 1.0281, 1.0940, 0.9377, 1.0927, 1.0240, 1.0927, 0.9797,\n",
       "                      1.0239, 0.9764, 0.9233, 0.9410, 1.0604, 0.9779, 0.9757, 0.9765, 1.0865,\n",
       "                      0.9838, 1.0743, 0.9408, 1.0226, 1.0262, 1.0981, 0.9760, 1.0235, 1.0895,\n",
       "                      0.9041, 0.9322, 1.0206, 1.0799, 0.9624, 1.0326, 1.0227, 1.0737, 0.9266,\n",
       "                      0.9232, 1.0232, 0.9775, 1.0237, 1.0234, 0.8971, 0.9437, 1.0235, 0.9274,\n",
       "                      0.9781, 1.0262, 0.9800, 0.9318, 0.9349, 1.0184, 0.9061, 0.9263, 0.9838,\n",
       "                      0.9776, 0.9475, 1.0955, 1.0654, 0.9779, 1.0791, 0.9807, 0.9153, 1.0866,\n",
       "                      1.0987, 1.0237, 0.9216, 1.0372, 0.9813, 0.9550, 0.9786, 0.9191, 0.9815,\n",
       "                      1.0949, 1.0317, 1.0239, 0.9285, 0.9300, 0.9754, 0.9237, 1.0241, 1.0237,\n",
       "                      1.0657, 0.9303, 0.9761, 0.9748, 1.0234, 0.9609, 0.9662, 1.0916, 1.0234,\n",
       "                      1.0744, 0.9795, 0.9291, 1.0241, 1.0122, 1.0930, 1.0244, 1.0218, 0.9786,\n",
       "                      0.9770, 0.9778, 1.0238, 0.9276, 0.9392, 1.1020, 0.9754, 0.9790, 0.9248,\n",
       "                      1.0243, 0.9374, 0.9815, 1.0949, 1.0236, 1.0203, 1.0217, 0.9788, 1.0466,\n",
       "                      1.0236, 1.0974, 0.9772, 0.9966, 1.0235, 0.9035, 0.9260, 1.0235, 0.9792,\n",
       "                      0.9260, 0.9149, 0.9241, 1.0431, 0.9422, 0.9298, 1.0530, 1.0222, 1.0927,\n",
       "                      1.1015, 1.0661, 1.0993, 0.9813, 0.9238, 0.9776, 1.0235, 0.9304, 0.9421,\n",
       "                      1.0870, 0.9475, 0.9269, 0.9520, 1.0227, 0.9777, 1.0233, 0.9239, 1.0864,\n",
       "                      0.9774, 1.0898, 1.0227, 0.9275, 0.9782, 0.9172, 1.0238, 0.9778, 1.0925,\n",
       "                      0.9778, 1.0029, 0.9344, 1.0982, 0.9775, 1.0939, 0.9287, 0.9148],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm5.bias',\n",
       "              tensor([-0.0721,  0.0852,  0.0849, -0.0717, -0.0568, -0.0540,  0.0827,  0.0493,\n",
       "                      -0.0682,  0.0257,  0.0225,  0.0809, -0.0687,  0.0240, -0.0699, -0.0725,\n",
       "                       0.0239,  0.0238,  0.0777, -0.0688,  0.0434, -0.0745,  0.0845,  0.0990,\n",
       "                       0.0658, -0.0701,  0.0840, -0.0761,  0.0234,  0.0240,  0.0920,  0.0244,\n",
       "                      -0.0733,  0.0676,  0.0886, -0.0259,  0.0778, -0.0197,  0.1034, -0.0772,\n",
       "                       0.0355, -0.0728,  0.0252,  0.0214,  0.0245,  0.0238,  0.0385, -0.0736,\n",
       "                      -0.0736,  0.0113,  0.0240,  0.0433,  0.0222,  0.0236, -0.0747, -0.0299,\n",
       "                       0.0860,  0.0205,  0.0232, -0.0757,  0.0238,  0.0244,  0.0063, -0.0741,\n",
       "                      -0.0723, -0.0694,  0.0240,  0.0246, -0.0280,  0.0237,  0.0817,  0.0242,\n",
       "                       0.0858,  0.0240,  0.0283, -0.0327,  0.0554,  0.0789,  0.0241,  0.0264,\n",
       "                      -0.0276, -0.0763,  0.0862,  0.0755,  0.0264, -0.0799,  0.0767,  0.0924,\n",
       "                       0.0242,  0.0860,  0.0165,  0.0231,  0.0896,  0.0567, -0.0249,  0.0768,\n",
       "                       0.0254,  0.0924,  0.0241,  0.0954,  0.0874,  0.0802,  0.0280,  0.0236,\n",
       "                      -0.0722,  0.0667,  0.0242,  0.0850, -0.0270, -0.0709, -0.0221,  0.0245,\n",
       "                      -0.0739,  0.0244, -0.0770,  0.0241,  0.0245,  0.0845, -0.0738, -0.0736,\n",
       "                       0.0181, -0.0232, -0.0782,  0.0239,  0.0237,  0.0801,  0.0806,  0.0236,\n",
       "                       0.0363,  0.0251,  0.0840,  0.0776,  0.0843,  0.0242, -0.0305,  0.0796,\n",
       "                       0.0815,  0.0220, -0.0778,  0.0815,  0.0239,  0.0885,  0.0857, -0.0721,\n",
       "                      -0.0205,  0.0836, -0.0289,  0.0243,  0.0253,  0.0480, -0.0791, -0.0751,\n",
       "                       0.0884, -0.0671,  0.0132,  0.0243, -0.0205, -0.0287,  0.0797,  0.0223,\n",
       "                       0.0645,  0.0423, -0.0735, -0.0684,  0.0745,  0.0242,  0.0237, -0.0689,\n",
       "                      -0.0039,  0.0553,  0.0235,  0.0215, -0.0740,  0.0242,  0.0225, -0.0729,\n",
       "                      -0.0680,  0.0935,  0.0236,  0.0556,  0.0205,  0.0807,  0.0835,  0.0864,\n",
       "                       0.0238,  0.0237, -0.0207,  0.0846, -0.0700,  0.0820,  0.0858,  0.0242,\n",
       "                       0.0567, -0.0714,  0.0203, -0.0718,  0.0716,  0.0231, -0.0732,  0.0242,\n",
       "                       0.0240, -0.0757,  0.0797,  0.0233,  0.0236,  0.0849, -0.0107,  0.0242,\n",
       "                       0.0817,  0.0823,  0.0842, -0.0696,  0.0264, -0.0708, -0.0753,  0.0251,\n",
       "                       0.0244,  0.0237, -0.0709,  0.0715,  0.0838,  0.0809, -0.0701,  0.1017,\n",
       "                      -0.0212,  0.0244,  0.0424, -0.0711, -0.0801,  0.0824, -0.0733, -0.0225,\n",
       "                       0.0892,  0.0391, -0.0769,  0.0283, -0.0723,  0.0196, -0.0721, -0.0684,\n",
       "                       0.0814,  0.0240,  0.0933,  0.0719,  0.0267,  0.0690,  0.0539,  0.0244,\n",
       "                       0.0835,  0.0197,  0.0833, -0.0723, -0.0779,  0.0245, -0.0744,  0.0229,\n",
       "                       0.0840,  0.0225,  0.0753, -0.0722,  0.0827,  0.0828,  0.0231,  0.0813,\n",
       "                       0.0243,  0.0705,  0.0587,  0.0859, -0.0255, -0.0701, -0.0722,  0.0397,\n",
       "                       0.0807, -0.0754,  0.0696,  0.0928,  0.1003,  0.0242, -0.0190, -0.0720,\n",
       "                       0.0817, -0.0715,  0.0822,  0.0823, -0.0688, -0.0742,  0.0244,  0.0792,\n",
       "                       0.0244,  0.0303,  0.0908,  0.0824,  0.0210,  0.0222,  0.0245,  0.0903,\n",
       "                       0.0635,  0.0406,  0.0250,  0.0240,  0.0684, -0.0423, -0.0720,  0.0690,\n",
       "                      -0.0685,  0.0700, -0.0726,  0.0663,  0.0245,  0.0881,  0.0247, -0.0723,\n",
       "                       0.0830,  0.0240,  0.0846, -0.0690,  0.0238, -0.0709,  0.0351,  0.0825,\n",
       "                       0.0819,  0.0665,  0.0298,  0.0242,  0.0818, -0.0781,  0.0395,  0.0225,\n",
       "                      -0.0729,  0.0808,  0.0829,  0.0239,  0.0241, -0.0734,  0.0807,  0.0830,\n",
       "                       0.0839,  0.0815,  0.0845,  0.0842,  0.0240,  0.0802,  0.0241, -0.0764,\n",
       "                       0.0250,  0.0185,  0.0840,  0.0211,  0.0248,  0.0353, -0.0738,  0.0239,\n",
       "                      -0.0756,  0.0822, -0.0733,  0.0252,  0.0829,  0.0742, -0.0603,  0.0342,\n",
       "                       0.0866,  0.0727,  0.0801,  0.0234,  0.0947,  0.0449,  0.1131,  0.0233,\n",
       "                       0.0259,  0.0697,  0.0833,  0.0228,  0.0382,  0.0372,  0.0899,  0.0237,\n",
       "                       0.0239,  0.0819,  0.0809,  0.0236, -0.0711,  0.0239,  0.0237,  0.0673,\n",
       "                       0.0827,  0.0245,  0.0820, -0.0748,  0.0251, -0.0723,  0.0840, -0.0713,\n",
       "                      -0.0290, -0.0183,  0.0833,  0.0845,  0.0835,  0.0840, -0.0065,  0.0788,\n",
       "                       0.0922,  0.0202, -0.0728,  0.0805,  0.0336,  0.0213,  0.0241,  0.0800,\n",
       "                       0.0268, -0.0770, -0.0778, -0.0718,  0.0797, -0.0741,  0.0004,  0.0959,\n",
       "                       0.0246,  0.0815,  0.0817,  0.0498,  0.0802,  0.0243,  0.0242,  0.0789,\n",
       "                      -0.0698, -0.0719,  0.0639,  0.0231,  0.0784,  0.0717,  0.0109,  0.0242,\n",
       "                       0.0230, -0.0722, -0.0810,  0.0241,  0.0860,  0.0287,  0.0244,  0.0220,\n",
       "                      -0.0717, -0.0725, -0.0745,  0.0233,  0.0797,  0.0815,  0.0473, -0.0758,\n",
       "                       0.0826,  0.0822,  0.0237, -0.0188,  0.0799,  0.0151,  0.0240,  0.0232,\n",
       "                       0.0248, -0.0722,  0.1005,  0.0241,  0.0089, -0.0717,  0.0744,  0.0243,\n",
       "                       0.0710, -0.0651,  0.0243, -0.0717, -0.0703, -0.0253,  0.0841,  0.0939,\n",
       "                      -0.0744,  0.0850,  0.0813,  0.0234,  0.0088,  0.0293,  0.0814,  0.0723,\n",
       "                      -0.0736,  0.0804, -0.0746,  0.0240, -0.0235,  0.0846, -0.0130,  0.0798,\n",
       "                       0.0777, -0.0710,  0.0239, -0.0710,  0.0239,  0.0473,  0.0473, -0.0696,\n",
       "                       0.0106,  0.0233, -0.0740, -0.0703,  0.0790,  0.0241, -0.0709,  0.0085,\n",
       "                      -0.0758,  0.0953, -0.0645,  0.0002, -0.0724,  0.0085,  0.0840, -0.0532],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv6.weight',\n",
       "              tensor([[[ 0.0747,  0.0526,  0.0942],\n",
       "                       [-0.0234, -0.0294, -0.0184],\n",
       "                       [-0.0104, -0.0415, -0.0612],\n",
       "                       ...,\n",
       "                       [-0.0943, -0.0510, -0.0742],\n",
       "                       [-0.0312, -0.0435, -0.0406],\n",
       "                       [ 0.0586,  0.0704,  0.0830]],\n",
       "              \n",
       "                      [[-0.0547, -0.1023, -0.0714],\n",
       "                       [-0.0070,  0.0078,  0.0036],\n",
       "                       [ 0.0171,  0.0199, -0.0034],\n",
       "                       ...,\n",
       "                       [ 0.0587,  0.0878,  0.0796],\n",
       "                       [-0.0034,  0.0048, -0.0323],\n",
       "                       [-0.1045, -0.0780, -0.0954]],\n",
       "              \n",
       "                      [[-0.0795, -0.0648, -0.1020],\n",
       "                       [-0.0077, -0.0464, -0.0735],\n",
       "                       [-0.0406, -0.0751, -0.0913],\n",
       "                       ...,\n",
       "                       [ 0.0570,  0.0363,  0.0722],\n",
       "                       [-0.0406, -0.0452, -0.0871],\n",
       "                       [-0.0552, -0.0948, -0.0608]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0480,  0.0760,  0.0608],\n",
       "                       [-0.0341, -0.0342, -0.0159],\n",
       "                       [-0.0397, -0.0023, -0.0064],\n",
       "                       ...,\n",
       "                       [-0.0501, -0.1048, -0.0980],\n",
       "                       [-0.0172, -0.0077, -0.0239],\n",
       "                       [ 0.0788,  0.0521,  0.0925]],\n",
       "              \n",
       "                      [[-0.0847, -0.0820, -0.0711],\n",
       "                       [ 0.0066,  0.0393,  0.0276],\n",
       "                       [ 0.0037,  0.0211,  0.0199],\n",
       "                       ...,\n",
       "                       [ 0.0815, -0.0708,  0.0946],\n",
       "                       [-0.0316,  0.0780,  0.0351],\n",
       "                       [-0.0924, -0.0608, -0.0690]],\n",
       "              \n",
       "                      [[-0.0379, -0.0052, -0.0348],\n",
       "                       [ 0.0758,  0.0976,  0.0889],\n",
       "                       [ 0.1077,  0.0620,  0.0744],\n",
       "                       ...,\n",
       "                       [ 0.0007,  0.0155, -0.0280],\n",
       "                       [ 0.0718,  0.0635,  0.0582],\n",
       "                       [-0.0303, -0.0069, -0.0617]]], device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv6.bias',\n",
       "              tensor([ 1.5479e-02, -2.3286e-02,  1.8580e-02, -2.3056e-02,  2.6865e-02,\n",
       "                       2.0356e-02,  4.9041e-02, -1.0051e-01, -1.9017e-02,  3.4214e-02,\n",
       "                       5.3246e-02, -7.8565e-02,  7.9834e-02, -1.1673e-02, -2.5307e-02,\n",
       "                       9.2824e-02, -7.2790e-02,  7.5332e-02, -6.8557e-02,  7.1803e-02,\n",
       "                      -8.3025e-02,  2.1758e-02,  1.3541e-02,  1.2523e-02, -8.7937e-03,\n",
       "                       8.8469e-02,  4.7854e-02,  6.9377e-02,  5.5158e-04,  1.2035e-01,\n",
       "                       9.3204e-02, -6.5031e-02,  4.9126e-02, -4.1947e-02,  5.3338e-02,\n",
       "                      -9.1363e-02,  5.4008e-02,  9.8504e-02,  8.9246e-02, -6.8128e-02,\n",
       "                      -1.1342e-02,  9.2836e-02, -3.3774e-04,  6.3807e-02,  5.7663e-02,\n",
       "                       7.4315e-02,  1.0733e-01, -4.0070e-02, -8.6078e-02,  4.4413e-02,\n",
       "                       7.4073e-02,  3.4267e-02,  8.2536e-02,  8.7141e-02, -1.0267e-01,\n",
       "                       2.9785e-03, -9.9840e-02,  4.8463e-02,  6.2305e-02,  8.1510e-02,\n",
       "                       2.1359e-03,  3.5142e-02, -1.3173e-02, -4.0865e-02, -9.2375e-02,\n",
       "                      -8.9273e-02, -5.8504e-02, -3.4441e-02,  6.6589e-02,  7.2270e-02,\n",
       "                      -1.3261e-02,  2.5264e-02, -9.9827e-02,  1.0461e-01,  4.7330e-02,\n",
       "                      -8.1215e-02,  7.5990e-02, -5.1237e-02,  1.1131e-01, -1.0658e-01,\n",
       "                       4.2064e-02, -2.1159e-03, -6.8971e-02,  4.9445e-02, -5.6541e-02,\n",
       "                       8.6517e-02,  1.1214e-01, -9.2722e-02, -1.7877e-02,  4.3407e-02,\n",
       "                       8.3039e-03,  7.5889e-02,  3.2445e-02,  8.8055e-02,  8.8183e-03,\n",
       "                       8.9840e-02, -8.6077e-02, -9.3866e-02, -9.7490e-02, -1.0435e-01,\n",
       "                       5.8054e-02,  2.2073e-02,  5.9988e-02, -4.3038e-02, -2.2573e-02,\n",
       "                       1.1534e-02, -1.0259e-01, -7.3914e-02, -7.6764e-02,  3.3004e-02,\n",
       "                      -5.4744e-02,  1.0670e-01,  3.9897e-02, -3.2509e-02,  1.0414e-01,\n",
       "                       2.8722e-02, -1.0141e-01, -5.5477e-02,  8.5293e-02, -6.1534e-02,\n",
       "                      -1.2169e-02, -9.3312e-02, -9.0139e-02, -5.7908e-02,  9.6956e-02,\n",
       "                       5.4081e-02, -9.7693e-02,  7.0278e-02, -3.0507e-02, -1.5765e-02,\n",
       "                      -1.0248e-01, -8.5604e-02, -8.1791e-02,  2.0258e-02,  5.3135e-02,\n",
       "                       2.4477e-03,  1.0837e-01,  5.2622e-02, -1.0556e-01,  4.3822e-02,\n",
       "                      -6.7911e-02,  5.2095e-02, -5.2830e-02, -1.1448e-02, -6.4907e-02,\n",
       "                      -6.7355e-02,  1.3619e-02, -7.8990e-02,  9.4308e-02, -5.8076e-02,\n",
       "                       8.6992e-02,  1.0852e-01, -9.5732e-02, -8.3684e-02,  7.9685e-02,\n",
       "                      -6.3045e-02,  1.2438e-03, -3.8996e-03, -3.9602e-02, -7.9438e-02,\n",
       "                       1.2954e-02, -9.6990e-02,  7.2163e-02,  1.5393e-03,  7.9026e-02,\n",
       "                       9.3397e-02,  9.6699e-03,  6.5194e-02, -8.8220e-02, -7.0654e-02,\n",
       "                      -5.3086e-02, -8.1757e-02, -9.9957e-04,  2.7840e-02,  8.7302e-02,\n",
       "                       3.7351e-02, -9.3880e-02,  6.0523e-02,  3.7057e-02,  7.3448e-02,\n",
       "                      -1.4678e-02,  1.0689e-01,  8.9908e-02,  3.0156e-02, -7.2324e-02,\n",
       "                       3.7074e-02,  4.6819e-03,  2.4024e-02,  3.4380e-02, -6.9216e-02,\n",
       "                       1.1855e-04,  9.3925e-02,  3.1642e-02, -1.4448e-02,  6.3257e-02,\n",
       "                       8.2089e-02,  9.5878e-02, -8.0479e-02, -1.3039e-02,  2.2342e-02,\n",
       "                       8.1102e-02,  8.2341e-02,  7.1723e-02, -1.5523e-02, -9.5663e-02,\n",
       "                       7.9972e-02,  4.6370e-02, -9.1278e-02,  1.8620e-02, -6.9153e-02,\n",
       "                       6.6615e-02, -1.0756e-02,  2.7919e-02,  8.1250e-04, -7.0844e-03,\n",
       "                       4.3433e-02, -2.4815e-02,  3.9273e-02,  5.4395e-02,  5.0898e-02,\n",
       "                      -9.1801e-02,  7.0095e-02,  2.7296e-02,  1.0322e-01, -9.5196e-02,\n",
       "                       1.7466e-03,  9.4388e-02,  4.8880e-02,  4.3814e-02, -4.5221e-03,\n",
       "                       1.1801e-02,  1.7147e-02, -5.6529e-02, -3.0656e-02,  9.3521e-02,\n",
       "                       9.5972e-02,  2.0826e-02, -8.0360e-02,  3.3616e-02,  3.6278e-02,\n",
       "                       4.5781e-02, -1.0753e-01,  6.1910e-02,  7.6686e-02,  1.4804e-02,\n",
       "                      -1.0746e-02, -6.8645e-03,  8.6317e-02,  1.7613e-02,  1.9552e-02,\n",
       "                      -1.9354e-03, -9.7039e-02,  4.6335e-02, -2.4261e-02,  4.9909e-02,\n",
       "                       3.9905e-02,  3.4545e-02,  1.1792e-01,  4.0400e-02, -1.0328e-01,\n",
       "                      -1.0403e-02, -7.7542e-03,  4.2870e-02,  4.9965e-02,  2.1658e-02,\n",
       "                      -1.0506e-01,  6.1259e-02,  5.4906e-02,  4.7084e-02,  9.6609e-03,\n",
       "                       6.0637e-02,  1.7287e-02, -7.4673e-02,  6.4346e-02,  6.1733e-02,\n",
       "                      -6.3782e-02,  1.2533e-02,  3.6808e-02, -2.1155e-02, -8.8010e-02,\n",
       "                      -6.5113e-02,  9.5587e-02, -1.0458e-01,  6.2949e-02,  1.1120e-01,\n",
       "                       3.0042e-02,  4.2739e-02,  3.5569e-02, -1.0276e-01, -6.6878e-02,\n",
       "                      -1.9065e-03,  6.2529e-02, -5.9287e-02, -9.5337e-04, -9.0447e-02,\n",
       "                       1.7477e-02,  4.2483e-02,  8.9101e-02, -7.6500e-02, -7.0059e-02,\n",
       "                       1.6971e-02, -5.8470e-02,  6.3667e-02, -1.0413e-01, -9.9531e-02,\n",
       "                       4.5090e-02,  3.2404e-03,  8.7113e-03,  1.6232e-02,  5.0549e-02,\n",
       "                       4.5216e-02, -6.2900e-02,  9.0742e-02, -3.8145e-02, -5.6362e-02,\n",
       "                      -9.2690e-02,  1.0857e-01,  1.8746e-02, -9.3305e-02,  1.5336e-02,\n",
       "                      -7.7081e-02, -6.5383e-02, -3.0703e-02, -2.5381e-02,  3.2120e-02,\n",
       "                       2.0740e-02,  4.5858e-02, -6.0956e-02,  8.0213e-02,  3.7429e-02,\n",
       "                       4.2138e-03,  1.2257e-02, -6.8776e-02,  9.1159e-02,  4.3424e-02,\n",
       "                      -8.6759e-02, -7.5694e-02,  4.3635e-02,  7.9995e-02,  4.7051e-03,\n",
       "                       2.3818e-02,  6.3366e-02,  9.3197e-02,  2.5532e-02,  2.5798e-02,\n",
       "                       7.2719e-03, -5.4246e-02,  2.9319e-02, -5.4026e-02,  3.4393e-02,\n",
       "                      -8.9626e-03,  6.7898e-02,  1.4133e-03, -8.7654e-02,  3.8595e-02,\n",
       "                       1.0535e-01,  2.9680e-02,  6.5750e-02, -1.0276e-01,  8.4214e-03,\n",
       "                       8.6120e-02, -6.9686e-02, -5.7983e-02,  7.1870e-02,  2.3010e-02,\n",
       "                       8.3452e-02, -6.8650e-02, -3.6373e-02,  2.0504e-02,  1.2097e-01,\n",
       "                      -7.3390e-02,  5.3391e-02,  6.2864e-02,  2.8682e-03, -6.5618e-02,\n",
       "                       9.6863e-02, -2.8755e-02,  1.0183e-01, -1.0026e-01, -2.7880e-02,\n",
       "                       1.0973e-01, -2.2602e-03, -1.0064e-03,  9.7064e-02, -1.4159e-02,\n",
       "                      -7.4394e-02, -2.9674e-02,  1.3537e-02, -8.4163e-02,  1.1820e-01,\n",
       "                      -6.0592e-02,  7.0212e-02,  8.2309e-02, -7.4566e-02, -1.0282e-01,\n",
       "                       5.5398e-02,  1.4000e-02,  9.2597e-02,  2.8501e-02,  3.5329e-02,\n",
       "                       5.3295e-02,  5.2515e-02, -4.2508e-02,  2.3202e-03, -5.4841e-02,\n",
       "                      -6.7295e-02,  7.0917e-02,  1.6859e-02, -2.3294e-02, -6.5705e-02,\n",
       "                       4.7213e-02,  8.6352e-02, -9.7819e-02,  4.9098e-02, -5.8255e-02,\n",
       "                       3.9365e-03, -6.0420e-02, -1.3900e-02,  4.9633e-02,  7.7424e-02,\n",
       "                       1.6259e-02, -1.1752e-02,  6.0937e-03,  2.5111e-02, -1.8244e-02,\n",
       "                       4.3108e-02,  4.0304e-02,  9.1632e-02,  1.0080e-01, -7.7080e-02,\n",
       "                      -7.8231e-02, -8.2467e-02,  5.2609e-02, -1.0473e-01,  7.5517e-02,\n",
       "                      -2.1197e-02, -3.5691e-02, -6.7730e-02,  3.3852e-02,  5.6257e-02,\n",
       "                       1.4813e-02,  2.4561e-03,  6.6195e-02, -8.6328e-02, -7.7320e-02,\n",
       "                       2.6988e-02,  8.9646e-02, -1.2839e-02,  1.2757e-02, -5.6480e-02,\n",
       "                      -1.8475e-02, -1.0352e-01, -1.0348e-01,  6.2217e-02, -5.5979e-02,\n",
       "                       3.7262e-02,  5.1361e-02,  4.1460e-02, -6.4682e-02,  7.7910e-02,\n",
       "                      -4.4768e-02, -9.6712e-02, -6.3112e-02,  3.6869e-02,  4.9946e-02,\n",
       "                       7.2716e-02,  6.2847e-02, -2.8551e-02,  2.8931e-02, -7.5771e-02,\n",
       "                       3.0285e-02,  5.5978e-03,  3.6182e-02,  5.0350e-04,  7.8178e-02,\n",
       "                      -7.3291e-02,  5.6759e-03,  4.9151e-03,  8.1343e-02,  4.1448e-02,\n",
       "                      -6.2954e-02, -6.3584e-02,  4.1842e-02,  4.8307e-02,  1.1062e-01,\n",
       "                       7.7720e-02,  1.3853e-02,  7.9271e-02,  9.3670e-02, -4.0998e-02,\n",
       "                       6.7234e-02,  3.9712e-02,  3.6735e-02,  1.9690e-02,  2.8886e-02,\n",
       "                       4.2910e-02, -8.9425e-02,  2.4726e-02,  2.7612e-02, -7.9829e-02,\n",
       "                      -8.1377e-02, -3.6941e-02,  4.9367e-02,  6.5287e-02, -3.4078e-02,\n",
       "                       5.5961e-02,  1.3546e-02,  8.9348e-02,  6.8807e-02,  3.3084e-02,\n",
       "                      -8.6873e-03, -6.1715e-02], device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm6.weight',\n",
       "              tensor([1.0186, 1.0167, 1.0627, 1.0249, 1.0681, 1.0714, 1.0764, 0.9219, 1.0554,\n",
       "                      1.0782, 0.9106, 0.9220, 0.9729, 1.0140, 1.0750, 0.9779, 0.9226, 0.9809,\n",
       "                      0.9220, 0.9719, 0.9172, 1.0317, 1.0830, 1.0858, 1.0597, 0.9838, 1.0546,\n",
       "                      0.9811, 1.0787, 0.9469, 0.9842, 0.9759, 1.0060, 1.0378, 0.9167, 0.9217,\n",
       "                      0.9128, 0.9758, 0.9789, 0.9233, 1.0392, 0.9143, 1.0165, 0.9713, 0.9742,\n",
       "                      0.9114, 0.9777, 1.0212, 0.9241, 1.0770, 0.9756, 1.0828, 0.9836, 1.0470,\n",
       "                      0.9234, 1.0629, 0.9215, 1.0703, 0.9805, 0.9791, 1.0483, 1.0728, 1.0237,\n",
       "                      1.0224, 0.9219, 0.9209, 0.9250, 1.0468, 0.9758, 0.9810, 1.0595, 1.0804,\n",
       "                      0.9224, 0.9802, 0.9391, 0.9215, 0.9465, 0.9744, 0.9778, 0.9713, 1.0844,\n",
       "                      0.9197, 0.9221, 1.0205, 0.9578, 0.9827, 0.9831, 0.9218, 1.0221, 1.0775,\n",
       "                      1.0757, 0.9834, 1.0728, 1.0177, 1.0241, 0.9800, 0.9234, 1.0176, 0.9229,\n",
       "                      0.9217, 0.9148, 1.0833, 1.0193, 1.0230, 1.0318, 1.0869, 0.9221, 0.9218,\n",
       "                      0.9224, 1.0177, 1.0229, 0.9828, 1.0773, 1.0309, 0.9821, 1.0809, 0.9746,\n",
       "                      0.9738, 0.9768, 0.9221, 1.0685, 0.9222, 0.9218, 0.9215, 0.9792, 0.9156,\n",
       "                      0.9213, 0.9826, 1.0287, 1.0242, 0.9229, 1.0236, 0.9753, 1.0777, 0.9805,\n",
       "                      1.0768, 0.9825, 0.9736, 0.9220, 1.0768, 0.9767, 0.9759, 1.0512, 1.0735,\n",
       "                      0.9226, 0.9210, 1.0659, 0.9218, 0.9555, 0.9244, 0.9150, 0.9824, 0.9220,\n",
       "                      0.9216, 0.9782, 1.0803, 1.0070, 0.9385, 1.0253, 0.9220, 1.0247, 0.9220,\n",
       "                      0.9766, 0.9115, 0.9837, 0.9800, 1.0840, 0.9826, 0.9230, 0.9219, 0.9441,\n",
       "                      0.9270, 1.0796, 1.0469, 0.9114, 1.0244, 0.9278, 1.0257, 1.0202, 0.9105,\n",
       "                      1.0857, 0.9175, 0.9761, 1.0765, 0.9225, 1.0767, 1.0778, 0.9320, 1.0232,\n",
       "                      0.9216, 1.0796, 0.9820, 1.0754, 1.0341, 0.9869, 0.9837, 0.9680, 0.9223,\n",
       "                      1.0143, 1.0206, 0.9785, 0.9824, 0.9848, 1.0720, 0.9730, 0.9786, 0.9661,\n",
       "                      0.9250, 1.0841, 0.9216, 0.9849, 1.0359, 1.0783, 1.0821, 1.0260, 0.9164,\n",
       "                      1.0222, 0.9814, 1.0792, 1.0767, 0.9225, 0.9146, 1.0764, 0.9822, 1.0258,\n",
       "                      1.0758, 0.9798, 1.0247, 1.0454, 1.0726, 1.0799, 1.0759, 0.9221, 1.0769,\n",
       "                      0.9803, 0.9150, 1.0783, 0.9211, 0.9551, 1.0312, 1.0787, 0.9220, 0.9811,\n",
       "                      0.9793, 0.9676, 1.0537, 1.0735, 0.9757, 0.9638, 1.0746, 1.0793, 0.9219,\n",
       "                      1.0219, 1.0587, 0.9614, 1.0635, 1.0770, 0.9839, 1.0240, 0.9225, 1.0283,\n",
       "                      1.0248, 1.0268, 1.0804, 1.0057, 0.9219, 1.0221, 0.9177, 1.0805, 1.0766,\n",
       "                      1.0206, 1.0817, 0.9236, 0.9645, 1.0224, 0.9239, 0.9078, 0.9742, 1.0241,\n",
       "                      0.9224, 0.9226, 0.9814, 0.9230, 0.9944, 0.9295, 1.0802, 1.0192, 1.0771,\n",
       "                      0.9205, 0.9230, 0.9742, 0.9625, 0.9155, 1.0764, 0.9216, 1.0731, 0.9369,\n",
       "                      0.9140, 0.9728, 0.9255, 1.0309, 0.9220, 0.9637, 0.9216, 0.9223, 1.0873,\n",
       "                      1.0778, 1.0780, 1.0738, 0.9725, 0.9853, 0.9258, 0.9798, 1.0400, 0.9213,\n",
       "                      0.9153, 0.9815, 1.0791, 0.9272, 1.0742, 0.9220, 0.9226, 1.0363, 1.0892,\n",
       "                      1.0775, 1.0317, 1.0601, 0.9240, 0.9130, 1.0805, 1.0163, 1.0172, 0.9228,\n",
       "                      0.9834, 0.9851, 0.9240, 0.9804, 1.0785, 0.9730, 1.0835, 1.0501, 0.9846,\n",
       "                      0.9782, 1.0419, 1.0791, 0.9067, 0.9220, 1.0777, 0.9220, 1.0787, 1.0259,\n",
       "                      0.9127, 1.0141, 0.9220, 1.0783, 0.9776, 1.0756, 0.9779, 0.9225, 1.0250,\n",
       "                      1.0479, 0.9770, 0.9185, 0.9835, 1.0797, 0.9858, 0.9216, 1.0223, 1.0758,\n",
       "                      0.9799, 0.9211, 0.9735, 0.9843, 1.0751, 0.9227, 0.9853, 1.0249, 0.9183,\n",
       "                      0.9231, 0.9286, 0.9543, 1.0472, 1.0838, 0.9787, 1.0243, 0.9214, 1.0247,\n",
       "                      1.0301, 0.9195, 0.9838, 0.9214, 0.9825, 0.9184, 0.9815, 0.9227, 1.0180,\n",
       "                      1.0613, 0.9753, 1.0286, 1.0801, 1.0194, 0.9831, 1.0761, 1.0300, 0.9215,\n",
       "                      0.9216, 0.9721, 0.9208, 1.0523, 0.9220, 0.9857, 0.9762, 0.9219, 1.0688,\n",
       "                      0.9316, 1.0758, 0.9216, 1.0314, 0.9162, 0.9905, 0.9744, 1.0864, 1.0824,\n",
       "                      1.0813, 1.0280, 1.0806, 1.0185, 0.9797, 0.9142, 0.9222, 0.9248, 0.9736,\n",
       "                      1.0779, 0.9230, 0.9486, 0.9125, 1.0806, 0.9224, 1.0758, 0.9129, 1.0784,\n",
       "                      1.0271, 0.9152, 0.9221, 0.9215, 1.0223, 0.9848, 1.0565, 1.0822, 0.9221,\n",
       "                      1.0268, 0.9226, 0.9222, 0.9739, 0.9285, 1.0811, 0.9381, 0.9558, 0.9224,\n",
       "                      0.9830, 1.0268, 0.9215, 0.9223, 1.0727, 0.9829, 0.9829, 0.9370, 1.0837,\n",
       "                      1.0769, 0.9220, 1.0185, 1.0781, 1.0788, 1.0457, 1.0195, 0.9223, 1.0798,\n",
       "                      1.0623, 0.9796, 1.0729, 0.9226, 0.9220, 1.0667, 1.0777, 0.9833, 1.0446,\n",
       "                      1.0801, 0.9116, 0.9793, 1.0604, 0.9784, 0.9385, 1.0772, 1.0803, 1.0735,\n",
       "                      1.0780, 0.9216, 1.0116, 1.0769, 0.9216, 0.9146, 1.0335, 1.0193, 0.9804,\n",
       "                      1.0384, 0.9123, 1.0108, 0.9840, 0.9870, 1.0226, 1.0263, 0.9226],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm6.bias',\n",
       "              tensor([ 0.0296, -0.0300, -0.0377, -0.0190,  0.0264,  0.0310,  0.0254, -0.0783,\n",
       "                      -0.0478,  0.0250,  0.0508, -0.0786,  0.0789, -0.0332, -0.0599,  0.0794,\n",
       "                      -0.0781,  0.0846, -0.0780,  0.0770, -0.0747,  0.0251,  0.0241, -0.0218,\n",
       "                      -0.0239,  0.0896,  0.0453,  0.0830,  0.0280,  0.0891,  0.0875, -0.0764,\n",
       "                       0.0785, -0.0438,  0.0882, -0.0780,  0.0572,  0.0819,  0.0820, -0.0783,\n",
       "                      -0.0222,  0.0707, -0.0501,  0.0760,  0.0786,  0.0475,  0.0810, -0.0282,\n",
       "                      -0.0787,  0.0275,  0.0792,  0.0285,  0.0763,  0.0516, -0.0786, -0.0054,\n",
       "                      -0.0779,  0.0259,  0.0786,  0.0835,  0.0312,  0.0253, -0.0342, -0.0246,\n",
       "                      -0.0779, -0.0735, -0.0788, -0.0196,  0.0803,  0.0829, -0.0175,  0.0248,\n",
       "                      -0.0781,  0.0832,  0.0507, -0.0777,  0.0658, -0.0656,  0.0814, -0.0816,\n",
       "                       0.0231,  0.0268, -0.0781,  0.0456, -0.0772,  0.0845,  0.0879, -0.0780,\n",
       "                      -0.0248,  0.0258,  0.0263,  0.0873,  0.0258,  0.0507, -0.0244,  0.0820,\n",
       "                      -0.0787, -0.0747, -0.0787, -0.0778,  0.0500,  0.0265,  0.0427, -0.0841,\n",
       "                      -0.0232, -0.0168, -0.0764, -0.0778, -0.0785,  0.0292,  0.0242,  0.0867,\n",
       "                       0.0262, -0.0233,  0.0821,  0.0259, -0.0781, -0.0737,  0.0799, -0.0781,\n",
       "                      -0.0102, -0.0783, -0.0776, -0.0782,  0.0825,  0.0609, -0.0778,  0.0859,\n",
       "                      -0.0253, -0.0230, -0.0786, -0.0770, -0.0798,  0.0250,  0.0850,  0.0264,\n",
       "                       0.0879,  0.0793, -0.0782,  0.0265, -0.0798,  0.0777, -0.0327, -0.0386,\n",
       "                      -0.0787, -0.0750,  0.0330, -0.0789,  0.0574, -0.0785,  0.0536,  0.0871,\n",
       "                      -0.0786, -0.0784,  0.0822, -0.0863, -0.0331,  0.0683,  0.0241, -0.0790,\n",
       "                       0.0253, -0.0788,  0.0775,  0.0566,  0.0865,  0.0831, -0.0233,  0.0808,\n",
       "                      -0.0786, -0.0777, -0.0788, -0.0786,  0.0254,  0.0211,  0.0528,  0.0257,\n",
       "                      -0.0787,  0.0452,  0.0446,  0.0579, -0.0172,  0.0842,  0.0796,  0.0274,\n",
       "                      -0.0778,  0.0277,  0.0253,  0.0715,  0.0196, -0.0775,  0.0257,  0.0837,\n",
       "                       0.0295, -0.0165,  0.0997,  0.0874,  0.0783, -0.0778, -0.0318, -0.0253,\n",
       "                       0.0815,  0.0863,  0.0889, -0.0393, -0.0758,  0.0817,  0.0841, -0.0796,\n",
       "                       0.0229, -0.0772,  0.0896, -0.0330,  0.0254,  0.0251, -0.0225,  0.0648,\n",
       "                      -0.0309,  0.0882,  0.0242,  0.0269, -0.0784,  0.0657,  0.0271,  0.0893,\n",
       "                       0.0203,  0.0288,  0.0824,  0.0296,  0.0455, -0.0175,  0.0245,  0.0272,\n",
       "                      -0.0780, -0.0314,  0.0882,  0.0563,  0.0263, -0.0755,  0.0808,  0.0468,\n",
       "                       0.0234, -0.0783,  0.0861,  0.0828,  0.0623, -0.0224, -0.0257,  0.0791,\n",
       "                       0.0335,  0.0285, -0.0165, -0.0782,  0.0640, -0.0195,  0.0734,  0.0293,\n",
       "                       0.0266,  0.0881,  0.0253, -0.0783, -0.0197, -0.0466,  0.0271,  0.0250,\n",
       "                       0.0348, -0.0779,  0.0458,  0.0528,  0.0541,  0.0269,  0.0456,  0.0242,\n",
       "                      -0.0804,  0.0752,  0.0488, -0.0786,  0.0780,  0.0942, -0.0292, -0.0780,\n",
       "                      -0.0790,  0.0876, -0.0781,  0.0800,  0.0838,  0.0249,  0.0277,  0.0271,\n",
       "                      -0.0781, -0.0782, -0.0826,  0.0754, -0.0720, -0.0385, -0.0785,  0.0309,\n",
       "                       0.0645,  0.0629, -0.0759, -0.0792, -0.0056, -0.0782,  0.0767, -0.0788,\n",
       "                      -0.0783,  0.0245,  0.0257,  0.0246,  0.0274,  0.0767,  0.0786, -0.0790,\n",
       "                       0.0832, -0.0179, -0.0780, -0.0773,  0.0926,  0.0252, -0.0789,  0.0279,\n",
       "                      -0.0781, -0.0815, -0.0169, -0.0158,  0.0262,  0.0250,  0.0317, -0.0787,\n",
       "                       0.0506,  0.0241, -0.0276,  0.0264, -0.0789,  0.0831,  0.0923, -0.0780,\n",
       "                      -0.0786,  0.0251,  0.0744,  0.0247, -0.0287,  0.0880,  0.0821,  0.0220,\n",
       "                       0.0234,  0.0747, -0.0771,  0.0266, -0.0786,  0.0248, -0.0853,  0.0521,\n",
       "                      -0.0259, -0.0781,  0.0252,  0.0813,  0.0272,  0.0816, -0.0786,  0.0253,\n",
       "                       0.0447, -0.0778, -0.0777,  0.0862,  0.0265,  0.0876, -0.0761, -0.0267,\n",
       "                       0.0258,  0.0906, -0.0774,  0.0814,  0.0871,  0.0283, -0.0781,  0.0870,\n",
       "                      -0.0520,  0.0629, -0.0788,  0.0972,  0.0886, -0.0171, -0.0226,  0.0860,\n",
       "                      -0.0257, -0.0777, -0.0197,  0.0205, -0.0768,  0.0878, -0.0779,  0.0853,\n",
       "                       0.0664, -0.0786, -0.0790,  0.0478,  0.0266,  0.0782,  0.0274,  0.0262,\n",
       "                       0.0477,  0.0871, -0.0339, -0.0194, -0.0760, -0.0787,  0.0696, -0.0816,\n",
       "                      -0.0491, -0.0785,  0.0959,  0.0772, -0.0783,  0.0432, -0.0804,  0.0276,\n",
       "                      -0.0783, -0.0185,  0.0559,  0.0855, -0.0814, -0.0171, -0.0207,  0.0296,\n",
       "                      -0.0229,  0.0249,  0.0462,  0.0798,  0.0605, -0.0782, -0.0804, -0.0744,\n",
       "                       0.0147, -0.0785,  0.0621, -0.0586, -0.0183, -0.0783,  0.0403,  0.0505,\n",
       "                       0.0248, -0.0211,  0.0641, -0.0780, -0.0716,  0.0433,  0.0886, -0.0160,\n",
       "                       0.0267, -0.0731, -0.0230, -0.0784, -0.0769,  0.0784, -0.0798,  0.0250,\n",
       "                       0.0577,  0.0829, -0.0781,  0.0824, -0.0216, -0.0778, -0.0782,  0.0288,\n",
       "                       0.0823,  0.0853,  0.0888, -0.0058,  0.0259, -0.0786,  0.0174,  0.0263,\n",
       "                       0.0247,  0.0248,  0.0513, -0.0788,  0.0256,  0.0259,  0.0831,  0.0276,\n",
       "                      -0.0779, -0.0785,  0.0244,  0.0275,  0.0868,  0.0465,  0.0276,  0.0583,\n",
       "                       0.0820, -0.0391,  0.0820,  0.0667,  0.0269,  0.0242,  0.0306,  0.0258,\n",
       "                      -0.0785, -0.0242,  0.0254, -0.0784, -0.0755, -0.0180,  0.0464,  0.0859,\n",
       "                      -0.0174,  0.0613, -0.0377,  0.0871,  0.0863,  0.0265, -0.0168, -0.0774],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv7.weight',\n",
       "              tensor([[[-0.0789, -0.0567],\n",
       "                       [ 0.0023,  0.0008],\n",
       "                       [ 0.1071,  0.0928],\n",
       "                       ...,\n",
       "                       [-0.0864, -0.0677],\n",
       "                       [ 0.0260,  0.0682],\n",
       "                       [ 0.0531,  0.0664]],\n",
       "              \n",
       "                      [[ 0.1105,  0.0716],\n",
       "                       [-0.0239, -0.0625],\n",
       "                       [-0.0885, -0.0559],\n",
       "                       ...,\n",
       "                       [ 0.0933,  0.0735],\n",
       "                       [-0.0621, -0.0140],\n",
       "                       [-0.0076,  0.0558]],\n",
       "              \n",
       "                      [[-0.0267, -0.0438],\n",
       "                       [-0.0797, -0.0384],\n",
       "                       [ 0.0455,  0.0708],\n",
       "                       ...,\n",
       "                       [-0.0815, -0.0746],\n",
       "                       [-0.0132, -0.0089],\n",
       "                       [ 0.0701,  0.0501]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0104,  0.0172],\n",
       "                       [-0.0696,  0.0143],\n",
       "                       [-0.0953, -0.0025],\n",
       "                       ...,\n",
       "                       [ 0.0141, -0.1042],\n",
       "                       [-0.0082, -0.0003],\n",
       "                       [ 0.0235,  0.0813]],\n",
       "              \n",
       "                      [[ 0.0020, -0.0191],\n",
       "                       [ 0.0910,  0.0329],\n",
       "                       [ 0.0511,  0.0108],\n",
       "                       ...,\n",
       "                       [-0.0315,  0.0829],\n",
       "                       [ 0.0672,  0.0506],\n",
       "                       [-0.0915, -0.0672]],\n",
       "              \n",
       "                      [[-0.0688, -0.0704],\n",
       "                       [-0.0049,  0.0456],\n",
       "                       [ 0.0880,  0.0798],\n",
       "                       ...,\n",
       "                       [-0.0676, -0.0635],\n",
       "                       [ 0.0283,  0.1025],\n",
       "                       [-0.0374, -0.0261]]], device='cuda:0')),\n",
       "             ('FeaturesEncoder.conv7.bias',\n",
       "              tensor([ 5.8793e-02, -1.9165e-02,  7.0092e-02,  9.3108e-02, -5.7189e-02,\n",
       "                      -2.8787e-02,  2.9973e-02,  1.7599e-02,  5.9901e-02, -1.6677e-02,\n",
       "                       7.8515e-02, -6.9932e-02, -2.3033e-02,  8.8505e-02,  5.7956e-02,\n",
       "                       7.6184e-02,  7.2420e-02, -5.2864e-02,  9.2406e-03, -6.5683e-02,\n",
       "                      -7.8626e-02,  1.1915e-02, -4.1697e-03,  5.6096e-02,  2.9244e-02,\n",
       "                       5.2326e-02,  1.3699e-02, -3.0123e-02,  9.6109e-03, -5.7489e-02,\n",
       "                       1.0564e-01, -5.0184e-02, -3.9926e-03, -2.8574e-02, -2.5419e-02,\n",
       "                       7.7705e-02, -3.8020e-02, -2.3390e-02, -5.4672e-02, -4.8035e-03,\n",
       "                       2.4072e-02,  4.6397e-02,  6.7432e-02,  4.3093e-02, -3.9458e-02,\n",
       "                       5.8321e-02,  8.4510e-02,  8.9820e-02,  4.8328e-02, -1.8437e-02,\n",
       "                       1.8720e-02,  1.7035e-02, -3.8868e-02,  1.4938e-02, -1.1561e-02,\n",
       "                      -5.2302e-02, -7.8470e-02, -8.3606e-02,  5.5311e-02, -4.2205e-02,\n",
       "                       1.8636e-02, -6.4024e-02, -5.6715e-02, -3.4099e-02,  9.1757e-02,\n",
       "                       6.5490e-02,  3.4194e-02, -4.5277e-02, -5.0553e-03, -4.5656e-02,\n",
       "                       3.6651e-02, -4.8075e-02, -8.3060e-03, -5.8444e-02, -3.0625e-02,\n",
       "                       4.2672e-02,  4.4557e-02,  6.3816e-02,  9.2637e-02,  2.3083e-02,\n",
       "                       2.8196e-02,  3.4383e-02, -6.2259e-02,  9.1412e-02,  2.5034e-02,\n",
       "                       1.7249e-02, -1.9772e-02,  4.4171e-02, -1.5133e-02, -5.3743e-02,\n",
       "                      -3.2375e-02,  6.1829e-02, -6.9780e-02,  1.4310e-03,  8.8983e-03,\n",
       "                      -2.1631e-03,  6.1000e-02,  7.6138e-02, -1.6043e-02,  6.5669e-02,\n",
       "                       5.0761e-02,  8.3172e-02, -1.6416e-02, -3.3765e-03,  1.2129e-02,\n",
       "                      -9.3536e-03,  3.4761e-02,  6.1776e-02, -2.1959e-02,  5.5750e-02,\n",
       "                       2.8013e-02,  8.6585e-03,  1.0019e-01,  7.8836e-02,  4.3184e-02,\n",
       "                       4.1583e-02, -4.8358e-02, -1.9418e-02,  6.2796e-02, -1.6968e-02,\n",
       "                       1.5360e-02, -1.8867e-02, -3.7839e-02, -4.2173e-02, -1.4004e-02,\n",
       "                       7.8331e-02,  5.2729e-02,  2.3185e-02,  3.0397e-02,  6.1763e-02,\n",
       "                      -4.4878e-02,  1.7758e-02,  6.0975e-02,  5.1263e-02, -4.5246e-02,\n",
       "                       8.1091e-02, -9.6598e-02, -5.8644e-02,  3.7558e-02, -4.2532e-03,\n",
       "                       1.9710e-02,  3.1843e-02,  3.5187e-02,  4.5631e-02, -3.3433e-02,\n",
       "                       7.6085e-03, -7.0324e-02,  2.9724e-02,  2.6694e-02,  5.6641e-02,\n",
       "                       8.1852e-02,  6.6979e-02,  7.2747e-02,  6.6701e-02, -3.8684e-02,\n",
       "                       7.0585e-02, -3.2021e-02, -6.1617e-02,  7.2103e-02,  8.0304e-02,\n",
       "                       1.5870e-02,  4.7706e-02,  7.0021e-02,  2.5873e-02,  3.6395e-02,\n",
       "                       1.3804e-01, -1.1733e-02, -8.4780e-03,  2.5868e-02,  5.6035e-02,\n",
       "                       7.9385e-02, -2.1686e-02, -4.1010e-02,  7.1614e-02,  5.5467e-02,\n",
       "                       1.4165e-02, -3.3730e-02, -5.6477e-02, -1.4829e-02,  4.5469e-02,\n",
       "                       3.1091e-02,  4.6768e-02, -3.2293e-02,  3.7844e-02,  6.1842e-02,\n",
       "                       8.6115e-02,  2.2801e-02,  4.7052e-02, -3.1424e-02,  1.0821e-02,\n",
       "                       4.5228e-02, -2.9435e-02, -5.4258e-02, -3.0903e-02,  5.1005e-02,\n",
       "                       3.4693e-02,  8.0549e-02,  6.5660e-02, -5.0309e-02,  1.5934e-02,\n",
       "                       4.4405e-02, -3.1025e-02, -3.1656e-02, -1.6868e-02, -7.3709e-02,\n",
       "                       7.8109e-02,  7.1675e-02,  1.0723e-01, -3.9379e-02, -1.4054e-02,\n",
       "                       8.9457e-02, -3.2257e-02,  2.2978e-02, -3.3749e-02,  5.1162e-02,\n",
       "                      -2.6744e-02,  3.3053e-02,  3.2434e-02,  6.9150e-02, -4.9735e-02,\n",
       "                       3.7822e-03,  3.1002e-02,  1.2546e-02,  9.0112e-02,  8.4016e-02,\n",
       "                       3.3104e-02,  4.5394e-02, -1.6748e-02,  5.2491e-02,  4.6706e-02,\n",
       "                       5.3425e-02, -3.5923e-03, -4.9771e-02, -5.0714e-02,  6.7133e-02,\n",
       "                       5.9725e-02, -3.3318e-02,  4.5419e-02, -3.7566e-02, -6.1964e-02,\n",
       "                       4.6854e-02, -5.5491e-02,  8.1016e-03,  8.0633e-02, -2.3466e-03,\n",
       "                       8.6068e-02, -1.8575e-02, -4.7985e-02, -2.2805e-02,  3.7557e-02,\n",
       "                      -2.6491e-02, -3.0850e-02, -1.3453e-02,  3.7792e-02, -7.6680e-02,\n",
       "                       2.7495e-02, -1.8567e-02,  2.8366e-02,  1.1379e-02, -4.4026e-02,\n",
       "                       3.0230e-02,  1.8233e-02, -9.2845e-03, -9.2905e-02, -2.6868e-02,\n",
       "                       5.1233e-02,  3.3165e-02,  3.3257e-03,  4.5598e-02,  3.8125e-02,\n",
       "                       2.6118e-02,  7.4918e-03, -2.0978e-02,  6.1300e-02,  9.9230e-02,\n",
       "                       2.4008e-02, -1.0748e-02,  2.4739e-02,  6.8378e-02, -2.1057e-02,\n",
       "                       1.4720e-02, -2.5359e-02, -4.6765e-02,  1.1137e-01,  2.3760e-02,\n",
       "                      -1.0268e-01,  4.8351e-02, -1.2891e-02,  8.9479e-03, -1.8213e-04,\n",
       "                       3.0076e-02,  1.5959e-02, -2.2605e-03,  2.8957e-02,  4.4114e-02,\n",
       "                      -2.1411e-02, -2.6724e-02, -1.4057e-03,  1.0347e-01,  1.0187e-01,\n",
       "                       8.3513e-02, -5.3521e-02,  7.5320e-02, -9.6020e-02,  2.1868e-02,\n",
       "                      -7.1314e-02, -5.9347e-02, -8.2423e-03,  1.1533e-01,  1.9468e-02,\n",
       "                      -2.3537e-02, -1.0242e-01,  8.3032e-03,  5.9172e-02,  1.7225e-02,\n",
       "                      -5.1572e-02, -2.7412e-02,  3.2603e-02, -5.3352e-02,  3.4674e-02,\n",
       "                       1.0303e-01,  9.9595e-02, -3.7361e-02,  1.0449e-01,  2.8870e-02,\n",
       "                       7.7567e-03, -8.5447e-02,  6.4331e-02,  3.6846e-02, -1.2837e-02,\n",
       "                       3.1026e-02, -4.9438e-02,  1.0509e-01, -7.7512e-02, -9.2367e-03,\n",
       "                      -2.7595e-02,  6.6172e-02,  6.5942e-03,  6.7208e-02,  7.8663e-02,\n",
       "                      -5.2513e-03,  3.4364e-02, -1.6673e-02, -6.1791e-02,  1.3745e-02,\n",
       "                       3.4014e-02,  2.7269e-02,  1.4628e-02,  4.1189e-02,  3.9480e-02,\n",
       "                      -7.0431e-03,  1.2736e-01, -6.9389e-02,  2.1456e-02, -1.5252e-02,\n",
       "                      -5.8546e-03,  1.3577e-02,  1.8611e-02,  9.6916e-02,  1.6696e-02,\n",
       "                       5.1054e-02, -2.4675e-02, -1.9407e-02,  1.5486e-02,  4.6519e-02,\n",
       "                      -9.1855e-02,  1.7820e-02, -2.1117e-02, -3.1072e-02, -1.0129e-01,\n",
       "                      -1.0424e-01, -2.6876e-02, -3.2177e-02,  4.4758e-02, -5.1527e-02,\n",
       "                      -2.8916e-03, -5.0540e-02, -3.8589e-02,  6.6903e-03,  7.7269e-02,\n",
       "                       4.2882e-02,  5.3597e-02,  3.3819e-02,  1.2475e-03, -6.8716e-02,\n",
       "                       1.3078e-02, -2.7216e-02,  3.2277e-02,  8.1983e-02, -3.2794e-02,\n",
       "                       7.5174e-02,  3.1849e-03,  2.4862e-02,  1.0838e-01, -5.5259e-02,\n",
       "                      -2.0065e-02, -5.7525e-02,  1.4626e-02,  5.3995e-03, -7.7707e-02,\n",
       "                       1.3503e-02, -8.3173e-02,  3.6059e-02, -8.7061e-03,  6.5697e-03,\n",
       "                       7.8666e-02, -5.8138e-02, -9.5466e-03, -1.4101e-02,  3.2378e-03,\n",
       "                       6.1624e-02,  6.8978e-05, -1.9256e-02,  9.2221e-02,  7.6215e-02,\n",
       "                       2.9393e-02, -5.2201e-02, -8.0318e-02,  5.0100e-02, -3.6687e-04,\n",
       "                      -4.2178e-02, -2.2376e-02,  2.8311e-02,  7.5264e-02, -1.0218e-01,\n",
       "                      -7.2588e-02,  8.8338e-02, -7.0987e-02,  3.0521e-02, -5.4243e-02,\n",
       "                      -7.2387e-03, -1.2975e-02, -2.6734e-02,  1.3767e-02, -2.1931e-02,\n",
       "                      -4.1256e-03,  4.5767e-02, -7.0465e-03, -2.7855e-02,  9.6414e-02,\n",
       "                       2.7663e-04, -2.7019e-03,  9.5971e-03,  1.0869e-02,  4.0905e-02,\n",
       "                      -8.8218e-03, -5.8637e-02, -4.9312e-02,  7.7932e-02, -4.4939e-03,\n",
       "                       2.0387e-02,  1.3832e-02, -1.3833e-02, -7.4647e-02, -2.6656e-03,\n",
       "                      -6.5060e-03,  4.1578e-02, -4.8342e-02, -5.4009e-02, -1.6526e-02,\n",
       "                       3.6943e-03, -5.4330e-02,  7.7083e-02, -4.8515e-02, -7.5619e-02,\n",
       "                      -2.3891e-02,  9.5927e-02, -9.6037e-03,  2.8529e-02, -4.8705e-02,\n",
       "                       2.3752e-02, -2.0041e-02,  4.7949e-02, -2.2622e-02, -5.0805e-02,\n",
       "                       4.0374e-02, -4.2312e-03, -2.2721e-03,  7.9430e-03,  1.1726e-01,\n",
       "                       3.4724e-02,  3.9250e-02, -6.7392e-02,  1.8322e-02,  6.4756e-02,\n",
       "                      -5.6167e-02,  4.8608e-02, -1.3902e-02, -6.5963e-03,  1.2005e-03,\n",
       "                      -3.1019e-02,  9.1691e-03, -2.6113e-03,  1.0186e-01, -2.7807e-02,\n",
       "                      -4.9280e-02,  1.6536e-02,  1.5942e-02, -5.2409e-02,  2.0817e-02,\n",
       "                      -3.6967e-02,  1.0099e-01,  4.0283e-02, -6.7975e-02, -1.0571e-01,\n",
       "                       1.0369e-01, -3.7483e-02, -6.6140e-02,  3.5031e-02,  6.9693e-02,\n",
       "                      -8.5268e-02, -1.3572e-02], device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm7.weight',\n",
       "              tensor([1.1239, 1.0255, 1.1232, 1.0835, 0.9423, 0.9447, 1.0454, 0.9940, 0.9453,\n",
       "                      1.0584, 0.9258, 0.9370, 1.0693, 1.0703, 1.0920, 1.0366, 1.0543, 0.9476,\n",
       "                      1.0498, 0.9168, 0.9124, 0.8926, 0.9274, 1.1045, 1.0516, 1.0792, 1.0543,\n",
       "                      1.0205, 1.0690, 0.9278, 1.0850, 0.9599, 1.0573, 0.9538, 0.9305, 1.0011,\n",
       "                      1.0361, 0.9425, 0.9811, 1.0164, 1.0480, 0.9824, 1.0106, 0.9132, 1.0058,\n",
       "                      0.9327, 1.0470, 0.9165, 0.9300, 0.9863, 0.9335, 0.8994, 0.9137, 0.8944,\n",
       "                      0.9810, 0.9439, 0.9306, 0.9229, 0.8871, 0.9963, 1.0616, 0.9687, 0.9042,\n",
       "                      0.9375, 1.0486, 0.9062, 1.0515, 0.9610, 0.9436, 0.9729, 1.0880, 0.9230,\n",
       "                      0.9545, 0.8943, 0.9665, 0.9158, 1.0461, 1.0722, 1.0531, 0.9541, 0.9671,\n",
       "                      0.9066, 0.9299, 1.0781, 1.0046, 1.0235, 0.9347, 1.0121, 0.8934, 1.0982,\n",
       "                      1.0044, 1.0760, 0.9433, 1.0088, 1.0380, 1.1256, 1.0455, 1.0232, 1.0919,\n",
       "                      0.8806, 1.0564, 1.0692, 0.9335, 0.9402, 0.8931, 1.0222, 0.8844, 1.0842,\n",
       "                      1.0087, 1.1172, 1.0969, 1.0329, 0.8958, 1.0393, 0.8786, 0.9211, 0.9033,\n",
       "                      1.0332, 0.9039, 1.1145, 0.8942, 0.9944, 0.9700, 1.0042, 0.9180, 0.8988,\n",
       "                      1.0708, 0.9313, 0.9949, 1.0443, 0.9450, 0.9285, 1.0460, 0.9008, 0.9311,\n",
       "                      0.9354, 0.9596, 0.9168, 0.9908, 1.0518, 1.0412, 0.9288, 0.9107, 0.9057,\n",
       "                      1.0603, 0.9000, 0.9707, 0.8986, 1.1061, 1.0497, 1.0575, 1.0247, 1.0861,\n",
       "                      0.9440, 0.9416, 0.9069, 0.9053, 0.9269, 1.0666, 1.0707, 0.9379, 1.0509,\n",
       "                      1.0848, 1.0424, 1.0439, 1.0702, 1.0065, 1.0676, 1.0508, 1.0474, 0.9385,\n",
       "                      0.9217, 0.9450, 0.8978, 1.0515, 0.9849, 0.9933, 0.9994, 0.9895, 0.8958,\n",
       "                      0.8941, 1.0327, 0.9580, 1.0204, 1.0349, 1.1637, 0.9528, 0.9002, 1.0852,\n",
       "                      1.0656, 1.0490, 0.9844, 0.9142, 1.0250, 1.0824, 1.0182, 1.0189, 1.0767,\n",
       "                      0.9455, 0.9612, 1.0218, 0.9991, 1.0639, 1.0694, 0.9540, 1.1170, 1.0120,\n",
       "                      1.0761, 1.0793, 1.0925, 0.9978, 1.0230, 0.9292, 1.1167, 1.0985, 1.0011,\n",
       "                      1.0096, 0.9423, 1.1235, 1.0674, 0.9575, 0.9326, 0.9793, 1.0394, 1.0065,\n",
       "                      1.0478, 1.0812, 0.8859, 1.1300, 1.0132, 1.0449, 0.9619, 0.9675, 0.8834,\n",
       "                      1.0959, 0.9237, 0.9606, 1.1124, 1.0640, 0.9384, 1.1052, 0.9409, 1.0415,\n",
       "                      1.0460, 0.9104, 1.0526, 1.0181, 0.9279, 1.0237, 1.0253, 0.9268, 0.9412,\n",
       "                      0.9650, 1.0430, 0.9744, 0.9020, 1.0293, 1.0231, 1.0229, 1.0553, 1.0856,\n",
       "                      1.0493, 0.9891, 0.9816, 0.9169, 1.1305, 1.0093, 1.0824, 0.9038, 1.0859,\n",
       "                      1.0435, 1.0491, 1.0830, 1.0825, 0.9781, 1.0210, 1.0406, 1.0338, 0.9610,\n",
       "                      1.0591, 1.0624, 0.9542, 1.0786, 0.9978, 0.9703, 0.9138, 1.0323, 0.9571,\n",
       "                      0.9157, 0.9511, 1.0535, 1.0586, 1.0892, 1.0766, 1.0089, 1.0826, 0.9240,\n",
       "                      1.0848, 1.0230, 1.0665, 0.9784, 1.0740, 0.9290, 0.9846, 1.0917, 0.9748,\n",
       "                      0.9487, 1.0290, 0.9600, 0.9588, 0.9506, 0.9248, 1.0852, 0.9614, 1.0228,\n",
       "                      1.0792, 1.0377, 1.0251, 1.0219, 1.0078, 0.9772, 1.0146, 0.9440, 0.9863,\n",
       "                      0.9084, 1.0813, 0.9239, 1.0190, 1.0184, 1.0966, 1.0225, 0.9743, 0.9580,\n",
       "                      0.9226, 1.0804, 0.9751, 0.9859, 1.0796, 0.9659, 0.9367, 0.9165, 1.0265,\n",
       "                      1.0908, 0.9840, 1.0117, 1.0239, 1.0769, 1.0850, 1.0856, 1.0592, 1.0330,\n",
       "                      0.9646, 0.9492, 1.0545, 1.0500, 1.0242, 1.0241, 1.0915, 0.9537, 0.9147,\n",
       "                      1.0905, 1.0765, 0.9616, 0.9830, 1.0831, 0.9734, 1.0579, 1.0020, 0.9396,\n",
       "                      0.9830, 0.9809, 0.9120, 1.0541, 1.0821, 0.9745, 1.0136, 0.9219, 1.0858,\n",
       "                      1.0877, 1.0300, 0.9971, 1.0526, 0.9490, 1.0312, 0.9800, 1.0242, 0.9532,\n",
       "                      1.0256, 0.9874, 0.9716, 0.9517, 1.0163, 1.0219, 0.9762, 0.9471, 1.0869,\n",
       "                      1.0241, 1.0890, 0.9523, 0.9826, 1.0571, 0.9740, 1.0172, 0.9605, 0.9713,\n",
       "                      1.1080, 0.9283, 0.9405, 0.8997, 1.0238, 1.0031, 1.0203, 0.9660, 0.9926,\n",
       "                      0.9334, 1.0347, 0.9611, 0.9550, 1.0796, 0.9979, 0.9454, 1.0876, 1.0277,\n",
       "                      0.9562, 0.9148, 0.9803, 0.9809, 0.9745, 1.0796, 1.0306, 1.0282, 1.0684,\n",
       "                      1.0337, 1.0283, 0.9408, 0.9663, 1.0275, 1.0199, 0.9162, 0.9617, 1.0202,\n",
       "                      0.9146, 1.0848, 1.0717, 1.0239, 0.9818, 0.9706, 0.9199, 0.9216, 1.0239,\n",
       "                      1.0276, 1.0542, 1.0824, 1.0794, 0.9936, 1.0878, 1.0276, 0.9443, 1.0261,\n",
       "                      1.0507, 1.0377, 1.0243, 0.9461, 0.9952, 0.9569, 1.0639, 0.9493, 1.0811,\n",
       "                      1.0331, 1.0312, 1.0153, 1.0357, 1.0210, 1.0453, 1.0033, 1.0185, 1.0896,\n",
       "                      1.0799, 1.0223, 0.9337, 1.0798, 1.0307, 1.0832, 1.0327, 1.1117, 0.9688,\n",
       "                      1.0919, 1.0891, 0.9559, 1.0807, 1.0759, 0.9226, 1.0521, 0.9245, 1.0828,\n",
       "                      0.9533, 1.0890, 1.0238, 1.0544, 1.0847, 1.0389, 1.1077, 1.0324, 0.9816,\n",
       "                      0.9795, 1.0732, 1.0762, 0.9439, 1.0251, 0.9241, 0.9775, 1.0880],\n",
       "                     device='cuda:0')),\n",
       "             ('FeaturesEncoder.norm7.bias',\n",
       "              tensor([ 0.1083, -0.0665,  0.1066,  0.0839, -0.0783, -0.0533,  0.0695, -0.0972,\n",
       "                      -0.0453, -0.0298,  0.0065, -0.0653, -0.0257,  0.0773,  0.0910,  0.0360,\n",
       "                       0.0566, -0.0531,  0.0366, -0.0743, -0.0665, -0.0781, -0.0952,  0.0822,\n",
       "                       0.0359,  0.0859,  0.0920, -0.0841, -0.0089, -0.0702,  0.0984, -0.0500,\n",
       "                      -0.0280, -0.0661, -0.0887,  0.0287,  0.0356, -0.0424, -0.0751, -0.0066,\n",
       "                       0.0653, -0.1235,  0.0385, -0.0967, -0.0257, -0.0615,  0.0747, -0.0055,\n",
       "                      -0.0557, -0.0589, -0.0051, -0.0166, -0.0749, -0.0825, -0.0868, -0.0659,\n",
       "                      -0.0663, -0.0648, -0.0391, -0.0598,  0.0282, -0.0350, -0.0814, -0.0483,\n",
       "                       0.0926, -0.0069,  0.0340, -0.0767, -0.1196, -0.0229,  0.0840, -0.0584,\n",
       "                      -0.0421, -0.0885,  0.0266, -0.0593,  0.0813,  0.0894,  0.0573, -0.0112,\n",
       "                      -0.0085, -0.0805, -0.0687,  0.1039, -0.0130,  0.0209, -0.0718,  0.0236,\n",
       "                      -0.1108, -0.0038, -0.0744,  0.0408, -0.0763,  0.0709, -0.0185, -0.0419,\n",
       "                       0.0616, -0.0322,  0.0328, -0.0567,  0.0466,  0.0667, -0.0985, -0.0828,\n",
       "                      -0.0706,  0.0201, -0.0705,  0.1176, -0.0304,  0.0995,  0.0718, -0.0812,\n",
       "                      -0.0514,  0.0187, -0.0222, -0.0592, -0.1256, -0.0819, -0.0377, -0.0369,\n",
       "                      -0.0678, -0.0078, -0.1015, -0.0497, -0.0650, -0.0473,  0.0538, -0.0574,\n",
       "                       0.0478,  0.0720, -0.0532, -0.0398,  0.0910, -0.0457, -0.0710,  0.0370,\n",
       "                      -0.0775, -0.0849, -0.0271,  0.0465,  0.0639, -0.0476, -0.0579, -0.0976,\n",
       "                       0.0616, -0.0681, -0.0511, -0.0635,  0.0154,  0.0747,  0.0556,  0.0172,\n",
       "                       0.0745, -0.0565, -0.0666, -0.0229, -0.0913, -0.0857,  0.0562,  0.0799,\n",
       "                      -0.0615,  0.0966,  0.0375,  0.0494,  0.0720,  0.1156,  0.0017,  0.0568,\n",
       "                       0.0831,  0.0441, -0.0204, -0.0994, -0.0538, -0.0796,  0.0980, -0.0510,\n",
       "                      -0.0775, -0.0149, -0.0184, -0.0806, -0.0584,  0.0544, -0.0344,  0.0318,\n",
       "                       0.0768,  0.0815, -0.0530, -0.1020, -0.0884,  0.0278,  0.0528, -0.0583,\n",
       "                      -0.0904, -0.0200,  0.0904,  0.0290,  0.1178,  0.0811, -0.0514, -0.0157,\n",
       "                       0.0165, -0.0682,  0.0253,  0.0175, -0.0552,  0.1040,  0.0219,  0.0945,\n",
       "                      -0.0271,  0.0097,  0.0958, -0.0344, -0.0224, -0.0514,  0.0904, -0.0253,\n",
       "                       0.0072,  0.0394,  0.0989, -0.0299,  0.0292, -0.0359, -0.0104,  0.0693,\n",
       "                       0.1035,  0.0940,  0.0798, -0.0765,  0.1155,  0.0012,  0.0595, -0.0777,\n",
       "                      -0.0339, -0.1041,  0.0509, -0.0780, -0.0861,  0.0310,  0.0296, -0.0672,\n",
       "                       0.0978, -0.0871, -0.1130, -0.0763, -0.0914,  0.0920,  0.0268, -0.0593,\n",
       "                      -0.0353, -0.0696, -0.0680,  0.0322, -0.1083,  0.0695, -0.0794, -0.0859,\n",
       "                      -0.0173,  0.0249,  0.0243, -0.0224, -0.0198,  0.0217,  0.0209, -0.0730,\n",
       "                      -0.0364,  0.0616,  0.0247, -0.0264,  0.0742, -0.0137,  0.0179,  0.0223,\n",
       "                      -0.0228,  0.0330,  0.0877,  0.0250, -0.0167,  0.0257,  0.0931, -0.0167,\n",
       "                       0.0279, -0.0343, -0.0229,  0.0969,  0.0261, -0.0828,  0.0259, -0.0470,\n",
       "                       0.0248, -0.0304,  0.0579,  0.0245, -0.0148,  0.0287,  0.0248, -0.0232,\n",
       "                      -0.0340, -0.0204,  0.0745,  0.0718,  0.0800, -0.0617,  0.0455, -0.0794,\n",
       "                      -0.0107, -0.0757, -0.0819,  0.0274,  0.0934,  0.0267, -0.0363, -0.0756,\n",
       "                      -0.0196,  0.0919,  0.0217, -0.0265, -0.0176,  0.0260, -0.0751,  0.0245,\n",
       "                       0.0865,  0.1016, -0.0388,  0.0905,  0.0248,  0.0199, -0.0770,  0.0397,\n",
       "                       0.0250, -0.0011,  0.0254, -0.0798,  0.0894, -0.0770, -0.0251, -0.0673,\n",
       "                       0.0888, -0.0258,  0.1032,  0.0879, -0.0415,  0.0252, -0.0164, -0.0767,\n",
       "                       0.0228,  0.0261,  0.0268, -0.0192,  0.0216,  0.0249, -0.0184,  0.0986,\n",
       "                      -0.0538,  0.0252, -0.0168,  0.0246, -0.0263, -0.0083,  0.0896,  0.0242,\n",
       "                      -0.0127, -0.0294, -0.0021,  0.0011,  0.0330, -0.0702,  0.0185,  0.0236,\n",
       "                      -0.0535, -0.0761, -0.0772, -0.0369, -0.0173,  0.0265, -0.0778,  0.0242,\n",
       "                      -0.0808, -0.0219, -0.0107,  0.0517,  0.0463,  0.0450,  0.0490,  0.0241,\n",
       "                      -0.0802,  0.0237, -0.0293,  0.0228,  0.0923, -0.0330,  0.0746,  0.0241,\n",
       "                       0.0245,  0.0998, -0.0516, -0.0178, -0.0770, -0.0083,  0.0244, -0.0834,\n",
       "                      -0.0189, -0.0775,  0.0245, -0.0363,  0.0397,  0.0498, -0.0753, -0.0487,\n",
       "                       0.0205,  0.0223,  0.1126,  0.0254, -0.0370,  0.0921,  0.0936,  0.0222,\n",
       "                      -0.0483, -0.0870,  0.0271,  0.0218, -0.0472, -0.0151,  0.0248,  0.0713,\n",
       "                      -0.0819, -0.0738,  0.0934, -0.0746,  0.0326, -0.0038,  0.0268, -0.0218,\n",
       "                      -0.0168,  0.0264, -0.0426,  0.0184,  0.0248,  0.0236, -0.0591,  0.1092,\n",
       "                       0.0249, -0.0342,  0.0172, -0.0268,  0.0231,  0.0228, -0.0808, -0.0804,\n",
       "                       0.0801,  0.0241,  0.0274, -0.0179, -0.0231, -0.0667,  0.0241,  0.0263,\n",
       "                       0.0264, -0.0110, -0.0254, -0.0221,  0.0203, -0.0690,  0.0788, -0.0283,\n",
       "                      -0.0576, -0.0637,  0.0770, -0.0271,  0.0265, -0.0446,  0.0444,  0.0015,\n",
       "                       0.0491, -0.0235, -0.0757,  0.0256, -0.0181,  0.0167,  0.0230,  0.0877,\n",
       "                       0.0263,  0.0259, -0.0535, -0.0205,  0.0436, -0.0352, -0.0152, -0.0183,\n",
       "                      -0.0383, -0.0228, -0.0356,  0.0235,  0.0289,  0.0912, -0.0259, -0.0279,\n",
       "                      -0.0102,  0.0247, -0.0310,  0.0160, -0.0208,  0.0644,  0.0151, -0.0785,\n",
       "                      -0.0708,  0.0684, -0.0248, -0.0484,  0.0499,  0.0891, -0.0822, -0.0217],\n",
       "                     device='cuda:0')),\n",
       "             ('masking.mask_embedding',\n",
       "              tensor([ 2.1580e-01, -2.8668e+00,  5.1297e-01,  7.0666e-01, -3.3428e-02,\n",
       "                      -1.1922e+00,  1.9103e+00, -1.9919e-01, -4.9754e-01,  3.0400e-02,\n",
       "                      -2.1156e-01, -1.9292e+00, -6.6022e-01,  7.0017e-01,  1.1079e+00,\n",
       "                      -7.7073e-02, -1.0083e-01, -4.7763e-01, -1.0918e+00, -2.0795e+00,\n",
       "                      -7.3032e-01, -6.4589e-01, -8.3118e-01,  8.8926e-01, -2.3028e+00,\n",
       "                       1.3556e-02,  2.0489e+00, -2.3176e-01, -1.8192e+00,  1.7752e+00,\n",
       "                       9.2581e-01, -9.9643e-02, -1.2438e+00, -4.1511e-01, -1.6591e+00,\n",
       "                      -6.7183e-02, -1.6623e+00, -1.4174e+00, -1.2142e+00, -4.3953e-01,\n",
       "                       1.7788e+00, -8.1203e-01, -3.3667e-02, -5.1244e-01, -1.1278e+00,\n",
       "                      -2.3789e+00,  5.8645e-01, -1.9148e+00, -1.1210e+00,  4.3640e-01,\n",
       "                      -8.2508e-01, -1.3253e+00, -4.7133e-01, -1.0950e+00, -6.3847e-01,\n",
       "                       4.7183e-01, -5.7357e-01, -1.4220e+00, -8.4648e-01, -1.7265e+00,\n",
       "                       1.8258e-01,  1.8926e-01, -1.2986e+00, -3.1274e-01,  1.6143e+00,\n",
       "                      -8.6314e-01, -3.6651e-01,  1.0767e+00, -3.6158e-01,  1.5076e+00,\n",
       "                       5.3633e-01, -1.0959e+00, -5.3992e-01, -1.8966e+00,  1.3415e+00,\n",
       "                      -3.6572e-01,  5.2618e-01,  6.6607e-01, -1.1017e+00, -1.6713e+00,\n",
       "                       2.0020e+00, -2.6691e+00, -8.0883e-02,  5.5999e-01, -1.0888e+00,\n",
       "                       6.7966e-01,  9.4480e-01, -4.6781e-02, -4.5244e-01,  1.1244e+00,\n",
       "                      -5.9044e-01,  1.9616e+00, -1.2547e+00,  5.4844e-01, -1.0282e+00,\n",
       "                       1.7015e+00,  1.2254e+00, -4.7293e-01,  8.2222e-01, -1.9002e-01,\n",
       "                       1.0205e+00,  2.0950e-01, -6.7297e-01, -1.9723e+00, -2.7032e+00,\n",
       "                       7.7023e-01, -7.3012e-01,  3.2003e-02,  3.6028e-01,  2.3216e-01,\n",
       "                       1.0186e+00, -2.1262e+00, -4.4274e-01, -1.1980e+00, -2.2081e-02,\n",
       "                      -5.5716e-01, -1.2289e+00, -5.3908e-01, -6.5780e-01,  1.6144e+00,\n",
       "                      -1.2666e+00,  1.8135e-01, -1.5244e+00,  1.0816e-01, -8.8070e-01,\n",
       "                      -1.7582e+00,  2.9196e-01, -2.2525e+00, -1.7309e-01,  1.5763e-01,\n",
       "                       1.6202e+00, -1.4834e+00,  5.0104e-01, -8.7141e-01,  1.0929e+00,\n",
       "                      -5.1766e-01, -4.7475e-01,  5.2055e-01, -1.3093e+00,  1.3344e+00,\n",
       "                      -1.8527e-01, -9.8712e-01,  4.9282e-01, -9.6483e-01,  6.3521e-01,\n",
       "                      -1.3220e+00, -1.3100e+00, -1.2067e+00,  2.5830e-01,  5.5654e-01,\n",
       "                       6.2842e-01,  3.0830e-01,  5.6688e-01, -1.2533e+00,  9.7292e-01,\n",
       "                      -1.3002e-01, -3.1795e-01, -7.1219e-02,  1.8984e-01,  1.0047e+00,\n",
       "                      -3.5735e-01,  5.4848e-01,  1.6255e+00,  2.9837e-01,  5.7056e-01,\n",
       "                       5.0459e-02,  4.2314e-01,  6.7925e-01,  1.2470e+00,  2.9342e+00,\n",
       "                      -1.8078e-01, -5.0755e-01,  1.7093e-02, -8.1286e-01,  2.7877e-01,\n",
       "                      -1.9883e+00,  1.4219e+00, -1.4624e+00,  1.1001e+00, -6.8409e-01,\n",
       "                      -1.9316e-01, -1.3092e+00,  6.4804e-01,  3.8501e-01,  1.6969e+00,\n",
       "                       3.1821e-01, -2.4187e-01, -6.0162e-01,  1.8251e+00, -1.4545e+00,\n",
       "                      -1.6148e-01, -4.8432e-02, -1.5073e+00,  2.0725e-02,  1.1513e+00,\n",
       "                       1.0543e+00,  4.5380e-01,  1.0917e+00, -1.8513e+00, -9.5664e-01,\n",
       "                      -3.1586e-01,  4.8897e-01, -4.1739e-01, -3.8732e-01, -1.0385e+00,\n",
       "                       2.3898e+00, -6.6421e-01,  1.2254e+00,  3.7580e-01,  4.6528e-01,\n",
       "                       1.3836e+00,  8.1892e-02, -9.8764e-01,  4.1524e-01,  1.1584e+00,\n",
       "                       1.6899e-01,  1.8641e+00, -2.3655e+00,  1.3021e+00,  3.1142e-02,\n",
       "                       9.6197e-01, -1.9156e+00, -8.4323e-01,  1.0556e+00,  1.0644e+00,\n",
       "                       2.4274e-01,  8.7881e-01, -2.4905e+00,  1.8299e-01, -2.4645e-01,\n",
       "                       2.2611e+00, -2.8700e-01,  1.6174e+00, -1.7665e+00,  1.0825e+00,\n",
       "                      -9.2173e-01, -2.2372e-01,  3.1871e-01,  4.3417e-01, -2.0790e-01,\n",
       "                       7.5154e-01, -2.9844e-02, -1.9833e+00, -3.3880e-01, -1.1915e+00,\n",
       "                       6.8896e-01, -3.2590e-03, -2.1214e+00,  8.0398e-02, -4.3441e-01,\n",
       "                       1.5845e+00,  7.5630e-01, -1.1967e+00,  5.9342e-01, -7.8924e-01,\n",
       "                      -6.7578e-01, -3.5852e-01, -4.1476e-02,  2.4906e-01, -1.3925e+00,\n",
       "                       8.0031e-01,  1.7349e-01, -1.1299e-01,  1.7855e-01,  5.1972e-01,\n",
       "                       2.0248e-01, -1.9111e-01, -1.6821e-01, -8.9357e-01, -1.7071e-01,\n",
       "                       3.1847e-01,  2.5271e+00,  3.2035e-01, -1.0750e-02,  1.6569e+00,\n",
       "                      -1.5623e+00,  1.7243e-01,  2.1260e-01,  2.0935e+00,  7.6997e-02,\n",
       "                       7.2517e-01, -2.0591e+00, -4.7777e-01,  2.1396e-01, -1.8394e+00,\n",
       "                      -1.4121e+00, -6.7543e-02, -2.5321e+00,  1.0241e+00, -1.0559e+00,\n",
       "                      -1.5583e+00,  5.5745e-01,  4.4920e-01, -1.4996e+00, -6.8342e-01,\n",
       "                      -3.6165e-01, -7.6544e-01,  2.5023e-01,  5.9464e-01, -2.9519e-01,\n",
       "                      -1.5483e+00,  1.0999e+00, -4.1624e-01,  4.1148e-01,  7.5725e-01,\n",
       "                      -8.3112e-01,  1.7265e-01,  1.3686e+00,  2.8321e+00, -9.4354e-01,\n",
       "                      -1.3143e+00, -1.5668e+00, -2.4285e-01,  6.2426e-01,  9.0134e-01,\n",
       "                       3.6590e-01,  1.3980e+00,  2.7121e-01, -6.8650e-01,  4.1025e-01,\n",
       "                      -4.8545e-01,  1.1813e+00, -3.5685e-01,  2.7741e-01,  1.5947e+00,\n",
       "                       1.2969e+00, -2.8827e-01, -1.5108e+00, -1.9326e+00,  5.6687e-01,\n",
       "                      -2.2658e-01, -4.4597e-01,  1.7145e+00,  4.4102e-01, -1.1396e+00,\n",
       "                      -1.8966e+00,  7.0114e-01, -7.4000e-01,  1.2521e+00,  2.1616e-01,\n",
       "                      -1.0433e+00, -3.2997e-01,  6.8178e-01,  1.5471e+00,  8.1083e-01,\n",
       "                      -5.4803e-01, -1.4007e+00,  3.2279e-01, -1.0042e+00,  4.9461e-01,\n",
       "                       1.5629e+00,  9.4410e-01, -4.1633e-01, -2.8890e-01, -3.3429e-02,\n",
       "                       6.0815e-01, -7.2818e-01,  3.2982e-01,  1.9461e-01, -1.2570e+00,\n",
       "                       5.0803e-01, -5.2129e-01,  1.2354e+00, -9.5980e-01,  3.4521e-01,\n",
       "                      -4.4953e-01,  1.5971e+00, -1.1257e+00, -1.6751e+00,  1.2099e+00,\n",
       "                       1.5315e+00, -1.8571e+00,  7.7756e-01,  4.0290e-01, -3.5275e-01,\n",
       "                       6.8994e-02, -7.2664e-01, -8.4958e-02,  2.0424e+00, -1.6956e+00,\n",
       "                       1.3497e+00, -2.5621e-01, -1.0930e+00,  8.6460e-01,  9.9563e-01,\n",
       "                       2.3251e-01, -8.3745e-01,  1.2165e+00,  1.4126e+00, -5.6981e-01,\n",
       "                      -7.5691e-01,  5.1685e-01, -3.2062e-01,  2.1223e-01, -4.5185e-01,\n",
       "                       1.0365e+00,  1.4273e+00, -6.7840e-02, -8.5072e-01,  1.2410e+00,\n",
       "                       1.1440e-01,  1.7227e+00, -6.9193e-01, -1.1529e+00, -7.7171e-01,\n",
       "                       1.0140e+00, -2.7219e-01, -1.1730e+00,  3.0286e+00,  1.2594e+00,\n",
       "                       1.1144e+00, -2.1809e+00, -3.2635e+00,  2.3112e-01, -6.1271e-03,\n",
       "                      -5.1705e-02, -6.5764e-01,  6.5982e-02, -4.8739e-01, -4.0191e-03,\n",
       "                      -9.3830e-01,  5.5690e-01,  6.8073e-01,  3.3826e-01, -2.0084e+00,\n",
       "                      -1.6342e+00,  8.8469e-01, -1.1874e+00,  1.0758e+00, -9.2109e-01,\n",
       "                       1.0100e-01,  6.2243e-01, -1.9659e-01,  3.5856e-01, -1.7390e+00,\n",
       "                      -2.0682e-01, -8.2883e-01,  1.2257e+00, -8.4399e-01,  3.9963e-01,\n",
       "                       1.3024e+00, -1.1493e+00,  3.5034e-01, -5.6922e-01,  1.0768e+00,\n",
       "                       4.5513e-01,  1.1292e+00, -4.1290e-01, -7.1226e-01,  9.3239e-01,\n",
       "                      -2.1193e+00,  2.8170e-01,  5.3303e-01, -6.7513e-01,  1.0155e+00,\n",
       "                       1.9359e-01, -1.0183e+00,  1.2698e+00, -1.2082e+00,  8.8027e-01,\n",
       "                      -1.9578e-01, -5.2650e-01, -1.5956e-02, -5.4639e-01, -1.4491e+00,\n",
       "                       1.5714e+00,  1.7775e-01, -1.3277e+00, -3.3508e-01,  3.3170e-02,\n",
       "                      -1.7572e+00,  1.6813e+00, -8.3016e-01,  2.1868e-02,  1.5451e+00,\n",
       "                       5.1755e-01,  1.5573e+00, -9.6595e-01,  2.2550e+00, -1.5308e-01,\n",
       "                       1.2527e+00, -2.7822e+00, -3.2433e-04, -5.7964e-01,  8.5386e-01,\n",
       "                      -5.0459e-01,  5.2031e-01,  6.4884e-02, -2.2094e-01,  1.2541e+00,\n",
       "                       3.5102e-01, -6.6179e-01,  6.6902e-01,  8.5593e-01,  1.5098e-01,\n",
       "                      -2.6135e-01,  7.4128e-01,  3.8717e-02,  3.3020e-01, -6.9309e-01,\n",
       "                       2.0231e+00,  1.0422e+00, -7.9387e-01,  1.6824e+00,  1.7645e+00,\n",
       "                       6.1476e-01, -1.2276e+00, -1.5990e+00, -6.8269e-01,  8.1318e-04,\n",
       "                       1.6963e+00,  1.9381e-01], device='cuda:0')),\n",
       "             ('TranformerBlock.positional_embedding.conv.weight',\n",
       "              tensor([[[-0.0617, -0.0665, -0.0301,  ..., -0.0404, -0.0386, -0.0814],\n",
       "                       [ 0.0256,  0.0133,  0.0434,  ...,  0.0551,  0.0575,  0.0413],\n",
       "                       [-0.0234, -0.0348, -0.0229,  ..., -0.0404, -0.0347, -0.0396],\n",
       "                       ...,\n",
       "                       [-0.0525, -0.0639, -0.0289,  ..., -0.0189, -0.0347, -0.0357],\n",
       "                       [-0.0277, -0.0106, -0.0529,  ..., -0.0333, -0.0396, -0.0682],\n",
       "                       [ 0.0416,  0.0435,  0.0161,  ..., -0.0526, -0.0508,  0.0294]],\n",
       "              \n",
       "                      [[-0.0816, -0.0563, -0.0401,  ...,  0.0065, -0.0255,  0.0846],\n",
       "                       [ 0.0710,  0.0308,  0.0617,  ...,  0.0029, -0.0508, -0.0511],\n",
       "                       [-0.0699, -0.0425, -0.0679,  ...,  0.0318,  0.0281,  0.0511],\n",
       "                       ...,\n",
       "                       [-0.0339, -0.0645, -0.0481,  ...,  0.0319,  0.0722,  0.0500],\n",
       "                       [-0.0897, -0.0523, -0.0829,  ...,  0.0524,  0.0149,  0.0396],\n",
       "                       [ 0.0420,  0.0480,  0.0777,  ...,  0.0416,  0.0518, -0.0941]],\n",
       "              \n",
       "                      [[-0.0840, -0.0733, -0.0608,  ..., -0.0558, -0.0276,  0.0686],\n",
       "                       [ 0.0291,  0.0707,  0.0292,  ...,  0.0182,  0.0237, -0.0705],\n",
       "                       [-0.0465, -0.0597, -0.0634,  ..., -0.0583, -0.0246,  0.0189],\n",
       "                       ...,\n",
       "                       [-0.0313, -0.0687, -0.0492,  ...,  0.0595,  0.0284,  0.0145],\n",
       "                       [-0.0754, -0.0499, -0.0678,  ..., -0.0039, -0.0600,  0.0737],\n",
       "                       [ 0.0871,  0.0836,  0.0696,  ...,  0.0778,  0.0269, -0.0265]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0745, -0.1119, -0.0914,  ...,  0.0032,  0.0284, -0.0122],\n",
       "                       [ 0.0368,  0.0684,  0.0614,  ..., -0.0442, -0.0630, -0.0182],\n",
       "                       [-0.0399, -0.0133, -0.0707,  ...,  0.0235, -0.0004,  0.0555],\n",
       "                       ...,\n",
       "                       [ 0.0095,  0.0263,  0.0702,  ..., -0.0255, -0.0346, -0.0324],\n",
       "                       [-0.1184, -0.0740, -0.0951,  ...,  0.0550,  0.0287,  0.0389],\n",
       "                       [ 0.0614,  0.0618,  0.0697,  ..., -0.0438,  0.0639, -0.0216]],\n",
       "              \n",
       "                      [[-0.0179, -0.0074, -0.0167,  ..., -0.0476, -0.0305, -0.0373],\n",
       "                       [ 0.0406,  0.0620,  0.0979,  ...,  0.0569,  0.0093,  0.0305],\n",
       "                       [ 0.0419,  0.0640,  0.0521,  ..., -0.0912, -0.0290, -0.0151],\n",
       "                       ...,\n",
       "                       [-0.0581, -0.0389, -0.0477,  ...,  0.0714,  0.0945,  0.0654],\n",
       "                       [-0.0418, -0.0473, -0.0597,  ..., -0.0533, -0.0397, -0.0447],\n",
       "                       [-0.0787, -0.0879, -0.0634,  ...,  0.0750,  0.0729,  0.0737]],\n",
       "              \n",
       "                      [[ 0.0587,  0.0679,  0.0654,  ...,  0.0055,  0.0341,  0.0191],\n",
       "                       [-0.0890, -0.1020, -0.0749,  ..., -0.1266, -0.1107, -0.0338],\n",
       "                       [ 0.0820,  0.0668,  0.0771,  ..., -0.0071, -0.0103,  0.0034],\n",
       "                       ...,\n",
       "                       [ 0.0829,  0.0850,  0.0769,  ...,  0.1080,  0.1047, -0.0055],\n",
       "                       [ 0.0659,  0.0979,  0.1077,  ...,  0.0813,  0.1148,  0.0143],\n",
       "                       [ 0.0627,  0.0672,  0.1088,  ...,  0.0879,  0.0804,  0.0339]]],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.positional_embedding.conv.bias',\n",
       "              tensor([-8.9832e-02,  6.8125e-02,  4.7432e-02, -8.8370e-04,  1.3506e-02,\n",
       "                       9.1599e-02, -1.2033e-02,  7.1235e-02, -7.7894e-02, -6.9050e-02,\n",
       "                      -5.3791e-02,  3.4967e-02, -5.7642e-02,  3.8907e-02,  1.1862e-03,\n",
       "                      -2.1265e-03,  5.4391e-02,  3.7852e-02, -2.6072e-02,  5.4127e-02,\n",
       "                      -4.3254e-02,  9.1252e-02,  3.7988e-02,  2.0054e-02, -8.3624e-02,\n",
       "                       8.3877e-02,  8.2119e-02, -5.3642e-02,  4.1999e-02,  2.9940e-02,\n",
       "                      -7.8954e-02,  5.2315e-02, -3.5346e-02,  6.6004e-02, -6.0175e-03,\n",
       "                       5.5767e-02,  8.6748e-03, -3.9531e-02,  6.2977e-02, -3.2552e-02,\n",
       "                      -3.7561e-02,  1.0201e-01,  6.1876e-02, -5.5468e-02,  6.0506e-02,\n",
       "                       7.8922e-02, -6.6703e-02, -3.6952e-02,  8.5727e-02,  8.1118e-02,\n",
       "                      -3.3651e-03,  8.7937e-02,  6.2487e-02, -7.2315e-03,  3.4960e-02,\n",
       "                       8.7461e-03,  2.7263e-05,  7.2267e-02, -4.0058e-03,  3.5609e-02,\n",
       "                       6.4452e-02,  5.6697e-02, -2.7962e-02,  8.4321e-02,  9.8340e-03,\n",
       "                       5.6472e-02,  6.7516e-02, -4.3115e-02, -6.7392e-03,  5.1185e-02,\n",
       "                       5.6984e-02,  5.5143e-02,  1.5998e-02,  7.4133e-02, -4.8992e-03,\n",
       "                      -4.2390e-02, -5.7972e-02, -3.0634e-02,  4.2720e-02, -6.0456e-02,\n",
       "                       8.0587e-02,  4.1424e-02,  6.3528e-02, -5.1037e-02, -6.8941e-03,\n",
       "                       2.2757e-02, -7.6268e-02, -4.3447e-02,  5.4616e-02,  1.0703e-01,\n",
       "                       4.2114e-03,  8.2643e-02, -4.7315e-02,  2.7899e-02, -5.8100e-02,\n",
       "                       1.0073e-02, -5.3589e-02, -4.7481e-02, -1.1549e-01,  5.9262e-02,\n",
       "                       9.4900e-02, -8.9041e-02, -4.3238e-02,  7.6537e-02, -1.1336e-01,\n",
       "                      -3.8652e-02,  1.1813e-01, -8.7494e-02, -1.4466e-02,  9.0656e-02,\n",
       "                       2.5987e-02, -8.8099e-02, -7.1095e-02,  3.2399e-02, -3.8048e-02,\n",
       "                       3.6066e-02, -3.6471e-02, -1.6120e-02, -3.4662e-02,  4.6657e-02,\n",
       "                       1.0010e-01,  1.0592e-01, -5.1424e-03,  3.7246e-02, -7.9127e-02,\n",
       "                      -3.6176e-02,  4.4337e-02, -8.4480e-02, -5.9967e-02,  8.6385e-02,\n",
       "                      -8.9383e-02, -1.3626e-01, -1.0991e-01,  3.9046e-02, -3.1719e-02,\n",
       "                      -6.7274e-02, -3.8881e-02, -9.1131e-02, -2.8072e-02, -7.3532e-03,\n",
       "                      -6.9497e-02,  3.5587e-03, -7.2372e-02, -3.6927e-02, -2.7079e-02,\n",
       "                      -7.4801e-02, -1.1631e-02,  4.8943e-02,  5.8734e-02, -6.6328e-02,\n",
       "                       1.3405e-02, -6.2237e-02, -2.4586e-02, -9.2271e-02,  1.5175e-03,\n",
       "                       9.5414e-02, -8.2375e-02,  4.5468e-02,  1.9224e-02,  5.0295e-02,\n",
       "                      -3.6389e-03, -2.8399e-02,  1.2760e-02,  6.2904e-02, -1.1975e-01,\n",
       "                      -6.8047e-03, -3.6828e-02, -5.4412e-02,  7.8100e-02,  6.1193e-03,\n",
       "                      -3.4548e-02,  1.1261e-02, -6.9665e-02, -3.7259e-02,  5.1696e-02,\n",
       "                       2.5522e-02,  4.4399e-02,  3.3385e-02, -6.2461e-02,  8.0516e-02,\n",
       "                      -1.1841e-01,  3.5818e-02,  2.6385e-02,  6.8901e-02,  8.0104e-02,\n",
       "                       2.0203e-02,  5.9954e-02,  6.5005e-02, -3.7106e-02, -7.7241e-03,\n",
       "                       5.3606e-02,  8.8274e-02,  6.4026e-02, -5.0202e-02,  5.4928e-02,\n",
       "                       5.5460e-03,  1.1421e-02, -5.4562e-02,  6.1392e-02, -7.0501e-02,\n",
       "                       8.6334e-03,  5.6241e-03,  7.8215e-02,  5.5100e-02,  5.7419e-02,\n",
       "                       1.9674e-02, -5.7540e-02, -1.5893e-02, -3.8631e-02, -3.7566e-02,\n",
       "                       5.2173e-02,  2.8382e-02,  9.7280e-02,  3.8184e-02,  6.6517e-02,\n",
       "                      -6.1866e-04, -3.7227e-02, -5.2106e-02,  1.5701e-02,  2.4155e-02,\n",
       "                       7.9563e-02, -6.9424e-03, -5.4592e-02,  4.4769e-02,  2.4724e-04,\n",
       "                      -1.2507e-01,  6.1935e-02, -6.6550e-02, -4.8181e-02,  7.1900e-02,\n",
       "                      -4.2272e-03, -4.5639e-02,  8.1623e-02,  3.5988e-02,  6.3207e-02,\n",
       "                      -2.3306e-02,  1.6220e-02,  4.4641e-02,  8.8100e-02,  7.9308e-02,\n",
       "                       8.8095e-02, -7.2724e-02,  1.5468e-02,  8.6505e-02, -1.2354e-01,\n",
       "                      -2.1313e-02, -7.6103e-02, -9.6262e-02, -6.5450e-02, -1.0564e-01,\n",
       "                       3.5332e-02, -2.6223e-02, -1.0238e-01,  6.3989e-02, -3.7076e-02,\n",
       "                      -5.3423e-02, -4.3271e-03,  1.1229e-02,  3.5720e-02,  1.0447e-02,\n",
       "                      -3.8671e-02,  7.9760e-02,  1.3534e-02, -6.0290e-02, -7.1925e-02,\n",
       "                       1.8903e-02, -3.5928e-02, -3.8830e-02, -3.9805e-02,  6.3802e-02,\n",
       "                       2.8080e-02, -2.2152e-02,  1.4156e-02, -4.3730e-02,  4.4491e-02,\n",
       "                       5.8215e-02, -7.9838e-03,  6.7256e-02,  6.3798e-02, -5.4996e-02,\n",
       "                       7.6541e-03, -2.5208e-02, -4.8783e-02,  3.5480e-02, -5.0304e-02,\n",
       "                      -4.4818e-02, -8.2350e-02,  8.3308e-03, -6.0368e-02,  2.6127e-02,\n",
       "                       3.2579e-02,  8.8447e-02,  5.4141e-02,  4.2496e-02, -2.5934e-02,\n",
       "                       8.0824e-02,  7.8503e-02, -3.6113e-02, -3.9824e-02,  3.7150e-02,\n",
       "                      -5.5302e-02,  1.7337e-02,  7.6664e-02, -4.4937e-02,  3.1321e-02,\n",
       "                       7.5883e-02,  3.2978e-02, -1.0258e-02,  5.5266e-02,  3.6466e-02,\n",
       "                      -1.0084e-02,  5.0208e-02, -5.0800e-02, -2.9017e-03, -6.7373e-02,\n",
       "                       8.1100e-02,  6.8198e-02,  1.7731e-02, -6.8350e-02,  3.4258e-02,\n",
       "                      -3.0609e-02,  4.1011e-02,  3.6189e-02, -4.2567e-02,  4.1221e-02,\n",
       "                      -3.7289e-02, -9.6279e-03,  3.6826e-02,  8.9078e-03,  7.8077e-02,\n",
       "                       7.4057e-02, -2.6337e-02, -1.2577e-02,  5.4898e-02,  7.9168e-02,\n",
       "                       4.9345e-02,  5.8120e-02,  6.7616e-03,  2.4845e-02, -7.5001e-02,\n",
       "                      -4.6925e-02,  7.4804e-02,  2.3851e-02,  5.1315e-02,  6.0041e-02,\n",
       "                      -7.3219e-02, -3.5320e-02,  6.4698e-02,  8.8219e-02,  5.6982e-03,\n",
       "                       8.3198e-02,  1.0508e-01,  9.7073e-02,  2.2915e-03,  7.9522e-02,\n",
       "                       5.0645e-02, -6.3002e-03,  5.5594e-02,  3.0710e-02,  4.3565e-02,\n",
       "                       6.9940e-02,  7.2066e-02,  5.4952e-02, -8.4197e-03, -5.3886e-02,\n",
       "                       6.5209e-02,  1.2882e-01,  3.9145e-02, -5.7958e-02,  6.7641e-02,\n",
       "                       1.5691e-02, -4.4325e-02,  6.9612e-03, -3.1562e-03,  6.9475e-02,\n",
       "                       4.6234e-02,  1.8942e-02,  4.9985e-02, -4.7409e-02, -7.7828e-02,\n",
       "                      -4.0770e-02, -7.3180e-02, -8.7623e-02, -8.5290e-03,  8.3409e-03,\n",
       "                       6.7099e-02, -4.4077e-02,  6.8557e-02, -5.4707e-02,  1.7022e-02,\n",
       "                       5.0774e-02,  6.1573e-02,  2.9371e-02, -1.1991e-01,  7.0023e-02,\n",
       "                       1.7452e-02, -4.1820e-02,  6.9799e-02,  2.1523e-02,  6.6634e-02,\n",
       "                       6.2104e-02, -2.5613e-02, -6.2689e-02,  4.8021e-02, -7.2669e-02,\n",
       "                      -2.8565e-02,  5.0424e-02,  6.6999e-03,  4.8550e-02,  1.0652e-02,\n",
       "                      -4.7961e-02,  4.7613e-02, -5.0719e-03,  3.7564e-03, -3.4744e-03,\n",
       "                       1.6363e-02, -8.9241e-02,  2.9837e-02, -7.5069e-02, -7.0017e-02,\n",
       "                       2.3063e-02,  5.1320e-02,  1.7720e-02, -1.4879e-02,  2.9306e-02,\n",
       "                       7.9568e-02,  6.1022e-04, -4.7608e-02,  6.7175e-02,  7.4731e-02,\n",
       "                      -4.7489e-02,  5.5747e-02, -5.0463e-02,  3.3798e-02, -3.8983e-02,\n",
       "                       7.2071e-02,  3.1399e-02, -2.2721e-02,  6.5953e-03, -6.4912e-02,\n",
       "                       6.9140e-02, -1.0669e-01, -4.1912e-02,  4.4294e-02,  1.9651e-02,\n",
       "                       4.4285e-02, -7.2655e-02, -7.3081e-02, -6.3180e-02,  2.8479e-03,\n",
       "                       4.4824e-02, -7.0340e-03, -2.3941e-02, -7.0112e-02,  5.8188e-02,\n",
       "                      -3.7708e-02, -8.2775e-02,  2.1740e-02, -5.4064e-02,  3.0912e-02,\n",
       "                      -9.6702e-02,  1.9884e-02,  2.2246e-02,  5.2779e-02, -2.4802e-02,\n",
       "                      -1.2390e-01,  2.3970e-02,  3.4398e-02, -2.8747e-02, -8.7187e-02,\n",
       "                       1.1402e-02, -6.2915e-02,  6.6966e-02, -7.4380e-02, -3.6493e-02,\n",
       "                      -9.4001e-03, -5.3231e-08,  4.5292e-02,  1.8867e-02,  4.9573e-02,\n",
       "                       6.4859e-02,  4.9875e-02,  6.3270e-02,  4.2001e-02, -7.7027e-02,\n",
       "                       5.1553e-02,  1.2505e-01, -3.4095e-03,  5.3210e-02,  5.5537e-02,\n",
       "                       2.3158e-02,  3.5752e-02, -1.8082e-02, -4.5569e-02, -1.0325e-04,\n",
       "                       3.0807e-02,  1.1996e-01,  5.9345e-02,  4.2004e-02,  3.7404e-02,\n",
       "                       2.8283e-02, -9.1748e-03, -1.1567e-01, -2.0351e-02,  3.1579e-02,\n",
       "                       9.3728e-02, -5.5350e-02, -5.0808e-02, -6.1090e-02,  1.0708e-02,\n",
       "                      -6.0082e-02,  6.9655e-03], device='cuda:0')),\n",
       "             ('TranformerBlock.positional_embedding.norm.weight',\n",
       "              tensor([0.9562, 1.0441, 1.0531, 1.0769, 0.9756, 1.0630, 1.0788, 1.0441, 0.9368,\n",
       "                      0.9637, 0.9331, 1.0651, 0.9368, 0.9393, 0.9368, 1.0644, 0.9620, 0.9442,\n",
       "                      0.9456, 1.0082, 1.0913, 0.9172, 1.0746, 1.0620, 0.9465, 1.0512, 0.9659,\n",
       "                      0.9552, 1.0568, 1.0591, 0.9669, 1.0681, 0.9506, 1.1223, 1.0526, 0.9832,\n",
       "                      1.0630, 1.0292, 0.9363, 1.0830, 0.9483, 0.9191, 1.1124, 0.9228, 1.0334,\n",
       "                      0.9957, 0.9381, 0.9393, 1.0616, 1.0810, 1.0815, 1.0272, 0.9527, 1.1134,\n",
       "                      1.0703, 1.0678, 1.0700, 0.9617, 0.9511, 1.0056, 0.9350, 1.0403, 1.0665,\n",
       "                      0.9429, 0.9529, 0.9479, 0.9375, 0.9569, 0.9323, 1.0318, 0.9308, 0.9307,\n",
       "                      0.9282, 1.0584, 0.9485, 0.9551, 0.9543, 1.1057, 0.9999, 1.0409, 1.0477,\n",
       "                      1.0570, 0.9155, 0.9499, 1.0492, 1.0449, 0.9502, 0.9755, 1.0739, 0.9301,\n",
       "                      1.0023, 0.9141, 1.0622, 1.0276, 0.9500, 0.9236, 1.0496, 1.1184, 0.9344,\n",
       "                      0.9365, 1.0849, 0.9387, 1.0601, 1.0577, 0.9110, 1.0154, 0.9615, 1.0469,\n",
       "                      0.9208, 0.9441, 1.0474, 1.0992, 0.9312, 1.0847, 1.0467, 1.0102, 1.0220,\n",
       "                      1.0819, 0.9866, 0.9425, 1.0284, 0.9875, 0.9656, 1.0843, 0.9785, 0.9284,\n",
       "                      1.0646, 0.9721, 1.0287, 0.9211, 0.9511, 0.9304, 0.9964, 1.0258, 1.0482,\n",
       "                      0.9525, 0.9620, 0.9450, 0.9323, 0.9362, 0.9792, 1.0618, 0.9055, 0.9505,\n",
       "                      0.9342, 0.9769, 1.0803, 0.9514, 1.0072, 0.9520, 1.0426, 0.9298, 0.9218,\n",
       "                      0.9516, 1.0406, 0.9200, 0.9490, 1.0120, 1.0139, 1.0614, 0.9460, 1.0182,\n",
       "                      1.0639, 0.9665, 1.0595, 0.9913, 0.9356, 1.0582, 0.9787, 1.0318, 1.0384,\n",
       "                      0.9812, 0.9525, 1.0068, 1.0633, 1.0260, 1.0265, 0.9537, 0.9326, 0.9913,\n",
       "                      0.9105, 1.0338, 1.0452, 1.0439, 0.9498, 0.9975, 1.0470, 1.0281, 1.0483,\n",
       "                      1.0492, 0.9384, 0.9223, 0.9475, 0.9550, 1.0946, 0.9493, 0.9151, 0.9479,\n",
       "                      1.0717, 1.0465, 0.9577, 0.9325, 1.0725, 1.0618, 1.0384, 1.0092, 0.9412,\n",
       "                      1.0323, 0.9429, 0.9432, 0.9686, 1.0305, 1.0440, 1.0884, 0.9777, 0.9377,\n",
       "                      1.0977, 0.9480, 0.9917, 0.9466, 1.0548, 0.9208, 1.0586, 1.0475, 0.9965,\n",
       "                      0.9179, 1.0652, 0.9609, 0.9448, 0.9360, 0.9157, 0.9214, 0.9274, 1.0505,\n",
       "                      1.0681, 1.0436, 1.0133, 1.0491, 1.0052, 0.9710, 0.9670, 0.9876, 1.0247,\n",
       "                      1.0352, 1.0112, 1.0434, 0.9590, 1.0050, 0.9359, 0.9385, 0.9234, 0.9285,\n",
       "                      1.0457, 1.0162, 0.9462, 1.0339, 0.9280, 1.0354, 0.9527, 1.0350, 1.0588,\n",
       "                      1.0417, 1.0364, 0.9521, 0.9373, 0.9545, 0.9459, 0.9556, 0.9686, 1.0333,\n",
       "                      0.9659, 0.9425, 1.0148, 0.9317, 0.9366, 0.9323, 1.0280, 0.9349, 0.9969,\n",
       "                      0.9265, 0.9348, 0.9482, 0.9226, 0.9297, 1.0357, 0.9763, 0.9225, 0.9311,\n",
       "                      0.9306, 0.9551, 1.0403, 1.0508, 1.0658, 1.0594, 1.0481, 0.9375, 1.0490,\n",
       "                      0.9355, 0.9567, 1.1028, 0.9542, 1.0754, 1.0704, 0.9373, 1.0003, 1.0523,\n",
       "                      0.9999, 1.0422, 0.9180, 1.0341, 0.9407, 0.9158, 0.9432, 1.0452, 0.9886,\n",
       "                      0.9615, 1.0252, 0.9578, 0.9449, 0.9463, 1.0077, 0.9621, 0.9113, 0.9607,\n",
       "                      1.0497, 1.0111, 1.0321, 1.0580, 1.0327, 1.0504, 1.0479, 1.0191, 1.0934,\n",
       "                      0.9904, 1.0401, 1.0379, 1.0373, 1.1276, 1.0506, 0.9572, 0.9557, 1.0523,\n",
       "                      1.0629, 0.9644, 1.0674, 0.9533, 1.0357, 1.0476, 1.0682, 0.9466, 0.9408,\n",
       "                      1.0559, 1.0586, 1.0639, 1.0544, 1.0647, 1.0883, 0.9973, 1.0634, 1.0893,\n",
       "                      0.9559, 0.9740, 0.9285, 1.0828, 0.9384, 0.9793, 1.0391, 1.0908, 0.9805,\n",
       "                      0.9761, 0.9298, 0.9240, 1.0863, 0.9241, 1.0687, 0.9847, 1.0056, 0.9101,\n",
       "                      0.9293, 0.9157, 0.9198, 1.0205, 0.9168, 1.0561, 1.0396, 0.9907, 0.9015,\n",
       "                      1.0227, 0.9413, 1.0318, 1.1250, 0.9458, 0.9392, 0.9127, 1.0510, 1.0236,\n",
       "                      0.9385, 1.0489, 0.8865, 1.0646, 1.0296, 0.9352, 0.9316, 1.0565, 0.9500,\n",
       "                      0.9509, 1.0442, 1.0645, 0.9206, 1.0666, 1.1032, 1.0427, 1.0103, 0.9904,\n",
       "                      0.9335, 0.9820, 0.9274, 0.9897, 0.9626, 0.9086, 0.9573, 1.0260, 0.9960,\n",
       "                      0.9557, 0.9953, 0.9340, 0.9438, 1.0543, 1.0410, 1.0620, 0.9731, 1.0398,\n",
       "                      0.9582, 1.0995, 0.9323, 0.9415, 1.0326, 0.9607, 1.0694, 0.9270, 1.0466,\n",
       "                      0.9300, 0.9325, 0.9854, 0.9711, 0.9351, 0.9544, 0.9204, 0.9498, 0.9378,\n",
       "                      0.9003, 1.0451, 0.9677, 0.9544, 1.0733, 1.0377, 0.9343, 1.0215, 1.0582,\n",
       "                      0.9710, 0.9227, 1.0379, 1.0895, 1.0523, 1.0501, 0.9389, 0.9268, 0.8918,\n",
       "                      0.9511, 0.9365, 1.0465, 0.9554, 0.9327, 0.9213, 0.9350, 1.0255, 1.0128,\n",
       "                      1.1117, 1.0661, 0.9434, 1.0287, 0.9449, 0.9950, 1.0096, 0.9444, 1.0340,\n",
       "                      0.9655, 0.9301, 1.0464, 0.9520, 1.0424, 1.0300, 0.9938, 0.9445, 0.9501,\n",
       "                      1.0362, 1.1224, 0.9441, 0.9249, 0.9874, 1.0791, 0.9333, 0.9467, 0.9668,\n",
       "                      1.0267, 1.0586, 0.9529, 0.9861, 0.9493, 1.0239, 1.1158, 1.1025],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.positional_embedding.norm.bias',\n",
       "              tensor([-0.0492, -0.0645, -0.0160, -0.0309,  0.0765,  0.0167, -0.0539,  0.0493,\n",
       "                      -0.0552, -0.0686, -0.0566,  0.0164, -0.0546,  0.0795,  0.0510, -0.0648,\n",
       "                      -0.0056,  0.0773, -0.0502, -0.0105, -0.0637,  0.0632, -0.0456, -0.0014,\n",
       "                      -0.0671,  0.0541,  0.0622, -0.0514, -0.0577,  0.0278, -0.0777, -0.0090,\n",
       "                      -0.0397,  0.0795, -0.0537,  0.0724,  0.0199, -0.0100,  0.0426, -0.0534,\n",
       "                      -0.0364,  0.1029,  0.1057, -0.0622, -0.0488,  0.0351, -0.0699,  0.0754,\n",
       "                       0.0824,  0.0515, -0.0617,  0.0336,  0.0444,  0.0847, -0.0619, -0.0656,\n",
       "                      -0.0609,  0.0330, -0.0249,  0.0326,  0.0657, -0.0204, -0.0704,  0.0973,\n",
       "                       0.0838,  0.0781,  0.0799, -0.0585,  0.0464, -0.0516,  0.0216,  0.0687,\n",
       "                       0.0738,  0.0193, -0.0585, -0.0512, -0.0516,  0.0505,  0.0894, -0.0405,\n",
       "                       0.0489,  0.0438,  0.0594,  0.0539, -0.0685, -0.0642, -0.0502, -0.0735,\n",
       "                       0.0506,  0.0802, -0.0061,  0.0459, -0.0478, -0.0035, -0.0509,  0.0192,\n",
       "                      -0.0510, -0.1282,  0.0609,  0.0806,  0.0861,  0.0395, -0.0738,  0.1001,\n",
       "                       0.0223, -0.0460,  0.0956, -0.0582,  0.0429,  0.0528,  0.0223, -0.0938,\n",
       "                      -0.0195, -0.0641, -0.0669,  0.0707, -0.0477, -0.0626,  0.0012,  0.0561,\n",
       "                       0.1030,  0.0753, -0.0040,  0.1153, -0.0571, -0.0098,  0.0308,  0.0409,\n",
       "                      -0.0214,  0.0791, -0.0697,  0.0497,  0.0024,  0.0274, -0.0502, -0.0650,\n",
       "                       0.0745,  0.0560,  0.0492,  0.0652,  0.0179, -0.0729, -0.0649, -0.0781,\n",
       "                      -0.0542, -0.0572, -0.0811,  0.0395,  0.0322,  0.0304,  0.0320,  0.0498,\n",
       "                      -0.0100, -0.0712,  0.0107,  0.0661,  0.0510,  0.0656, -0.0441,  0.0509,\n",
       "                       0.0544,  0.0218,  0.0501,  0.0214, -0.0607, -0.0468, -0.0638, -0.0481,\n",
       "                       0.0703, -0.0487, -0.0534,  0.0294, -0.0501,  0.0116,  0.0335,  0.0524,\n",
       "                      -0.0167,  0.0437, -0.0529,  0.0135,  0.0913,  0.0453, -0.0653,  0.0458,\n",
       "                       0.0485,  0.0031,  0.0398, -0.0506, -0.0757, -0.0324,  0.0446,  0.0863,\n",
       "                       0.0619, -0.0671,  0.0279,  0.0610,  0.0825, -0.0451,  0.0826, -0.0451,\n",
       "                       0.0726,  0.0595,  0.0685,  0.0334,  0.0387,  0.0987, -0.0510, -0.0494,\n",
       "                      -0.0546, -0.0653,  0.0987,  0.0511,  0.0980,  0.0726, -0.0779,  0.0597,\n",
       "                      -0.0912, -0.0516,  0.0181,  0.0594,  0.0588,  0.0656, -0.0575, -0.0667,\n",
       "                      -0.0280,  0.0811,  0.0194, -0.0734, -0.0577,  0.0522,  0.0670, -0.0568,\n",
       "                       0.0604,  0.0507,  0.0571, -0.0391, -0.0218, -0.0094, -0.0255,  0.0784,\n",
       "                       0.0611, -0.0988,  0.0210,  0.0561, -0.0091, -0.0457, -0.0554, -0.0482,\n",
       "                       0.0633,  0.0624,  0.0817,  0.0511, -0.0679, -0.0341,  0.0584, -0.0520,\n",
       "                       0.0611, -0.0530,  0.0567, -0.0075, -0.0573, -0.0287, -0.0546, -0.0353,\n",
       "                      -0.0556,  0.0658,  0.0544, -0.0599, -0.0756, -0.0358, -0.0903,  0.0516,\n",
       "                      -0.0106, -0.0599,  0.0855,  0.0766, -0.0243,  0.0766,  0.0860,  0.0748,\n",
       "                      -0.0086,  0.0590, -0.0781,  0.0547, -0.0536, -0.0116,  0.0785,  0.0704,\n",
       "                      -0.0380,  0.0633, -0.0580,  0.0686,  0.0548,  0.0462,  0.0504,  0.0273,\n",
       "                       0.0356, -0.0460, -0.0585, -0.0943, -0.0788, -0.0167,  0.0820, -0.0248,\n",
       "                      -0.0314,  0.0201,  0.0880, -0.0566,  0.0630, -0.0545,  0.0609,  0.0737,\n",
       "                      -0.0063, -0.0316, -0.0887,  0.0760, -0.0274,  0.0310, -0.0302,  0.0535,\n",
       "                       0.0008,  0.0507,  0.0706, -0.0556, -0.0340, -0.0230, -0.0262, -0.0497,\n",
       "                      -0.0431, -0.0710, -0.0624, -0.0120, -0.0803,  0.0221,  0.0293, -0.0561,\n",
       "                       0.0201, -0.0608,  0.0386, -0.0681, -0.0523,  0.0658,  0.0515,  0.0741,\n",
       "                      -0.0099, -0.0521, -0.1419,  0.0503,  0.0562,  0.0658,  0.0526, -0.0238,\n",
       "                       0.0816,  0.0381,  0.0601, -0.0669, -0.0582, -0.0024, -0.0663, -0.0099,\n",
       "                       0.0384,  0.1043,  0.0575, -0.0802,  0.0525,  0.0988,  0.0785, -0.0418,\n",
       "                      -0.0468,  0.0837,  0.0454, -0.0596,  0.0809,  0.0774,  0.0720,  0.0980,\n",
       "                       0.1051,  0.0705, -0.0162,  0.0690, -0.0196, -0.0793, -0.0750, -0.0570,\n",
       "                      -0.0585,  0.0931, -0.0184,  0.0296, -0.0370,  0.0201, -0.1082,  0.0630,\n",
       "                       0.0050,  0.0880,  0.0508,  0.0303, -0.0550,  0.0529,  0.0918,  0.0337,\n",
       "                      -0.0293, -0.0158, -0.0627,  0.0349, -0.0463, -0.0584, -0.0625,  0.0004,\n",
       "                       0.0890, -0.0135, -0.0809, -0.0616,  0.0059,  0.0678,  0.0883,  0.0038,\n",
       "                      -0.0248,  0.0272,  0.0344, -0.1079,  0.0478,  0.0511, -0.0345,  0.0442,\n",
       "                       0.0180,  0.0862, -0.0375, -0.0766,  0.0628,  0.0748, -0.0080,  0.0740,\n",
       "                      -0.0155, -0.0233, -0.0338,  0.0248, -0.0178,  0.0350, -0.0772, -0.0386,\n",
       "                       0.0715,  0.0494,  0.0478,  0.0188,  0.0411,  0.0621, -0.0394,  0.0823,\n",
       "                      -0.0790, -0.0572,  0.0790, -0.0388, -0.0551, -0.0137,  0.0471, -0.0572,\n",
       "                      -0.0535, -0.0111, -0.0533, -0.0635,  0.0567, -0.0272, -0.0774,  0.0460,\n",
       "                      -0.0478,  0.0627,  0.0727,  0.0817, -0.0447, -0.0465, -0.0081, -0.0473,\n",
       "                       0.0489,  0.0808, -0.0301, -0.0013, -0.0132,  0.0343, -0.0589,  0.0369,\n",
       "                       0.0911,  0.0689,  0.0694, -0.0198, -0.0992,  0.0551,  0.0735,  0.0498,\n",
       "                       0.0585,  0.0730, -0.0357, -0.0279,  0.0026, -0.0119,  0.0677, -0.0531,\n",
       "                       0.1284,  0.0961,  0.0662,  0.0655,  0.0017,  0.0013,  0.0470, -0.0284,\n",
       "                      -0.0433,  0.0884, -0.0291,  0.0046, -0.0719,  0.0125, -0.0688,  0.1092],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.attention.query.weight',\n",
       "              tensor([[-0.1017, -0.0090,  0.0999,  ..., -0.0380, -0.0393,  0.0282],\n",
       "                      [-0.1221, -0.0179,  0.0596,  ..., -0.0694, -0.0656,  0.0017],\n",
       "                      [ 0.0693,  0.0150, -0.0581,  ..., -0.0065,  0.0110, -0.0277],\n",
       "                      ...,\n",
       "                      [-0.0061,  0.0781,  0.0734,  ..., -0.0492,  0.1140, -0.0565],\n",
       "                      [ 0.0019,  0.0225,  0.0151,  ..., -0.0126,  0.0825, -0.1345],\n",
       "                      [-0.0087,  0.0374,  0.0017,  ..., -0.0338,  0.1024, -0.0915]],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.attention.query.bias',\n",
       "              tensor([ 4.1770e-02,  9.2673e-03, -6.4864e-03,  2.8107e-02,  3.5349e-02,\n",
       "                      -1.3753e-02, -6.2515e-03,  1.4871e-02,  5.1798e-02, -3.5916e-04,\n",
       "                       2.4887e-02, -4.1807e-02,  2.2944e-02,  4.5518e-03,  8.4748e-04,\n",
       "                       4.5076e-03, -5.8553e-02, -9.5424e-03, -2.6656e-02,  4.0817e-02,\n",
       "                       8.7168e-03, -2.5947e-02, -3.1098e-02, -1.8950e-02,  4.5066e-02,\n",
       "                      -4.7668e-02, -6.3452e-02, -2.1310e-02,  2.4547e-02,  4.1041e-02,\n",
       "                       1.6369e-02, -3.1757e-02, -9.4291e-03,  2.3942e-02, -2.3861e-02,\n",
       "                       5.8072e-02, -8.5473e-03, -7.3384e-03, -2.4560e-02,  6.1249e-02,\n",
       "                      -5.7502e-02, -7.8637e-02, -5.0733e-02, -2.1553e-02, -3.1196e-03,\n",
       "                       8.7068e-03, -5.7709e-03,  1.6663e-02, -1.9733e-02,  1.6335e-03,\n",
       "                      -2.4993e-02,  4.2395e-02,  5.4346e-02, -3.8656e-02,  8.2745e-03,\n",
       "                       3.4675e-02, -2.9218e-03, -4.6204e-02, -5.7121e-03, -5.1831e-02,\n",
       "                       2.4914e-02,  3.3845e-04,  5.7009e-02, -1.0796e-01, -4.7455e-02,\n",
       "                       8.8141e-02,  5.8991e-02,  3.3266e-02,  5.1792e-02, -8.3522e-02,\n",
       "                       3.8412e-03, -4.3357e-02, -6.7969e-02, -6.0176e-02, -8.8894e-02,\n",
       "                       4.8417e-02,  3.0987e-02, -3.9434e-02,  8.6560e-02,  8.3018e-02,\n",
       "                       3.3704e-02, -4.0225e-02, -5.9343e-02, -4.5249e-02, -5.3377e-02,\n",
       "                       8.8301e-02,  1.2184e-02,  2.1218e-02,  3.3797e-02,  5.8140e-02,\n",
       "                      -2.7452e-02, -9.8354e-02, -8.5648e-02,  5.6358e-02, -5.5809e-02,\n",
       "                      -3.3870e-02, -1.0303e-01, -5.1395e-02,  5.1617e-02, -6.2658e-02,\n",
       "                      -8.2529e-02,  4.0444e-02,  5.0124e-02, -5.0553e-02,  6.0153e-02,\n",
       "                      -2.6109e-04,  6.7914e-02,  4.3210e-02,  9.4538e-03, -3.3220e-02,\n",
       "                      -6.4401e-02, -4.9465e-02, -3.0696e-02, -1.0774e-01,  1.9725e-02,\n",
       "                       5.5922e-02, -9.4042e-02,  1.3368e-02, -2.7064e-02,  7.9123e-02,\n",
       "                       3.7604e-04,  2.5123e-03, -7.5328e-02, -7.7202e-02,  4.4690e-02,\n",
       "                       5.6247e-02, -6.8816e-02,  5.3559e-02,  8.6330e-02, -5.3445e-02,\n",
       "                      -7.3921e-02,  6.3433e-02, -2.4445e-02, -4.9084e-02, -7.9049e-02,\n",
       "                       2.1711e-02, -2.3082e-02,  5.1716e-02,  2.1687e-02,  4.3318e-02,\n",
       "                       7.7951e-02, -3.5305e-02, -2.0602e-02, -2.4332e-02, -2.2615e-02,\n",
       "                      -4.6422e-02,  2.6076e-02, -3.3698e-02, -8.3547e-03, -7.0709e-02,\n",
       "                      -1.8072e-02, -3.3570e-02, -6.6071e-02,  7.8397e-02,  5.7828e-02,\n",
       "                       6.4514e-03,  8.1013e-03,  4.4686e-02, -1.0557e-02,  2.6119e-02,\n",
       "                       3.6013e-02,  1.0748e-01, -1.8564e-02, -2.5140e-02,  7.1467e-02,\n",
       "                      -2.4198e-02,  7.8771e-02, -5.9607e-02,  7.8199e-03,  6.7307e-02,\n",
       "                      -9.8317e-02,  4.3657e-02, -6.9042e-02,  9.7114e-02, -7.5889e-02,\n",
       "                      -1.2168e-02,  2.7876e-02,  2.6502e-02,  1.9284e-02, -4.2682e-02,\n",
       "                      -3.7726e-02, -2.8648e-02,  3.7460e-02,  1.5905e-02, -7.6233e-02,\n",
       "                       1.3502e-03,  4.7519e-02, -5.9718e-02, -2.5426e-03, -1.6519e-02,\n",
       "                      -4.3069e-02,  8.4246e-03, -1.0164e-01, -8.5388e-02,  9.2904e-02,\n",
       "                       3.6505e-02, -8.6436e-02, -3.6750e-02,  4.9193e-02,  6.9283e-02,\n",
       "                       2.0189e-02, -4.2698e-02,  9.7720e-03,  1.0103e-01,  1.1389e-01,\n",
       "                       5.7758e-02, -7.2950e-02,  9.9031e-02,  1.3087e-01,  4.8132e-02,\n",
       "                       7.1519e-02, -1.0877e-01, -8.8590e-02, -3.9242e-02, -7.7773e-02,\n",
       "                      -5.6889e-02,  4.9709e-02,  1.2087e-02,  8.6782e-02,  4.5711e-02,\n",
       "                      -7.2548e-02, -3.3843e-02, -6.1844e-02, -8.6241e-02,  5.5786e-02,\n",
       "                      -3.0473e-02, -1.0943e-01,  3.2645e-02,  5.4920e-02, -6.0304e-02,\n",
       "                       6.2631e-02, -1.1446e-01, -7.6111e-02, -7.5345e-02, -2.0025e-02,\n",
       "                       6.6443e-02, -4.4232e-02, -6.4110e-02, -7.6815e-02,  6.7530e-02,\n",
       "                      -1.6398e-02, -4.9726e-02, -5.6352e-02,  5.9875e-02,  2.6212e-02,\n",
       "                       1.0282e-01, -2.8325e-02, -1.1390e-01, -3.7111e-02,  9.6323e-02,\n",
       "                       4.4089e-02, -5.4244e-02,  7.8513e-02, -4.5664e-02,  4.4953e-02,\n",
       "                      -4.8263e-02,  5.8714e-02, -4.9670e-02, -9.9230e-02, -1.6289e-02,\n",
       "                       6.1780e-02, -6.3159e-02,  2.9836e-02, -2.5783e-02, -6.6316e-02,\n",
       "                      -8.3775e-02,  3.9702e-02, -8.0942e-02, -3.3491e-02, -9.6317e-02,\n",
       "                       6.8705e-02,  2.5047e-02,  2.1805e-02,  1.0037e-01, -4.2178e-02,\n",
       "                       7.6549e-02, -4.9471e-02,  8.6181e-02,  6.4200e-02, -1.0553e-01,\n",
       "                      -3.4335e-02,  4.6810e-02,  7.7482e-02,  6.0163e-02,  1.4395e-02,\n",
       "                      -5.5706e-02,  5.8093e-02, -8.5937e-02, -5.5568e-02, -5.1766e-02,\n",
       "                      -1.0170e-01, -5.7026e-02, -5.2282e-02, -7.5044e-02, -1.1076e-01,\n",
       "                       4.7902e-02, -2.0358e-02,  8.2087e-02, -4.6429e-03, -9.8615e-02,\n",
       "                       7.7076e-02,  8.2873e-02,  7.0443e-02,  8.2972e-02, -4.2574e-02,\n",
       "                      -4.9511e-02, -5.6495e-02, -8.8431e-02, -6.5764e-02,  3.7305e-02,\n",
       "                       8.3734e-02, -9.0133e-02, -4.1402e-02, -3.7551e-02, -4.6959e-02,\n",
       "                      -9.8077e-02, -2.7599e-02, -7.5848e-02, -1.0601e-01,  2.0185e-02,\n",
       "                       4.0348e-02,  4.3891e-02, -2.8102e-02, -8.8723e-02, -8.0950e-02,\n",
       "                       6.0233e-02,  9.3731e-02,  5.1400e-03, -5.7998e-02, -7.7933e-02,\n",
       "                       8.0540e-02,  1.0446e-01,  7.4159e-02,  8.5484e-02, -7.5405e-02,\n",
       "                      -5.3442e-02, -7.3053e-02, -2.6605e-02,  1.1413e-02, -5.6631e-02,\n",
       "                      -8.0034e-02,  8.3062e-02,  1.7876e-02,  3.0653e-02, -8.1770e-02,\n",
       "                      -2.9755e-02,  4.0360e-02,  5.7386e-02, -2.8146e-02, -7.1050e-02,\n",
       "                      -6.5557e-02, -1.7190e-03, -7.5832e-02, -2.2548e-02,  1.9437e-02,\n",
       "                       6.3561e-02,  6.8629e-02, -6.3541e-02,  5.7145e-02, -6.3257e-02,\n",
       "                      -1.0456e-01, -2.7988e-02,  6.6506e-02,  1.0248e-01,  5.9591e-02,\n",
       "                      -7.0999e-02, -7.7914e-02, -2.1753e-02, -3.2394e-02, -4.6651e-02,\n",
       "                       3.1597e-02, -6.8783e-02,  1.0089e-01, -2.8244e-02, -2.7823e-02,\n",
       "                      -8.7870e-02, -5.1410e-02, -1.0234e-01, -4.0031e-02, -8.9539e-02,\n",
       "                       6.8542e-02,  6.3682e-02, -9.5152e-02,  7.8007e-02, -8.3572e-02,\n",
       "                       2.3133e-02, -7.0131e-02, -1.7423e-02, -2.0936e-02,  4.2146e-02,\n",
       "                      -5.4939e-02, -1.3458e-03,  2.8639e-03,  1.2540e-02, -4.1250e-02,\n",
       "                      -3.5982e-02, -9.4355e-03, -8.7433e-02, -1.1732e-01, -2.1587e-02,\n",
       "                       5.9885e-02, -6.3172e-02,  6.1517e-02, -1.2081e-01, -5.6242e-02,\n",
       "                       1.1615e-02,  6.3506e-02,  5.6351e-02,  8.9655e-02, -7.8470e-02,\n",
       "                       4.4022e-04, -2.3162e-02, -3.4239e-02,  2.7910e-02,  2.8048e-03,\n",
       "                       7.4495e-02,  2.2235e-02, -3.1213e-02,  5.9730e-02,  6.3698e-02,\n",
       "                      -1.0431e-02, -7.0175e-02,  5.1817e-02, -2.6147e-03, -1.2249e-01,\n",
       "                       3.1406e-02,  7.4319e-02, -1.3065e-01,  5.2815e-02, -7.0097e-02,\n",
       "                      -8.6776e-02, -7.9483e-02,  4.4705e-02, -5.0503e-03, -1.1886e-04,\n",
       "                      -6.5027e-02,  4.5849e-02, -3.3682e-02,  5.2901e-02, -3.7677e-02,\n",
       "                       8.1634e-02,  8.7810e-02, -4.1081e-02, -7.4830e-02,  4.2489e-02,\n",
       "                       9.3964e-03,  8.4539e-02,  1.5321e-02,  1.2830e-01,  1.0176e-01,\n",
       "                       9.3661e-02,  1.1265e-01,  8.7212e-02, -9.7287e-02,  5.9249e-02,\n",
       "                      -9.4891e-02,  5.3241e-02, -6.3927e-02, -1.2469e-02, -9.1576e-02,\n",
       "                      -8.7372e-02,  8.6719e-02,  9.6031e-02, -8.5386e-02,  8.8910e-02,\n",
       "                       3.9343e-02, -7.0478e-02, -7.0320e-02, -3.0403e-02, -7.0726e-02,\n",
       "                       5.9601e-02, -8.9313e-02,  1.1959e-01,  5.9739e-02, -4.9160e-02,\n",
       "                       7.6733e-02, -5.1572e-02, -1.2745e-02,  1.2616e-01, -9.3022e-02,\n",
       "                      -1.0269e-01,  6.8638e-02, -6.8127e-02,  6.9823e-02,  7.1455e-02,\n",
       "                      -9.7009e-02,  1.3416e-01, -6.3853e-02,  6.9509e-02,  9.6544e-02,\n",
       "                       2.9844e-02,  2.5162e-02,  6.9154e-02, -8.6312e-02,  7.9090e-02,\n",
       "                      -7.5972e-02,  8.7461e-02, -6.5189e-02,  1.7312e-02, -6.8063e-02,\n",
       "                       3.9697e-02,  7.7345e-02, -1.0308e-01, -5.9772e-02,  9.5872e-02,\n",
       "                       8.3835e-02,  7.1533e-02,  3.9629e-02,  5.4740e-02, -1.1359e-01,\n",
       "                      -4.8709e-02, -7.9665e-02], device='cuda:0')),\n",
       "             ('TranformerBlock.attention.key.weight',\n",
       "              tensor([[ 0.0328, -0.0809,  0.0967,  ..., -0.0619,  0.0829,  0.0635],\n",
       "                      [-0.0561, -0.0240, -0.0418,  ...,  0.1067, -0.0137, -0.0817],\n",
       "                      [ 0.0126,  0.0175, -0.0580,  ...,  0.0409, -0.0013,  0.1234],\n",
       "                      ...,\n",
       "                      [-0.0293,  0.0353, -0.0432,  ...,  0.0387, -0.0483,  0.0075],\n",
       "                      [ 0.0074, -0.0529,  0.0440,  ..., -0.0432,  0.0517,  0.0089],\n",
       "                      [-0.1185,  0.0404, -0.0488,  ..., -0.0222, -0.0536, -0.0615]],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.attention.key.bias',\n",
       "              tensor([ 3.9299e-02, -5.3142e-02, -7.7286e-02,  1.1176e-03,  8.3621e-02,\n",
       "                       8.7224e-02, -3.5896e-02,  3.3824e-02,  6.4045e-02,  3.9937e-02,\n",
       "                       1.7848e-02, -6.0382e-02,  7.3940e-02,  1.0803e-02,  3.7162e-02,\n",
       "                      -3.4727e-02, -1.6227e-02,  2.0830e-02,  2.1463e-02,  6.8952e-03,\n",
       "                       6.8116e-02, -3.3781e-02,  1.1328e-02, -3.9303e-02,  4.8851e-02,\n",
       "                      -6.4825e-02, -6.7437e-02,  4.5516e-02, -3.4901e-02, -3.2022e-02,\n",
       "                      -2.6371e-02,  2.7564e-02,  4.2270e-02, -1.4881e-02, -3.9130e-02,\n",
       "                       7.2897e-03, -6.7110e-03, -6.8890e-03,  3.5912e-02, -3.1451e-02,\n",
       "                       4.2858e-02,  2.7884e-03,  9.7722e-03, -1.2233e-02,  5.4309e-02,\n",
       "                      -2.2235e-02, -4.6641e-02,  4.5496e-02,  3.9306e-04, -4.7638e-03,\n",
       "                      -1.8312e-02,  8.1266e-03, -4.1492e-02,  1.5002e-03,  6.1550e-02,\n",
       "                      -2.4339e-02,  5.1347e-02, -2.5608e-02, -1.0856e-02, -1.9486e-02,\n",
       "                       2.9565e-02,  4.1754e-02, -2.2157e-02,  3.8427e-02,  9.1789e-02,\n",
       "                       1.1067e-02, -4.4341e-02, -7.3066e-02, -3.2391e-02, -1.0803e-02,\n",
       "                       9.3083e-03,  6.6862e-02, -3.3789e-03,  2.0477e-02,  2.3378e-02,\n",
       "                      -5.2936e-02, -1.9377e-02,  2.6004e-02,  1.0518e-02, -3.9214e-02,\n",
       "                      -4.4653e-02,  6.0947e-02,  9.3167e-02,  2.5295e-02,  2.0515e-02,\n",
       "                      -6.7679e-02, -1.2910e-02, -1.6049e-02, -8.6002e-02, -7.4005e-03,\n",
       "                       3.7445e-02,  9.6520e-03, -1.5624e-03, -1.2277e-02, -5.4554e-03,\n",
       "                       3.2797e-02, -1.1758e-02,  7.5444e-02,  1.5344e-02,  5.4497e-02,\n",
       "                       4.4207e-02, -4.6502e-02, -7.0569e-05,  1.7335e-02, -5.3112e-02,\n",
       "                       3.5406e-02, -9.8411e-03, -1.4268e-02, -2.5501e-02,  1.9560e-02,\n",
       "                      -1.1399e-02,  1.1398e-02,  3.7188e-02,  5.0589e-02,  9.2952e-02,\n",
       "                      -6.7596e-03,  6.2120e-02, -7.6763e-04,  1.6264e-02, -1.5861e-02,\n",
       "                       4.3573e-03,  2.7399e-02,  2.9429e-02,  4.4056e-02, -2.4999e-02,\n",
       "                      -1.3556e-02,  1.8349e-02, -1.8064e-02, -8.0885e-02,  9.8555e-02,\n",
       "                      -2.5224e-02,  7.9937e-03, -6.7474e-02, -6.5164e-02, -1.2485e-01,\n",
       "                       1.5505e-02,  3.0056e-02,  1.5080e-03, -2.4578e-02,  1.2477e-02,\n",
       "                      -1.1878e-01,  1.2287e-01, -3.4633e-02, -4.6283e-02, -1.4919e-02,\n",
       "                      -6.1204e-02,  2.8008e-02, -1.0894e-01,  8.1656e-03,  9.3330e-02,\n",
       "                      -3.0114e-02,  7.9933e-03,  8.5261e-02, -3.5677e-02,  6.7262e-02,\n",
       "                       8.0185e-03,  2.5540e-02,  2.8298e-02, -4.2695e-02,  4.8483e-02,\n",
       "                      -4.0659e-02,  3.7222e-02,  8.6305e-02, -1.2330e-01, -4.1679e-02,\n",
       "                      -3.6281e-02, -8.5232e-02,  1.2829e-02, -9.4946e-03,  7.6447e-02,\n",
       "                      -5.3145e-02, -3.0599e-02,  3.5042e-02,  2.2428e-02,  4.5359e-02,\n",
       "                       5.0656e-02, -8.2428e-02,  1.3448e-02, -6.9356e-02, -6.9929e-02,\n",
       "                       3.9292e-02, -3.2289e-02, -8.8937e-02, -2.5718e-02,  3.5732e-02,\n",
       "                      -1.0140e-01,  8.9800e-03,  3.3790e-03, -9.9097e-02,  6.4542e-03,\n",
       "                       5.7212e-02, -3.5203e-02, -7.9961e-02,  4.6413e-02, -5.0508e-02,\n",
       "                       4.6740e-02,  2.2425e-02, -7.4467e-02,  1.0164e-01,  7.9324e-02,\n",
       "                      -4.4606e-02,  3.4403e-04, -7.6167e-02,  8.4825e-02,  1.3406e-01,\n",
       "                       1.3719e-01, -9.3887e-02,  1.0856e-01,  1.8794e-01,  1.3593e-01,\n",
       "                       1.6067e-02, -1.3653e-01,  6.3863e-02, -9.9690e-02, -1.1758e-01,\n",
       "                       1.8975e-02, -7.1245e-02, -5.7745e-02, -4.8594e-02,  9.7608e-02,\n",
       "                      -4.1907e-02, -1.1474e-01,  9.9531e-03, -3.6108e-02,  1.8393e-01,\n",
       "                      -1.9133e-02, -1.1380e-01, -2.1133e-03,  1.2875e-01, -1.0813e-01,\n",
       "                       1.0042e-01, -1.6688e-01,  1.0447e-02, -9.5947e-02,  1.1838e-02,\n",
       "                       7.1436e-02, -4.8957e-02, -1.1218e-01, -1.4280e-01, -6.8484e-02,\n",
       "                      -1.7768e-02,  5.7020e-02,  2.5120e-02,  6.9296e-02,  1.4609e-02,\n",
       "                       8.6075e-02, -5.9072e-02, -1.3163e-01,  2.2457e-02, -1.3078e-02,\n",
       "                      -1.4090e-02, -9.2352e-02,  8.7730e-02,  2.9234e-02,  9.6885e-02,\n",
       "                       5.5638e-02, -1.2548e-02,  9.7869e-02,  6.1566e-02, -2.8024e-03,\n",
       "                      -5.7789e-02, -9.8218e-03,  1.4562e-02, -3.1972e-04,  7.4568e-02,\n",
       "                       3.0923e-02, -1.9018e-02,  3.7257e-03, -2.3846e-04, -5.4779e-04,\n",
       "                      -7.9106e-02, -2.8958e-02, -6.1384e-02, -8.0803e-02,  3.9545e-02,\n",
       "                      -6.1126e-02, -4.1122e-03, -6.6436e-02,  1.1497e-02,  9.8701e-03,\n",
       "                      -2.9535e-02, -1.8493e-02, -6.2179e-02, -2.9890e-02, -7.6472e-02,\n",
       "                       3.8778e-02, -3.8362e-02,  2.2800e-02,  6.0833e-02,  2.7075e-02,\n",
       "                       4.6393e-02,  7.4510e-03,  4.6361e-02,  7.8142e-02, -2.3534e-02,\n",
       "                      -3.3399e-03,  2.7603e-03, -5.5089e-02,  4.3757e-02,  3.7046e-02,\n",
       "                       1.4438e-02, -4.0038e-02, -9.3208e-03, -2.3748e-02,  3.8918e-02,\n",
       "                       7.0058e-02, -1.0661e-02,  5.0530e-02,  5.5016e-02, -8.2353e-02,\n",
       "                      -1.8517e-02, -7.2015e-03,  1.0416e-02,  6.3280e-02,  7.3494e-02,\n",
       "                       5.3261e-02,  1.1588e-02,  7.3496e-02, -4.6057e-03, -4.8075e-02,\n",
       "                       1.1229e-01,  1.1074e-01, -9.0363e-03, -9.1917e-02, -8.1150e-02,\n",
       "                       9.6002e-02,  5.2091e-02,  7.7205e-02, -7.3678e-02, -5.6018e-02,\n",
       "                       7.5354e-02,  5.3381e-02,  7.9703e-02,  4.4199e-03, -6.1773e-02,\n",
       "                      -4.7398e-02, -4.4396e-02, -6.2308e-02,  1.3162e-02, -6.0419e-02,\n",
       "                      -6.3585e-02,  7.6169e-02,  8.2152e-03,  4.3891e-02, -3.7491e-02,\n",
       "                      -7.9800e-02,  5.2426e-02,  1.0396e-01, -1.2991e-01, -5.9914e-02,\n",
       "                      -9.9219e-02, -9.2417e-02, -9.3658e-02, -9.9067e-02,  2.0233e-02,\n",
       "                       1.3106e-02, -2.6708e-04, -2.7345e-02,  6.1196e-02, -2.2951e-02,\n",
       "                      -4.7818e-02, -8.0164e-02,  7.3478e-02,  1.1108e-01,  1.2192e-01,\n",
       "                      -6.4146e-02, -4.4461e-02, -7.6739e-02, -4.1795e-02,  6.6824e-04,\n",
       "                       1.0201e-01, -6.0972e-02,  1.3472e-01, -4.3014e-03, -3.9355e-02,\n",
       "                      -7.5330e-02, -2.3925e-02, -1.0338e-01, -4.9256e-02, -6.6297e-02,\n",
       "                       1.2115e-01,  1.1305e-02, -1.0439e-01,  1.0521e-01, -3.6941e-02,\n",
       "                      -7.6758e-02, -4.2487e-02, -1.9176e-02, -4.5819e-02, -4.4535e-02,\n",
       "                       7.8311e-02, -2.8838e-02,  2.8990e-04,  5.8854e-02,  6.1899e-03,\n",
       "                       2.3102e-02,  6.6418e-03, -9.1979e-02, -1.2680e-01,  1.5770e-02,\n",
       "                       6.1905e-02,  5.7144e-03,  1.0717e-01, -1.2958e-01, -8.7946e-03,\n",
       "                       2.0750e-02,  4.4222e-02,  4.9742e-02,  1.9192e-02,  2.3046e-02,\n",
       "                      -4.1115e-03, -4.1249e-02,  3.1695e-02,  1.5101e-02,  1.7558e-02,\n",
       "                       1.0304e-03,  2.1965e-02,  2.3591e-02,  1.0439e-01,  1.7570e-02,\n",
       "                      -1.3680e-02, -2.3846e-02,  8.0682e-02,  1.7036e-02, -8.0961e-02,\n",
       "                       7.3400e-02,  7.1191e-02, -1.5472e-01,  2.7700e-02, -9.9022e-02,\n",
       "                      -8.4087e-02, -7.5409e-02, -3.8132e-02, -4.3659e-02,  6.6873e-02,\n",
       "                      -1.1173e-02,  4.8836e-02, -2.2597e-02,  7.8594e-02, -4.9118e-03,\n",
       "                      -6.1990e-03,  3.4357e-02,  3.7343e-02, -4.3233e-03,  8.6083e-02,\n",
       "                       1.9570e-02,  2.8147e-03,  2.4463e-02, -6.9253e-02, -6.8275e-02,\n",
       "                      -4.5757e-02, -9.3181e-02, -6.0590e-02, -5.1834e-02,  4.4076e-02,\n",
       "                       3.9703e-02, -8.3340e-02, -9.3379e-03, -9.0866e-03,  4.3156e-02,\n",
       "                       3.4880e-02, -4.7379e-02, -3.2101e-02,  5.1088e-02,  9.6165e-03,\n",
       "                      -2.7040e-02, -6.6921e-03,  2.2705e-02,  2.5455e-02, -8.4702e-03,\n",
       "                      -5.9614e-02,  6.4513e-02, -9.2788e-02, -3.6749e-02,  6.8302e-02,\n",
       "                      -2.2904e-02,  6.7931e-02,  3.3763e-02, -1.1072e-01,  4.7334e-02,\n",
       "                       5.0481e-02, -5.2577e-03,  5.2697e-02, -5.4442e-02, -1.0109e-01,\n",
       "                      -8.4250e-03, -2.8247e-02,  4.7182e-02,  1.9683e-02, -9.3785e-03,\n",
       "                      -8.8026e-03, -1.3895e-02,  1.7423e-03,  9.7433e-03,  6.7589e-03,\n",
       "                       8.7252e-02,  6.0999e-02,  6.5970e-02, -6.3772e-02,  9.5166e-03,\n",
       "                      -9.4661e-02, -8.2307e-02,  8.7123e-02,  6.2901e-03, -4.1560e-02,\n",
       "                       4.5021e-03, -5.3604e-02, -5.0384e-02, -2.1535e-02,  8.6979e-02,\n",
       "                       4.6229e-02,  1.0629e-01], device='cuda:0')),\n",
       "             ('TranformerBlock.attention.value.weight',\n",
       "              tensor([[-0.0259,  0.0159, -0.0253,  ..., -0.0712,  0.0228, -0.1043],\n",
       "                      [ 0.0277, -0.1082,  0.0349,  ...,  0.0397,  0.0874,  0.0784],\n",
       "                      [ 0.1104, -0.0864,  0.0960,  ...,  0.0908,  0.0187,  0.0749],\n",
       "                      ...,\n",
       "                      [ 0.0218, -0.0040, -0.0180,  ..., -0.0595, -0.0424,  0.0157],\n",
       "                      [-0.0795,  0.0149, -0.0256,  ..., -0.0292, -0.0896, -0.0516],\n",
       "                      [-0.0708,  0.0382, -0.0926,  ..., -0.1256, -0.0613, -0.0861]],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.attention.value.bias',\n",
       "              tensor([-0.0194,  0.0738,  0.0448, -0.0449,  0.0742,  0.0936,  0.0923, -0.1170,\n",
       "                      -0.0452, -0.0420, -0.0648, -0.0792,  0.0332,  0.0256, -0.0856,  0.0148,\n",
       "                      -0.0245,  0.0928,  0.0423, -0.0333,  0.0113, -0.0331, -0.0482, -0.0687,\n",
       "                      -0.0040,  0.0129,  0.0991,  0.0177,  0.1023,  0.0660,  0.0165,  0.0735,\n",
       "                       0.0681, -0.0672, -0.0108,  0.0731,  0.0717, -0.0193,  0.0941, -0.0670,\n",
       "                      -0.0257, -0.0500,  0.0005,  0.0245,  0.0360, -0.0413,  0.0811,  0.0011,\n",
       "                       0.0468, -0.0970,  0.0216, -0.0445,  0.0276,  0.0408, -0.1008, -0.1038,\n",
       "                      -0.0657, -0.0179,  0.0201,  0.0295,  0.0142,  0.0112,  0.0725,  0.0898,\n",
       "                       0.0092,  0.0557, -0.0025, -0.0281, -0.0779, -0.0262,  0.0401, -0.0298,\n",
       "                      -0.0135,  0.0691,  0.0750, -0.0731, -0.0417,  0.0488,  0.0824,  0.0731,\n",
       "                       0.0722, -0.1092,  0.0151, -0.0124, -0.0652, -0.0708,  0.0746,  0.0305,\n",
       "                       0.0324,  0.0088,  0.1160, -0.1151,  0.0836,  0.0065, -0.0124,  0.0537,\n",
       "                      -0.1008, -0.0710,  0.0946, -0.0518,  0.0398, -0.0886, -0.0743,  0.0190,\n",
       "                       0.0023,  0.0290, -0.0413,  0.0373, -0.0383,  0.0393,  0.1109,  0.1020,\n",
       "                       0.0900,  0.0393,  0.0090,  0.0719, -0.0329,  0.0934, -0.0807,  0.1039,\n",
       "                       0.0437,  0.0434,  0.0034, -0.0154,  0.0798, -0.0304, -0.1077, -0.0586,\n",
       "                      -0.0177, -0.0589, -0.0271,  0.0063,  0.0932, -0.0103, -0.0899, -0.0266,\n",
       "                       0.1019, -0.0992, -0.0922, -0.0386, -0.0378, -0.0208,  0.0946,  0.0590,\n",
       "                      -0.0056, -0.0802, -0.0090, -0.0410, -0.0795,  0.0480,  0.0146,  0.0265,\n",
       "                      -0.0306, -0.0556,  0.0205, -0.0349, -0.0646, -0.0318, -0.0243, -0.0188,\n",
       "                       0.0625, -0.0611, -0.1282,  0.0507,  0.0548,  0.0435,  0.0023,  0.0821,\n",
       "                      -0.0506,  0.0235, -0.0667,  0.1258,  0.0219, -0.0570,  0.0323, -0.0296,\n",
       "                       0.0548, -0.0325,  0.0279,  0.0722, -0.0873, -0.0385, -0.0604, -0.0051,\n",
       "                       0.1145, -0.0345, -0.0453,  0.0838,  0.0793, -0.0329, -0.0718, -0.0812,\n",
       "                      -0.0865, -0.1140,  0.1175, -0.0216,  0.0712, -0.0077,  0.0476,  0.0188,\n",
       "                      -0.0662, -0.0271,  0.0113,  0.0127,  0.0514, -0.0301,  0.0713, -0.0395,\n",
       "                      -0.0470,  0.0525,  0.0254, -0.0730,  0.0279,  0.0643, -0.0337,  0.0564,\n",
       "                      -0.0204, -0.0212, -0.0060,  0.0102,  0.1079,  0.0397,  0.0839,  0.0080,\n",
       "                      -0.0218,  0.0290, -0.0741,  0.1246, -0.0051,  0.0117, -0.0483, -0.0311,\n",
       "                       0.0445, -0.1099,  0.0378, -0.0529,  0.0805,  0.0373,  0.0655,  0.0412,\n",
       "                      -0.0834,  0.0037, -0.0844, -0.1445,  0.0236,  0.0850, -0.0786,  0.0296,\n",
       "                      -0.0650, -0.0534, -0.0183,  0.0798,  0.0099,  0.0021,  0.0922,  0.0373,\n",
       "                      -0.0940, -0.0584, -0.0532, -0.0822,  0.0565,  0.1184, -0.0478,  0.0394,\n",
       "                      -0.0661,  0.1348, -0.0459,  0.0349, -0.0117, -0.1003, -0.0361, -0.0160,\n",
       "                       0.1045, -0.0348,  0.0842,  0.0243,  0.0405,  0.0869, -0.0087,  0.1200,\n",
       "                       0.1128,  0.0991, -0.0761,  0.0824,  0.0263, -0.0513,  0.0746,  0.1033,\n",
       "                      -0.0789, -0.0612,  0.0234, -0.0233, -0.0915, -0.0164, -0.0101,  0.0701,\n",
       "                      -0.0039, -0.0292,  0.0346, -0.0877, -0.0466, -0.0014, -0.0632,  0.0080,\n",
       "                      -0.0179, -0.0478, -0.0321, -0.0420, -0.0757,  0.1200,  0.0786, -0.0666,\n",
       "                       0.0362,  0.0369,  0.0529,  0.1167, -0.0532,  0.0131, -0.0581,  0.0882,\n",
       "                      -0.0925,  0.0989, -0.0090,  0.0914,  0.0285,  0.1279, -0.0078, -0.0379,\n",
       "                       0.0822, -0.0019, -0.1017,  0.0653, -0.0543, -0.0417, -0.0245,  0.0631,\n",
       "                       0.0639,  0.0321, -0.0411, -0.1302, -0.0162,  0.0659, -0.0423, -0.0960,\n",
       "                       0.0306,  0.0573, -0.0593, -0.0592, -0.0242,  0.0742, -0.0978,  0.0064,\n",
       "                      -0.0598,  0.0781, -0.0234,  0.0026,  0.0733, -0.0883, -0.0712,  0.0102,\n",
       "                       0.0069, -0.0052, -0.0565,  0.1128,  0.0686, -0.0304, -0.0197,  0.0521,\n",
       "                       0.0245,  0.0951, -0.0158,  0.0473,  0.0344,  0.0536, -0.0386,  0.0436,\n",
       "                       0.1142,  0.0715, -0.0373, -0.0355,  0.0488, -0.0640,  0.0023,  0.0620,\n",
       "                       0.0735,  0.0209, -0.0224, -0.0174, -0.0930, -0.0556,  0.0260,  0.0370,\n",
       "                      -0.0591, -0.0334,  0.0631,  0.0203,  0.0310,  0.0446, -0.0966, -0.0531,\n",
       "                      -0.0196,  0.0868, -0.0057, -0.0449,  0.1236,  0.0039, -0.0326,  0.0367,\n",
       "                       0.0151,  0.0432,  0.0032,  0.0763, -0.0321, -0.0198,  0.0685,  0.0144,\n",
       "                       0.0688, -0.0426,  0.0693, -0.0952,  0.0560,  0.0703,  0.0538, -0.0803,\n",
       "                       0.0291,  0.0664, -0.0911, -0.0318,  0.0751,  0.0526,  0.0738, -0.1126,\n",
       "                       0.1016, -0.0320,  0.0040,  0.0398,  0.0148, -0.0508, -0.0015,  0.0204,\n",
       "                       0.0814, -0.1016, -0.0492, -0.0823,  0.0481,  0.0602, -0.0639,  0.0496,\n",
       "                       0.0234,  0.0610, -0.0009, -0.0468,  0.0710, -0.0256, -0.1092, -0.0964,\n",
       "                       0.0755, -0.0220, -0.1255,  0.0094,  0.0181, -0.0506, -0.0497, -0.0899,\n",
       "                       0.0762, -0.0388, -0.1144, -0.0780, -0.0763,  0.0508, -0.0742,  0.0024,\n",
       "                      -0.0517, -0.0584, -0.0684,  0.0370,  0.0073, -0.0517, -0.1175, -0.0893,\n",
       "                      -0.0217,  0.0429,  0.0889,  0.0617, -0.0651,  0.0836,  0.0031, -0.0051,\n",
       "                      -0.0739,  0.0422, -0.0294, -0.0912, -0.0497, -0.0688,  0.0203,  0.0248,\n",
       "                      -0.0039,  0.0510, -0.0881, -0.0017,  0.0489, -0.0173, -0.0040,  0.0521,\n",
       "                      -0.0017,  0.1118, -0.0905, -0.0366,  0.0719, -0.0312, -0.0329, -0.0625],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.attention.fc_out.weight',\n",
       "              tensor([[-0.0490,  0.0473,  0.0524,  ..., -0.0946,  0.0027,  0.0004],\n",
       "                      [ 0.0863,  0.0196, -0.0996,  ...,  0.1006,  0.0061,  0.0332],\n",
       "                      [-0.0698, -0.0566,  0.0491,  ..., -0.0778,  0.0528,  0.0598],\n",
       "                      ...,\n",
       "                      [-0.0973,  0.1299, -0.0237,  ..., -0.0329, -0.0354, -0.0656],\n",
       "                      [-0.0952, -0.0139,  0.0433,  ..., -0.0315, -0.0356,  0.0234],\n",
       "                      [-0.0534, -0.0268,  0.0136,  ..., -0.0506, -0.0365,  0.0468]],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.attention.fc_out.bias',\n",
       "              tensor([ 0.0499, -0.0441,  0.0252,  0.0880, -0.0613, -0.0417,  0.0266,  0.1129,\n",
       "                       0.0590,  0.0276,  0.0362, -0.0182, -0.0049, -0.0926,  0.0684, -0.1026,\n",
       "                      -0.0964,  0.0513, -0.0902,  0.0407, -0.1039, -0.0565, -0.0669,  0.0946,\n",
       "                      -0.1226, -0.0670,  0.1115,  0.1024,  0.0316,  0.0262,  0.0380,  0.0219,\n",
       "                      -0.0827, -0.0501, -0.0384,  0.0174, -0.0889,  0.0281,  0.0068, -0.0923,\n",
       "                       0.0539, -0.0822,  0.0247,  0.0202, -0.0286, -0.0671,  0.0490, -0.0895,\n",
       "                      -0.0966,  0.0623, -0.0372, -0.0734, -0.0184, -0.0690, -0.0512,  0.1037,\n",
       "                      -0.0704, -0.0229, -0.0486, -0.0601,  0.0753,  0.0231, -0.0545, -0.0459,\n",
       "                       0.0844, -0.0211,  0.0067,  0.1076, -0.0380,  0.0798, -0.0486,  0.0486,\n",
       "                      -0.0858, -0.0440,  0.0379, -0.0243,  0.1171, -0.0188, -0.0880, -0.0210,\n",
       "                      -0.0677, -0.0803,  0.0277,  0.0513, -0.0468,  0.0175,  0.0651,  0.0760,\n",
       "                      -0.0950,  0.1162, -0.0099, -0.0840,  0.0608,  0.0425, -0.0220,  0.0332,\n",
       "                       0.1233,  0.0871,  0.0778,  0.0155,  0.0403, -0.0939, -0.0831, -0.0373,\n",
       "                      -0.1043,  0.0010,  0.0112,  0.0085,  0.0415,  0.0359,  0.1043, -0.0876,\n",
       "                       0.0498,  0.0152,  0.1029, -0.0681, -0.0652,  0.0476, -0.0581,  0.1157,\n",
       "                      -0.0718, -0.0099, -0.0661, -0.0117, -0.0498, -0.0324,  0.0456, -0.0668,\n",
       "                      -0.0347,  0.0635, -0.0451, -0.0348, -0.0058,  0.0310,  0.0904,  0.0347,\n",
       "                      -0.1002,  0.0729, -0.0407,  0.0737,  0.0430, -0.0700, -0.0577, -0.0801,\n",
       "                       0.0562, -0.0465,  0.0670, -0.0393, -0.0109,  0.0725, -0.0669, -0.0443,\n",
       "                      -0.0601, -0.0532,  0.0793,  0.0160, -0.0955,  0.0622,  0.0915, -0.0323,\n",
       "                      -0.1063,  0.0463,  0.0805,  0.1168,  0.1085,  0.0299,  0.0911, -0.0531,\n",
       "                       0.1129,  0.0718,  0.0455, -0.0443,  0.0136, -0.0141, -0.0115, -0.0509,\n",
       "                       0.0873, -0.1067,  0.0921, -0.0758,  0.0991,  0.0852,  0.0482, -0.0292,\n",
       "                      -0.0005,  0.0838, -0.0381,  0.0266, -0.0135, -0.0835, -0.0989,  0.0796,\n",
       "                      -0.0374,  0.0516,  0.1063, -0.0154,  0.0050, -0.0887,  0.0709, -0.0867,\n",
       "                      -0.0184,  0.0934,  0.0299, -0.0261, -0.0033,  0.0233, -0.0723,  0.0516,\n",
       "                      -0.0281,  0.1138, -0.0851,  0.0405, -0.0537, -0.0043, -0.0725,  0.0292,\n",
       "                       0.0448,  0.1001,  0.0733, -0.0236,  0.0387, -0.1134,  0.0152,  0.0526,\n",
       "                      -0.0447,  0.0499, -0.0817, -0.0596,  0.0978, -0.1009,  0.0823,  0.0415,\n",
       "                       0.0487, -0.1157,  0.0713, -0.0164, -0.0724, -0.0468,  0.0919,  0.0482,\n",
       "                       0.0497, -0.0613,  0.0057, -0.0770, -0.0349,  0.0237, -0.0773,  0.0127,\n",
       "                       0.0194,  0.0747,  0.0455,  0.0864, -0.0777,  0.0265,  0.0855, -0.0262,\n",
       "                       0.0704,  0.0769,  0.0500, -0.0988, -0.0130, -0.0439, -0.0312,  0.0849,\n",
       "                      -0.0217, -0.0256, -0.0969,  0.0596, -0.0728,  0.0926,  0.0914,  0.0628,\n",
       "                      -0.0785, -0.0407,  0.0456, -0.0568, -0.0050,  0.0364,  0.0841,  0.0066,\n",
       "                       0.0907, -0.1115, -0.0757,  0.1173,  0.0886, -0.0404,  0.0569, -0.0697,\n",
       "                       0.1168, -0.0994, -0.0460, -0.0045,  0.0334, -0.1164, -0.0485,  0.0033,\n",
       "                      -0.0774, -0.0504,  0.0933, -0.0415, -0.0521,  0.0357, -0.0292,  0.0344,\n",
       "                       0.0184, -0.0856, -0.0930, -0.0567,  0.0962, -0.0818,  0.0514, -0.1056,\n",
       "                      -0.0261,  0.0786,  0.0682,  0.0775,  0.0785, -0.0569,  0.0410,  0.0831,\n",
       "                       0.0795, -0.0551, -0.0555, -0.0597,  0.0918,  0.1086,  0.0158, -0.0276,\n",
       "                      -0.0926,  0.0264, -0.0648,  0.0814, -0.0076, -0.1066, -0.0119, -0.0412,\n",
       "                       0.0487, -0.0692, -0.0443,  0.0322, -0.0951, -0.1022, -0.0555,  0.0909,\n",
       "                       0.0420, -0.0427, -0.0871,  0.0849,  0.0220,  0.1094,  0.1143,  0.0364,\n",
       "                      -0.0518,  0.0726,  0.0090,  0.0778, -0.1083,  0.0753,  0.0724, -0.0860,\n",
       "                       0.0777, -0.0069, -0.0583, -0.0513, -0.0132,  0.0400, -0.0205,  0.0107,\n",
       "                      -0.1140,  0.1249, -0.0543,  0.0239,  0.0850,  0.1148,  0.0426, -0.0701,\n",
       "                       0.0549,  0.0445, -0.0724, -0.0935,  0.1143,  0.0222, -0.1122,  0.0490,\n",
       "                      -0.0556,  0.0905, -0.0762,  0.0964,  0.0571, -0.0138, -0.0393,  0.0790,\n",
       "                      -0.0939,  0.0023, -0.0362,  0.0051, -0.0779,  0.1053,  0.0345,  0.0415,\n",
       "                      -0.0594,  0.1106, -0.0413, -0.0113,  0.0106,  0.0930, -0.0303, -0.0779,\n",
       "                       0.0889, -0.0639,  0.1102, -0.1103, -0.0630,  0.0870,  0.1106,  0.0691,\n",
       "                      -0.0569, -0.0308, -0.0167, -0.0651, -0.0650,  0.0290,  0.0458, -0.0485,\n",
       "                       0.0692, -0.0494, -0.0027,  0.0056, -0.0813, -0.0044,  0.0950,  0.1057,\n",
       "                      -0.0165, -0.0643, -0.0939,  0.0493, -0.0365,  0.0205, -0.0492,  0.0628,\n",
       "                       0.0715, -0.0652,  0.0019,  0.0022, -0.0309, -0.1114,  0.0471, -0.0633,\n",
       "                       0.0475,  0.0316,  0.0769,  0.0317,  0.0657, -0.0214, -0.0792,  0.0027,\n",
       "                       0.0630,  0.0732, -0.0621,  0.0875,  0.0734, -0.0850,  0.0821, -0.0104,\n",
       "                      -0.0596,  0.0697, -0.0213, -0.0701,  0.0398,  0.0482, -0.1041,  0.0563,\n",
       "                      -0.0290,  0.1023, -0.0241,  0.1373, -0.0108, -0.0304, -0.0609,  0.0401,\n",
       "                       0.0515,  0.0054, -0.0307,  0.0894, -0.0835, -0.0186,  0.0507, -0.1276,\n",
       "                      -0.0902,  0.0620,  0.0458, -0.0523,  0.0880,  0.0550, -0.0090, -0.0691,\n",
       "                      -0.0662, -0.0196,  0.0344,  0.0196,  0.1231,  0.0063, -0.0662,  0.1013,\n",
       "                       0.0485, -0.0147,  0.0283, -0.1061,  0.0085, -0.0482,  0.0313,  0.0618],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.norm1.weight',\n",
       "              tensor([1.0084, 1.0696, 1.0019, 0.9541, 1.0232, 0.9847, 0.9787, 0.9674, 0.9673,\n",
       "                      0.9481, 0.9601, 0.9572, 1.0017, 0.9188, 0.9943, 0.9847, 0.9758, 0.9682,\n",
       "                      1.0010, 0.9488, 1.0579, 0.9788, 0.9946, 0.9986, 1.1154, 1.1292, 1.0476,\n",
       "                      1.0887, 0.9220, 1.0579, 1.0101, 0.9407, 0.9917, 1.0889, 1.0717, 0.9671,\n",
       "                      1.0290, 0.9908, 0.9674, 0.9488, 1.0747, 1.0974, 1.0299, 0.9611, 1.1141,\n",
       "                      1.0475, 1.0715, 1.0271, 0.9881, 0.9815, 0.9851, 1.0404, 0.8987, 0.9781,\n",
       "                      1.0044, 0.9533, 1.0526, 0.9991, 1.0049, 1.1109, 1.0199, 1.0222, 1.0215,\n",
       "                      0.9993, 1.0688, 1.0362, 0.9782, 1.0225, 1.0141, 1.0125, 1.0130, 0.9931,\n",
       "                      1.0001, 1.0934, 1.1061, 1.0334, 1.0871, 0.9946, 0.9816, 1.0433, 0.9316,\n",
       "                      0.9548, 0.9791, 0.9693, 1.0124, 1.0393, 1.0249, 0.9885, 0.9865, 1.0172,\n",
       "                      0.9773, 0.9460, 0.9312, 0.9795, 0.9792, 1.0545, 1.0612, 0.9490, 1.0179,\n",
       "                      0.8567, 0.9534, 1.0186, 1.0638, 0.9596, 1.0378, 1.0384, 0.9117, 1.0212,\n",
       "                      1.0560, 1.0024, 1.0641, 1.1064, 0.8420, 1.0517, 0.9294, 0.9732, 1.0217,\n",
       "                      0.9147, 1.1346, 1.1134, 1.0261, 1.0316, 0.9786, 0.9907, 1.0949, 0.9987,\n",
       "                      0.9556, 1.0608, 0.9251, 1.0135, 0.9369, 1.0093, 0.9972, 0.9989, 0.9910,\n",
       "                      0.9529, 0.9820, 0.9740, 0.9882, 1.0404, 1.0326, 1.0799, 1.0374, 1.0488,\n",
       "                      1.1056, 1.1239, 0.9766, 0.9995, 1.0080, 1.0549, 0.9183, 1.1413, 0.9326,\n",
       "                      1.0196, 0.9873, 0.9398, 0.9844, 1.0174, 0.9084, 0.9669, 1.0301, 0.9901,\n",
       "                      1.0638, 1.0719, 1.0136, 0.9338, 1.0754, 0.9677, 1.0555, 1.0338, 0.9433,\n",
       "                      0.9895, 1.0237, 0.9740, 1.0041, 1.0602, 1.0291, 1.0025, 1.1120, 1.0633,\n",
       "                      0.8629, 0.9278, 0.9683, 1.0289, 1.0041, 1.0197, 1.1147, 0.9868, 0.9200,\n",
       "                      0.9984, 1.0580, 0.9947, 1.0381, 0.9856, 1.0399, 1.0167, 1.0198, 0.9543,\n",
       "                      0.9391, 0.9925, 1.0491, 1.0338, 0.8993, 0.9708, 0.9947, 1.0319, 1.1391,\n",
       "                      0.9630, 1.0045, 1.0556, 0.9108, 1.0421, 1.0009, 1.0021, 0.9676, 0.8749,\n",
       "                      1.0796, 0.9286, 1.0787, 0.9157, 1.0247, 1.1206, 1.0066, 1.0305, 0.9645,\n",
       "                      0.9979, 0.9188, 1.1175, 0.9787, 0.9962, 1.1147, 0.9399, 1.0853, 1.0729,\n",
       "                      1.0002, 1.0109, 0.9753, 1.0045, 1.0667, 0.9547, 0.9977, 1.0479, 1.0035,\n",
       "                      1.0178, 0.9948, 1.0295, 1.0006, 1.0141, 1.0361, 0.9882, 0.9943, 0.9969,\n",
       "                      1.0579, 0.9971, 0.9020, 0.9855, 0.8490, 0.9798, 0.9592, 0.9547, 0.9306,\n",
       "                      1.0322, 0.9773, 1.1329, 0.9187, 1.0633, 1.0386, 0.9780, 1.0009, 0.9214,\n",
       "                      1.0571, 1.0667, 0.9984, 0.9847, 1.0570, 1.0689, 1.0414, 1.0363, 1.0864,\n",
       "                      1.0167, 1.0453, 1.0592, 0.9498, 1.0279, 0.9200, 1.0992, 1.1508, 1.0699,\n",
       "                      1.0831, 1.0851, 1.0269, 0.9639, 1.0163, 1.0026, 1.0406, 1.0130, 0.9874,\n",
       "                      0.9805, 1.0521, 0.9728, 1.0037, 1.0889, 0.9148, 1.0312, 0.9496, 0.9858,\n",
       "                      1.0659, 0.9439, 1.0439, 1.0748, 0.9793, 1.0524, 0.9778, 1.1530, 1.0059,\n",
       "                      1.0489, 0.9966, 0.9686, 0.9143, 1.0580, 0.9486, 0.9827, 1.0052, 1.0505,\n",
       "                      1.0578, 1.0361, 0.9749, 1.0106, 1.1170, 1.0371, 1.0428, 0.9768, 0.9666,\n",
       "                      0.9868, 1.0302, 1.0080, 1.0492, 1.0151, 0.9306, 1.0657, 1.0544, 0.9737,\n",
       "                      0.9509, 1.0894, 0.9891, 1.1420, 1.0152, 1.1360, 1.0198, 1.0390, 1.0288,\n",
       "                      1.0229, 1.0431, 0.9987, 1.0513, 0.9915, 0.9835, 0.9377, 1.0128, 0.9901,\n",
       "                      1.0953, 1.0245, 0.9404, 1.0624, 0.9998, 0.9449, 0.9870, 0.9277, 1.0722,\n",
       "                      1.1326, 0.9992, 0.9934, 1.0553, 1.1210, 0.9742, 1.0215, 0.9269, 1.0139,\n",
       "                      0.9135, 0.9585, 1.0537, 0.9818, 1.0863, 1.0653, 1.0326, 0.9765, 0.9843,\n",
       "                      1.0080, 1.0727, 1.0055, 0.9627, 1.0105, 1.0239, 0.9682, 1.0995, 1.0165,\n",
       "                      0.9277, 1.0299, 1.0253, 1.1123, 0.9838, 1.0672, 1.0760, 0.9758, 0.9219,\n",
       "                      1.0320, 0.9554, 0.9894, 1.0781, 1.0082, 1.1021, 1.0530, 1.0873, 0.9475,\n",
       "                      1.0186, 1.0130, 1.0994, 0.9454, 0.9745, 0.9479, 1.1237, 1.0182, 1.1336,\n",
       "                      0.9142, 0.9255, 0.9787, 0.9934, 1.0009, 0.9812, 0.9899, 1.0777, 1.0716,\n",
       "                      1.0002, 0.9713, 1.0520, 0.9869, 1.0149, 1.0362, 1.0338, 1.0598, 0.9977,\n",
       "                      0.9961, 0.9975, 0.9927, 0.9414, 0.9248, 1.0672, 0.9956, 0.9214, 1.0014,\n",
       "                      0.9220, 1.0528, 0.9704, 0.9785, 0.9988, 1.0141, 0.9083, 0.9596, 1.0212,\n",
       "                      1.0999, 0.9759, 0.9676, 1.1219, 1.0071, 0.9999, 1.1078, 1.0191, 1.1141,\n",
       "                      1.0156, 1.0544, 1.0031, 1.1048, 0.9835, 0.9998, 0.9948, 1.0316, 0.9621,\n",
       "                      0.9883, 1.0047, 1.0188, 1.0281, 0.9888, 1.0074, 0.9775, 0.9339, 0.9874,\n",
       "                      0.9694, 1.0425, 1.0149, 0.9389, 1.0196, 0.9964, 1.0366, 1.0128, 1.0214,\n",
       "                      0.9764, 0.9457, 0.9696, 1.0258, 0.9586, 1.1191, 1.0517, 0.9777, 1.0167,\n",
       "                      1.0591, 1.0422, 0.9275, 1.0466, 1.0782, 0.7743, 1.0587, 0.9563],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.norm1.bias',\n",
       "              tensor([ 5.3701e-02, -8.0454e-02,  2.5851e-02,  7.1976e-03, -6.7461e-02,\n",
       "                      -6.1761e-02,  6.6039e-02,  4.5561e-02, -5.1585e-02,  5.8327e-02,\n",
       "                      -8.9634e-03, -5.7438e-02, -2.6551e-02,  1.1139e-02, -2.2172e-02,\n",
       "                      -6.2307e-03,  8.1166e-03, -1.7297e-02,  6.0013e-03, -5.5067e-02,\n",
       "                      -6.5715e-02,  1.5965e-02,  3.0149e-03, -1.7078e-02, -1.1045e-01,\n",
       "                      -1.3320e-01,  4.3072e-02,  9.0622e-02,  2.9333e-02,  1.2032e-01,\n",
       "                       2.1567e-02,  1.3200e-02, -2.4778e-02,  4.8330e-02, -7.1012e-02,\n",
       "                      -3.6468e-02, -1.7283e-02, -6.1257e-02, -3.8622e-02, -1.0644e-02,\n",
       "                       7.5018e-02, -9.2964e-02, -1.9667e-02, -2.9976e-02, -1.0962e-01,\n",
       "                      -2.0954e-02,  1.0621e-01, -1.6333e-02,  1.7591e-02,  1.9265e-04,\n",
       "                      -1.4375e-02, -8.9672e-02, -1.0918e-02,  2.5514e-02,  2.5209e-02,\n",
       "                      -6.0742e-03, -1.1304e-01, -5.6131e-02,  2.0321e-03, -9.2973e-02,\n",
       "                       6.3835e-02,  8.7821e-02, -6.6024e-02, -6.4320e-02,  7.6351e-02,\n",
       "                      -6.9644e-02,  5.3528e-02,  3.0461e-02, -6.8813e-02,  8.8844e-02,\n",
       "                       5.0813e-02, -5.4142e-02, -7.1225e-02, -1.0959e-01,  1.0840e-01,\n",
       "                      -7.7775e-02,  8.7821e-02,  5.6169e-02, -1.8422e-02, -7.5197e-02,\n",
       "                      -3.8603e-02,  5.5071e-02, -2.9767e-02,  1.9997e-02, -3.2412e-02,\n",
       "                      -4.7949e-02, -5.3038e-02, -3.6573e-02, -1.1149e-02, -1.8991e-02,\n",
       "                       1.4876e-02, -3.9629e-02, -6.3741e-04,  2.5182e-03, -4.9364e-02,\n",
       "                       3.3487e-02,  6.7829e-02, -2.5126e-02,  1.4742e-02,  1.4008e-02,\n",
       "                       1.3817e-02, -6.0707e-02, -7.6003e-02, -5.5560e-02, -1.1821e-02,\n",
       "                       9.1636e-02, -1.0254e-02,  5.5609e-02,  8.2977e-02,  1.4971e-02,\n",
       "                       7.1002e-02, -1.0263e-01, -2.7248e-02, -6.1453e-02,  6.8696e-02,\n",
       "                      -1.5817e-02, -2.5230e-02,  4.0864e-02, -1.1653e-01,  1.0416e-01,\n",
       "                      -3.8652e-02,  5.1943e-02, -2.4932e-02,  4.8259e-02, -8.4830e-02,\n",
       "                      -2.3592e-02, -4.0326e-02, -5.4412e-02, -2.0480e-02,  7.2855e-02,\n",
       "                      -5.2494e-02, -7.0210e-02,  6.0691e-02, -6.4253e-02,  7.9435e-03,\n",
       "                      -1.2801e-02, -9.2234e-03,  9.3797e-03, -1.2405e-02,  4.1712e-02,\n",
       "                       5.6487e-02, -7.8532e-02,  4.3928e-02, -7.3237e-02,  1.0672e-01,\n",
       "                      -1.0599e-01, -3.5660e-02, -1.8819e-02,  5.7005e-02,  8.1162e-02,\n",
       "                      -2.2861e-02, -1.0896e-01, -1.8537e-02, -2.9326e-02, -1.2702e-02,\n",
       "                      -4.4198e-02,  9.5102e-03, -4.6513e-02,  5.1414e-02,  1.2772e-02,\n",
       "                      -4.2860e-02,  6.5901e-02,  6.9695e-02,  8.6345e-02,  3.1770e-02,\n",
       "                       1.4594e-02,  8.4790e-02,  5.0239e-02,  1.0430e-01,  7.4756e-03,\n",
       "                      -3.4341e-02, -7.0708e-02, -5.1727e-02, -1.6706e-02,  4.8685e-02,\n",
       "                      -6.5713e-02,  9.1951e-03, -3.8690e-03,  1.1271e-01, -7.1295e-02,\n",
       "                       7.3806e-02,  3.7818e-02,  1.3840e-02, -6.3861e-02,  6.3978e-02,\n",
       "                      -2.3180e-02, -1.0363e-01, -3.9870e-02, -2.2966e-03,  1.2000e-02,\n",
       "                      -8.4203e-02,  7.7688e-02, -7.2415e-02, -5.5650e-03,  1.0756e-01,\n",
       "                       5.9460e-02,  6.0031e-02,  1.4749e-02, -3.0277e-02, -3.4734e-02,\n",
       "                      -9.1977e-02,  4.7991e-02,  4.5514e-02,  5.2649e-03, -5.1635e-02,\n",
       "                      -9.8156e-04, -1.0828e-01,  2.8946e-02,  3.6317e-02,  6.9319e-02,\n",
       "                       1.2697e-02,  8.7906e-02,  1.8874e-02,  4.4707e-02,  2.9743e-02,\n",
       "                       8.8421e-02,  8.1145e-02,  2.7047e-02,  8.4053e-02, -1.7096e-02,\n",
       "                       3.2656e-02, -1.1144e-01, -5.6305e-02,  6.8633e-02,  2.3181e-02,\n",
       "                       3.5541e-02, -8.0585e-02, -1.1383e-01,  2.6835e-02, -7.9646e-03,\n",
       "                       1.0974e-01, -1.0959e-02,  9.0720e-02, -6.9414e-02, -4.1674e-03,\n",
       "                      -4.8218e-02,  3.7712e-02,  4.5575e-02,  8.1588e-02, -2.1133e-02,\n",
       "                       3.4800e-02,  4.2092e-02, -6.5224e-02, -1.9455e-02,  3.4816e-02,\n",
       "                       6.6943e-02, -6.7458e-02, -6.8458e-02,  6.1319e-02,  4.9235e-02,\n",
       "                       2.8819e-02, -9.9875e-04, -7.3139e-02,  6.5118e-02,  1.7096e-02,\n",
       "                      -2.2079e-02,  3.5946e-02, -3.4622e-02,  1.0932e-02, -3.2093e-02,\n",
       "                       3.4641e-02,  6.5087e-02,  2.2155e-02,  1.0233e-01, -2.7234e-02,\n",
       "                       5.0056e-02, -6.0371e-02, -6.0388e-02, -5.4497e-02,  5.6709e-02,\n",
       "                       1.1072e-01,  8.0456e-02,  1.6268e-02,  4.0072e-02,  5.3768e-02,\n",
       "                      -6.9238e-02,  6.4554e-02,  7.0036e-02,  8.8835e-02,  5.9615e-02,\n",
       "                       5.5216e-02, -4.8283e-02,  4.8492e-02,  4.5561e-02,  2.5995e-02,\n",
       "                      -1.0548e-01,  1.4391e-01, -9.5014e-02,  9.6708e-02, -8.3669e-02,\n",
       "                      -2.1723e-02, -8.6849e-02,  5.2414e-02,  2.6646e-03, -6.9850e-02,\n",
       "                      -4.8472e-02,  2.1495e-03,  2.5018e-02,  7.9594e-02,  4.7650e-03,\n",
       "                      -2.4718e-02,  9.4409e-02,  1.0450e-02,  6.0806e-02,  4.5972e-03,\n",
       "                      -1.8497e-02, -7.7253e-02, -5.3772e-02,  2.2721e-02, -8.7510e-02,\n",
       "                      -5.6356e-02, -6.6860e-02, -1.1496e-02,  1.0727e-01,  2.9607e-02,\n",
       "                      -2.4529e-02,  6.2677e-02, -2.4198e-02,  4.1940e-03,  9.9186e-02,\n",
       "                       6.6452e-03,  2.2316e-02, -9.2186e-02,  5.8148e-02,  9.7327e-02,\n",
       "                       3.3534e-02, -1.8874e-02,  4.9342e-04, -9.2473e-02,  8.5437e-02,\n",
       "                      -7.1507e-02, -4.6515e-02,  5.9818e-02,  1.6137e-02, -6.7016e-02,\n",
       "                      -2.2138e-02,  7.1012e-02, -2.9276e-02,  2.6262e-02,  9.0135e-02,\n",
       "                      -9.7058e-02,  7.4692e-03,  3.3919e-02,  8.5522e-02,  6.2584e-02,\n",
       "                      -1.2465e-01, -1.9094e-02,  1.1388e-01, -6.2833e-02,  6.4241e-02,\n",
       "                       3.0990e-02,  7.0591e-02, -9.2893e-02,  1.6378e-02,  6.5207e-02,\n",
       "                       2.9614e-02,  2.2665e-02, -3.0657e-03,  4.0078e-02, -4.9459e-02,\n",
       "                       8.2068e-02, -9.2788e-02, -2.9722e-02, -6.9584e-02,  2.9725e-02,\n",
       "                       3.5589e-02,  6.3938e-02, -8.4582e-03, -7.3968e-02,  9.7962e-02,\n",
       "                       4.6711e-02, -4.8091e-02,  7.4899e-02,  1.2780e-01,  3.4190e-02,\n",
       "                      -5.6038e-02,  2.0410e-02,  5.1348e-02,  9.8027e-04,  5.6732e-02,\n",
       "                       5.1965e-02, -4.8800e-02, -9.8670e-02,  9.6885e-02,  6.2762e-02,\n",
       "                       7.1998e-04,  2.2434e-02,  3.2594e-03,  7.9981e-02, -6.3249e-02,\n",
       "                      -2.9320e-02, -2.6853e-02, -5.0559e-02,  3.5975e-02, -7.1189e-02,\n",
       "                       5.0197e-02, -1.2598e-02,  4.7779e-02, -6.7161e-02,  1.1279e-01,\n",
       "                       3.4575e-02,  7.5747e-02, -7.9205e-02, -5.2306e-02, -1.4043e-02,\n",
       "                       5.1320e-02,  1.2171e-02,  2.2545e-02,  8.7293e-02,  4.7878e-02,\n",
       "                       9.4559e-02, -4.2372e-02, -1.0058e-01,  6.3943e-03,  6.6061e-02,\n",
       "                       6.3757e-02, -9.0938e-02,  1.3534e-02, -1.0344e-02, -8.1582e-02,\n",
       "                      -9.9226e-02,  1.3391e-02,  1.0534e-01,  1.1821e-02,  7.5747e-04,\n",
       "                      -2.5336e-02,  7.0212e-02, -4.0537e-02,  3.0062e-02, -3.8811e-02,\n",
       "                       2.0514e-01,  6.3747e-02,  5.9673e-02, -6.5769e-03, -6.4546e-02,\n",
       "                      -3.3100e-02,  2.4256e-02, -1.0606e-02, -5.7735e-02,  7.1855e-02,\n",
       "                       1.7421e-02,  2.4060e-02,  5.5144e-02, -6.1357e-02,  2.2999e-02,\n",
       "                      -3.0656e-02,  8.8512e-02, -1.4319e-01, -7.8532e-03,  5.3502e-02,\n",
       "                      -1.6619e-02,  6.4049e-02,  2.4089e-02, -7.0316e-03,  4.7083e-02,\n",
       "                       1.6246e-02,  3.1681e-02,  3.9237e-02, -3.2464e-03,  9.6829e-02,\n",
       "                      -1.0133e-02, -1.7238e-03,  1.2077e-01, -6.5174e-02, -6.6168e-03,\n",
       "                       1.1572e-01,  5.8784e-02, -1.1413e-01, -3.4711e-02,  7.0190e-02,\n",
       "                      -6.5233e-02,  1.0732e-01,  1.0143e-02,  4.2199e-02,  4.4362e-02,\n",
       "                       8.9318e-02,  5.6455e-02,  2.3324e-02,  4.3979e-02,  5.7070e-02,\n",
       "                       7.0319e-02, -5.0051e-02,  5.6011e-02,  7.0504e-03, -2.4769e-02,\n",
       "                      -5.9187e-02,  6.8519e-03, -1.1126e-01, -5.8974e-02,  1.2069e-02,\n",
       "                       6.1864e-02, -5.9687e-02,  4.1918e-02, -2.3532e-02, -5.5200e-02,\n",
       "                      -6.2727e-03,  1.1915e-02, -1.0420e-02, -3.5043e-02, -3.1115e-02,\n",
       "                       9.4790e-02,  7.2079e-02,  1.7193e-02, -9.3524e-03,  4.7546e-02,\n",
       "                       6.3627e-02,  1.0441e-02, -6.7544e-02, -9.5366e-02,  1.1197e-02,\n",
       "                       6.2571e-02, -3.0428e-03], device='cuda:0')),\n",
       "             ('TranformerBlock.norm2.weight',\n",
       "              tensor([0.7617, 0.9842, 0.9859, 1.0179, 1.0392, 0.9630, 0.9977, 0.9996, 0.9597,\n",
       "                      0.9873, 1.1832, 1.0063, 1.0593, 0.9211, 0.9813, 0.9776, 0.9430, 0.9863,\n",
       "                      0.9788, 1.0081, 0.8505, 1.0748, 0.9822, 0.9997, 0.9927, 0.9984, 1.0312,\n",
       "                      0.9898, 0.9937, 1.0785, 0.9767, 0.9624, 1.0592, 1.0409, 0.9919, 1.1019,\n",
       "                      0.9743, 1.0162, 1.0737, 1.0158, 1.0500, 0.9861, 0.9951, 0.9358, 0.9747,\n",
       "                      1.0359, 1.0100, 1.0850, 0.9674, 0.9675, 0.9700, 0.9898, 0.9649, 0.9869,\n",
       "                      1.0779, 0.9408, 1.0489, 0.8781, 1.0074, 0.9448, 0.9962, 1.0408, 0.9999,\n",
       "                      1.0056, 0.8907, 0.9909, 1.0184, 0.9973, 1.0470, 1.0880, 0.9105, 0.8063,\n",
       "                      1.0439, 0.9880, 0.9896, 0.9131, 0.9442, 0.9479, 1.0769, 0.9537, 0.9088,\n",
       "                      0.9106, 0.9734, 0.7955, 0.9921, 1.0661, 0.8871, 1.0578, 1.0747, 1.0793,\n",
       "                      0.9748, 0.9900, 1.0157, 0.9869, 0.9548, 1.0824, 1.0026, 0.9541, 0.9931,\n",
       "                      0.9587, 1.0588, 0.9692, 0.9848, 0.9788, 0.9950, 1.0907, 0.9734, 0.9247,\n",
       "                      1.0415, 1.0477, 0.9909, 0.9648, 0.9963, 1.0574, 1.0456, 0.9799, 1.0019,\n",
       "                      1.0263, 0.9678, 0.9905, 0.9915, 1.0409, 0.9844, 1.0665, 0.9884, 1.0801,\n",
       "                      0.9879, 1.0302, 0.9757, 1.0394, 0.8928, 1.1353, 1.0186, 0.9859, 0.9996,\n",
       "                      0.9259, 0.9594, 0.9986, 1.0816, 0.9949, 0.9802, 1.0043, 1.0737, 1.0092,\n",
       "                      0.9837, 0.9748, 1.0161, 0.9904, 0.9490, 1.0056, 1.0517, 1.1084, 1.0098,\n",
       "                      1.0294, 1.0687, 1.0524, 1.0513, 0.9513, 1.0631, 0.9979, 0.9850, 0.9599,\n",
       "                      0.9931, 0.9986, 1.0468, 1.0016, 1.0070, 0.9131, 0.9349, 0.9974, 1.0580,\n",
       "                      1.0061, 0.9491, 0.9728, 0.9039, 1.0349, 1.0600, 0.9930, 1.0299, 1.0196,\n",
       "                      1.0313, 0.7795, 1.0187, 1.0723, 0.8737, 0.8177, 0.9965, 1.0191, 0.9895,\n",
       "                      1.0019, 1.1324, 1.0318, 0.9454, 0.9516, 0.8875, 1.0024, 0.9621, 0.9363,\n",
       "                      1.0046, 1.0774, 1.0054, 0.9886, 1.0251, 0.9927, 1.0119, 1.0192, 0.9542,\n",
       "                      0.9955, 0.7896, 0.9846, 0.9120, 1.0373, 0.9707, 0.9727, 1.0090, 1.0003,\n",
       "                      0.9866, 1.0008, 1.0129, 0.9384, 0.9896, 0.9992, 1.1095, 1.1216, 0.9672,\n",
       "                      0.9939, 0.9096, 1.0798, 1.0623, 1.0846, 0.9726, 1.0641, 1.0882, 0.9851,\n",
       "                      0.9873, 1.0054, 1.1280, 0.9743, 1.0095, 0.8971, 0.9847, 1.0807, 0.9727,\n",
       "                      1.0621, 0.9727, 0.8724, 0.9225, 0.8591, 1.0767, 1.0883, 1.0766, 0.9801,\n",
       "                      0.9866, 1.0358, 1.0342, 0.9461, 0.9410, 0.9236, 1.0602, 1.0880, 0.8834,\n",
       "                      1.1088, 1.0244, 0.9924, 1.0731, 1.0098, 1.0507, 1.0295, 0.8662, 1.0842,\n",
       "                      0.9731, 1.0719, 0.9741, 0.9659, 0.9957, 0.9875, 1.0907, 1.1578, 0.9937,\n",
       "                      0.9203, 1.0003, 0.9800, 0.8043, 0.9962, 0.9044, 0.9991, 0.9847, 1.0699,\n",
       "                      1.0715, 1.0691, 0.9962, 0.9997, 0.9946, 0.9825, 0.9641, 1.1180, 0.9750,\n",
       "                      0.9710, 0.9714, 1.0553, 1.0766, 0.9917, 0.9274, 1.1058, 1.0958, 0.9550,\n",
       "                      0.9841, 0.9025, 1.0558, 1.0738, 1.0361, 1.0007, 0.9888, 0.9974, 1.0846,\n",
       "                      1.0770, 1.0006, 0.9602, 0.8867, 1.0073, 0.9816, 0.8671, 0.9824, 0.9918,\n",
       "                      0.9928, 1.0758, 0.9185, 0.9936, 1.0006, 0.9996, 1.0697, 0.8669, 0.8726,\n",
       "                      1.0476, 1.0745, 1.0529, 1.0054, 1.0680, 1.0054, 1.0124, 0.9655, 1.0730,\n",
       "                      0.9744, 0.9755, 1.0510, 0.9559, 0.9745, 1.0665, 0.9631, 0.9887, 0.9742,\n",
       "                      1.0142, 1.0112, 0.9306, 1.0810, 0.9996, 0.9698, 1.0617, 0.9637, 1.0839,\n",
       "                      0.9899, 1.1558, 0.9379, 0.9886, 1.0712, 0.9524, 1.0057, 1.0026, 1.0383,\n",
       "                      0.9905, 0.9850, 1.0187, 1.0138, 0.9924, 0.9556, 0.9600, 1.0061, 1.0886,\n",
       "                      0.9958, 0.9734, 0.9870, 1.0544, 0.9474, 1.1955, 1.0155, 0.9689, 0.9986,\n",
       "                      1.0809, 0.9965, 0.9399, 1.0235, 0.8993, 1.0245, 1.0388, 1.0373, 1.0197,\n",
       "                      0.8687, 0.9350, 1.0186, 0.9997, 0.9215, 0.9770, 0.9722, 0.9974, 0.9646,\n",
       "                      1.0077, 1.1259, 1.0830, 0.9928, 0.8671, 1.0155, 1.0236, 0.9870, 0.9383,\n",
       "                      0.9358, 1.0659, 1.0045, 0.9505, 1.0968, 0.9281, 1.0762, 0.9705, 0.9814,\n",
       "                      0.8891, 1.0041, 1.0830, 1.0625, 0.7085, 1.0109, 1.0669, 1.0716, 1.0358,\n",
       "                      1.0728, 1.1002, 0.9692, 0.7741, 1.0786, 1.0813, 0.9683, 1.0375, 0.9862,\n",
       "                      1.0576, 0.9360, 1.0183, 1.0095, 0.3259, 0.9316, 1.0599, 1.0138, 0.9964,\n",
       "                      0.9915, 1.0160, 0.9636, 0.9477, 0.9934, 1.1325, 0.9999, 0.9820, 0.9776,\n",
       "                      1.0209, 0.9672, 0.9407, 1.0389, 1.0591, 1.0499, 1.0862, 1.0948, 1.0180,\n",
       "                      1.0832, 1.0111, 0.9305, 0.9965, 0.9940, 1.0253, 0.9109, 0.9690, 0.9164,\n",
       "                      0.9995, 1.0202, 0.9715, 0.9887, 1.0704, 1.1112, 0.8845, 0.9878, 1.0320,\n",
       "                      0.9343, 0.9137, 0.9938, 1.0729, 1.0646, 0.5930, 1.0048, 1.0062, 1.0266,\n",
       "                      1.0671, 0.9550, 0.9568, 1.0617, 1.1019, 0.9750, 0.5789, 1.0333, 0.9748,\n",
       "                      1.0852, 1.0094, 0.9004, 0.9840, 1.0019, 0.9116, 0.9955, 0.9526],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.norm2.bias',\n",
       "              tensor([ 0.0009, -0.0033, -0.0300,  0.0653,  0.0593,  0.0584, -0.0633,  0.0299,\n",
       "                      -0.0294, -0.0384,  0.0271,  0.0632, -0.0309,  0.0250, -0.0304,  0.0333,\n",
       "                       0.0329,  0.0609,  0.0347,  0.0642,  0.0029, -0.0613,  0.0328, -0.0261,\n",
       "                       0.0436,  0.0403, -0.0355,  0.0299, -0.0682,  0.0775, -0.0152, -0.0393,\n",
       "                      -0.0572, -0.0617,  0.0255,  0.0643,  0.0099,  0.0612,  0.0338, -0.0386,\n",
       "                       0.0637,  0.0349, -0.0510, -0.0393,  0.0314, -0.0044,  0.0706, -0.0877,\n",
       "                       0.0191, -0.0294,  0.0242,  0.0373, -0.0355,  0.0372, -0.0748, -0.0326,\n",
       "                      -0.0583,  0.0011,  0.0208,  0.0249, -0.0314, -0.0450,  0.0432,  0.0571,\n",
       "                      -0.0189,  0.0349, -0.0598, -0.0325,  0.0703,  0.0890,  0.0371,  0.0080,\n",
       "                       0.0598,  0.0258, -0.0277,  0.0336, -0.0239,  0.0335, -0.0732, -0.0346,\n",
       "                       0.0296, -0.0357, -0.0421, -0.0557,  0.0350,  0.0692, -0.0193,  0.0703,\n",
       "                      -0.0725,  0.0801,  0.0329,  0.0456,  0.0653, -0.0318,  0.0390,  0.0836,\n",
       "                      -0.0328,  0.0376, -0.0360, -0.0413,  0.0675,  0.0350,  0.0265,  0.0236,\n",
       "                       0.0319, -0.0347, -0.0381,  0.0283, -0.0363,  0.0610, -0.0341, -0.0365,\n",
       "                       0.0347, -0.0813,  0.0593, -0.0598,  0.0314,  0.0689, -0.0324, -0.0359,\n",
       "                       0.0416, -0.0622,  0.0205, -0.0571,  0.0338, -0.0825, -0.0347, -0.0345,\n",
       "                       0.0357, -0.0683,  0.0199,  0.0309, -0.0619,  0.0415, -0.0402,  0.0385,\n",
       "                       0.0269, -0.0321, -0.0836, -0.0334, -0.0299,  0.0182, -0.0667,  0.0232,\n",
       "                      -0.0310,  0.0323,  0.0607,  0.0392,  0.0323, -0.0597,  0.0605,  0.0325,\n",
       "                      -0.0660,  0.0230, -0.0594,  0.0617, -0.0533, -0.0382,  0.0710,  0.0352,\n",
       "                       0.0304, -0.0369, -0.0320, -0.0327, -0.0328, -0.0415, -0.0438,  0.0296,\n",
       "                      -0.0211, -0.0204,  0.0769,  0.0435, -0.0381,  0.0330,  0.0055, -0.0036,\n",
       "                       0.0605,  0.0224, -0.0560, -0.0504,  0.0574, -0.0128,  0.0900,  0.0602,\n",
       "                      -0.0060, -0.0386,  0.0320, -0.0527, -0.0685,  0.0393,  0.0317, -0.0371,\n",
       "                       0.0190, -0.0407, -0.0203, -0.0630,  0.0309,  0.0333,  0.0619, -0.0721,\n",
       "                       0.0402, -0.0379,  0.0677, -0.0298,  0.0601,  0.0249,  0.0400, -0.0353,\n",
       "                       0.0044, -0.0336,  0.0276, -0.0359,  0.0081, -0.0566, -0.0641, -0.0421,\n",
       "                      -0.0365, -0.0673, -0.0278,  0.0378, -0.0368,  0.0378,  0.0332, -0.0605,\n",
       "                       0.0671, -0.0340, -0.0223, -0.0814,  0.0780,  0.0266, -0.0099,  0.0638,\n",
       "                       0.0918,  0.0288, -0.0312, -0.0575, -0.0554,  0.0361, -0.0399, -0.0171,\n",
       "                      -0.0292, -0.0629,  0.0148, -0.0595,  0.0322,  0.0208,  0.0248,  0.0223,\n",
       "                      -0.0665, -0.0548,  0.0751, -0.0376,  0.0366, -0.0777,  0.0613,  0.0445,\n",
       "                      -0.0354, -0.0239,  0.0682, -0.0891,  0.0605, -0.0563,  0.0675,  0.0389,\n",
       "                      -0.0613, -0.0285,  0.0321,  0.0314,  0.0235,  0.0283, -0.0692,  0.0700,\n",
       "                       0.0342,  0.0393, -0.0364,  0.0102, -0.0571, -0.0340, -0.0322,  0.0237,\n",
       "                      -0.0397, -0.0003, -0.0041, -0.0363, -0.0236,  0.0398, -0.0334, -0.0707,\n",
       "                       0.0693,  0.0575,  0.0340,  0.0347, -0.0391,  0.0257,  0.0395,  0.0398,\n",
       "                       0.0321, -0.0154,  0.0271, -0.0609, -0.0757, -0.0359,  0.0301, -0.0561,\n",
       "                      -0.0621,  0.0056,  0.0354,  0.0200,  0.0504, -0.0779, -0.0808,  0.0475,\n",
       "                       0.0287, -0.0390,  0.0861,  0.0815, -0.0652,  0.0426, -0.0222,  0.0477,\n",
       "                      -0.0581, -0.0013,  0.0337, -0.0296, -0.0375,  0.0707, -0.0248,  0.0284,\n",
       "                       0.0378, -0.0382,  0.0620, -0.0040, -0.0366, -0.0558,  0.0297, -0.0499,\n",
       "                       0.0370, -0.0735, -0.0610, -0.0422,  0.0339, -0.0744, -0.0342, -0.0019,\n",
       "                      -0.0538,  0.0343, -0.0048,  0.0696, -0.0107, -0.0301, -0.0147, -0.0644,\n",
       "                       0.0341, -0.0354, -0.0631, -0.0357,  0.0225,  0.0308, -0.0446, -0.0831,\n",
       "                      -0.0324,  0.0367,  0.0443,  0.0350,  0.0377,  0.0348, -0.0608,  0.0618,\n",
       "                      -0.0457, -0.0378,  0.0674, -0.0744, -0.0578, -0.0364,  0.0606, -0.0304,\n",
       "                       0.0643,  0.0300, -0.0659,  0.0178, -0.0337,  0.0543,  0.0255, -0.0570,\n",
       "                      -0.0338, -0.0338,  0.0332,  0.0827, -0.0322, -0.0340, -0.0505, -0.0121,\n",
       "                       0.0413, -0.0684,  0.0577, -0.0409,  0.0202,  0.0315,  0.0315, -0.0457,\n",
       "                       0.0261, -0.0287,  0.0333,  0.0603, -0.0386,  0.0518,  0.0264, -0.0885,\n",
       "                       0.0036, -0.0004, -0.0272,  0.0149,  0.0096, -0.0349,  0.0393,  0.0287,\n",
       "                       0.0401, -0.0363,  0.0279, -0.0271, -0.0769, -0.0407, -0.0347,  0.0319,\n",
       "                       0.0644, -0.0850, -0.0668,  0.0158,  0.0685,  0.0813, -0.0711, -0.0679,\n",
       "                      -0.0586, -0.0562,  0.0163,  0.0591, -0.0839,  0.0771,  0.0303, -0.0316,\n",
       "                      -0.0295, -0.0606,  0.0306,  0.0652, -0.0621,  0.0196, -0.0186, -0.0582,\n",
       "                       0.0623, -0.0610,  0.0610, -0.0395, -0.0149,  0.0299, -0.0318, -0.0552,\n",
       "                      -0.0597, -0.0286,  0.0334, -0.0408, -0.0329,  0.0297, -0.0570,  0.0857,\n",
       "                      -0.0521,  0.0873, -0.0583,  0.0471, -0.0316, -0.0555,  0.0211, -0.0527,\n",
       "                       0.0346,  0.0827,  0.0278, -0.0311, -0.0197, -0.0072,  0.0633,  0.0308,\n",
       "                      -0.0319, -0.0638, -0.0622, -0.0613, -0.0580,  0.0772, -0.0169,  0.0341,\n",
       "                       0.0369,  0.0701, -0.0586,  0.0159, -0.0421, -0.0402,  0.0555, -0.0637,\n",
       "                       0.0381,  0.0304,  0.0687,  0.0305, -0.0139, -0.0380,  0.0633, -0.0155,\n",
       "                       0.0876, -0.0326, -0.0241,  0.0341,  0.0287,  0.0034, -0.0250,  0.0310],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.feed_forward.0.weight',\n",
       "              tensor([[-0.0297,  0.1025, -0.0165,  ..., -0.0561, -0.0242, -0.0156],\n",
       "                      [-0.0485,  0.0285, -0.0414,  ..., -0.0740, -0.0321, -0.0626],\n",
       "                      [-0.0770,  0.0886, -0.0879,  ...,  0.0731, -0.1105, -0.0498],\n",
       "                      ...,\n",
       "                      [-0.0848,  0.0268, -0.0737,  ...,  0.1014, -0.0437, -0.0269],\n",
       "                      [-0.0478,  0.0714, -0.0687,  ...,  0.0423, -0.0741, -0.0452],\n",
       "                      [ 0.0332,  0.0364, -0.1004,  ...,  0.0632, -0.0743, -0.0655]],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.feed_forward.0.bias',\n",
       "              tensor([-0.0700, -0.0167, -0.0542,  ..., -0.0460, -0.0849, -0.0858],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.feed_forward.2.weight',\n",
       "              tensor([[-0.0790,  0.0455,  0.0285,  ..., -0.0508, -0.0532,  0.0714],\n",
       "                      [-0.0538, -0.0495, -0.0533,  ...,  0.0521, -0.0413, -0.0441],\n",
       "                      [ 0.0464,  0.0717,  0.0723,  ..., -0.0507,  0.0531,  0.0798],\n",
       "                      ...,\n",
       "                      [-0.0813, -0.0475,  0.0651,  ..., -0.0515, -0.0505,  0.0579],\n",
       "                      [ 0.0744,  0.0463, -0.0017,  ..., -0.0632,  0.0744,  0.0643],\n",
       "                      [-0.0477, -0.0551,  0.0533,  ..., -0.0568, -0.0563,  0.0792]],\n",
       "                     device='cuda:0')),\n",
       "             ('TranformerBlock.feed_forward.2.bias',\n",
       "              tensor([ 0.0105, -0.0819,  0.0644,  0.0446,  0.0347,  0.0466, -0.0090, -0.0279,\n",
       "                       0.0456,  0.0840, -0.0234,  0.0717,  0.0340, -0.0601,  0.0611, -0.0502,\n",
       "                      -0.0673,  0.0980, -0.0537,  0.0854,  0.0543, -0.0234, -0.0790,  0.0764,\n",
       "                      -0.0637, -0.0373,  0.0644, -0.0348, -0.0620,  0.0765,  0.0569,  0.0663,\n",
       "                      -0.0652, -0.0426, -0.0501,  0.0074, -0.0527,  0.0815, -0.0188, -0.0472,\n",
       "                       0.0755, -0.0802, -0.0685,  0.0508, -0.0399, -0.0844,  0.0777, -0.0597,\n",
       "                      -0.0597,  0.0530, -0.0727, -0.0595,  0.0403, -0.0453, -0.0679,  0.0610,\n",
       "                      -0.0502,  0.0505, -0.0619, -0.0482,  0.0579,  0.0182, -0.0493,  0.0388,\n",
       "                       0.0412, -0.0296, -0.0263,  0.0494,  0.0086,  0.0911, -0.0465,  0.0547,\n",
       "                       0.0235, -0.0663,  0.0493,  0.0684,  0.0264, -0.0484, -0.0550,  0.0313,\n",
       "                      -0.0568,  0.0131,  0.0472, -0.0334, -0.0716,  0.0309,  0.0582,  0.0393,\n",
       "                      -0.0620,  0.0900, -0.0148,  0.0026,  0.0546,  0.0249, -0.0473,  0.0865,\n",
       "                       0.0668, -0.0697,  0.0399,  0.0548,  0.0600, -0.0663, -0.0617,  0.0034,\n",
       "                      -0.0562,  0.0373,  0.0539, -0.0757,  0.0324,  0.0254,  0.0412, -0.0534,\n",
       "                      -0.0262, -0.0864,  0.0240, -0.0346, -0.0557,  0.0458,  0.0549,  0.0487,\n",
       "                      -0.0838, -0.0283, -0.0765, -0.0134, -0.0603, -0.0678,  0.0599, -0.0678,\n",
       "                      -0.0578, -0.0051, -0.0725,  0.0196, -0.0739, -0.0815,  0.0516, -0.0261,\n",
       "                      -0.0586,  0.0667, -0.0727,  0.0843,  0.0212, -0.0801, -0.0524, -0.0485,\n",
       "                       0.0425, -0.0248,  0.0621, -0.0507, -0.0324,  0.0150,  0.0458, -0.0362,\n",
       "                      -0.0768, -0.0558, -0.0367,  0.0268, -0.0847,  0.0727,  0.0338, -0.0523,\n",
       "                      -0.0632,  0.0122,  0.0730,  0.0794,  0.0052,  0.0735,  0.0629, -0.0215,\n",
       "                       0.0596,  0.0755,  0.0547,  0.0572,  0.0373, -0.0309, -0.0320, -0.0562,\n",
       "                       0.0535, -0.0498,  0.0581, -0.0238,  0.0290,  0.0182,  0.0611,  0.0345,\n",
       "                      -0.0294,  0.0532, -0.0469,  0.0507, -0.0431, -0.0361,  0.0170,  0.0423,\n",
       "                      -0.0665,  0.0618,  0.0373, -0.0442, -0.0356, -0.0394,  0.0803, -0.0638,\n",
       "                      -0.0692,  0.0623,  0.0466, -0.0867,  0.0522,  0.0809, -0.0369,  0.0743,\n",
       "                       0.0521,  0.0460, -0.0443,  0.0282, -0.0799, -0.0206, -0.0470,  0.0593,\n",
       "                       0.0523, -0.0811,  0.0763, -0.0442,  0.0784, -0.0733,  0.0070, -0.0386,\n",
       "                       0.0834,  0.0568,  0.0289, -0.0575,  0.0499,  0.0378,  0.0494,  0.0410,\n",
       "                       0.0952, -0.0621,  0.0670, -0.0356, -0.0243, -0.0444,  0.0578,  0.0454,\n",
       "                       0.0743, -0.0136, -0.0591, -0.0692, -0.0403, -0.0427, -0.0097, -0.0425,\n",
       "                      -0.0471, -0.0033,  0.0691,  0.0589, -0.0585, -0.0254,  0.0361, -0.0479,\n",
       "                       0.0707,  0.0629,  0.0379, -0.0792,  0.0653, -0.0026,  0.0306,  0.0477,\n",
       "                      -0.0268,  0.0335, -0.0430, -0.0299, -0.0128,  0.0209,  0.0817,  0.0684,\n",
       "                      -0.0365, -0.0660,  0.0574, -0.0609, -0.0379,  0.0401,  0.0602, -0.0070,\n",
       "                       0.0791, -0.0465,  0.0581,  0.0572,  0.0606, -0.0774,  0.0296, -0.0812,\n",
       "                       0.0705,  0.0447, -0.0814, -0.0366,  0.0473, -0.0552, -0.0540,  0.0071,\n",
       "                      -0.0527, -0.0439, -0.0229, -0.0911, -0.0726,  0.0517, -0.0265, -0.0034,\n",
       "                      -0.0415, -0.0792, -0.0407, -0.0512,  0.0813, -0.0900, -0.0774, -0.0456,\n",
       "                      -0.0650,  0.0539,  0.0514,  0.0723, -0.0114, -0.0636,  0.0676,  0.0904,\n",
       "                       0.0149, -0.0396, -0.0479,  0.0152,  0.0651,  0.0897,  0.0508, -0.0804,\n",
       "                      -0.0614,  0.0417,  0.0089, -0.0617,  0.0154, -0.0208, -0.0534, -0.0679,\n",
       "                       0.0584, -0.0846, -0.0443,  0.0521, -0.0472, -0.0578,  0.0633,  0.0481,\n",
       "                      -0.0063, -0.0841, -0.0745,  0.0540,  0.0210,  0.0441,  0.0812, -0.0356,\n",
       "                      -0.0500,  0.0399, -0.0344,  0.0662, -0.0775, -0.0048,  0.0134, -0.0720,\n",
       "                       0.0616, -0.0018,  0.0092, -0.0691,  0.0296,  0.0830, -0.0632,  0.0713,\n",
       "                      -0.0538,  0.0746,  0.0622, -0.0903, -0.0006,  0.0339,  0.0969,  0.0455,\n",
       "                       0.0470, -0.0208, -0.0707, -0.0379,  0.0824,  0.0358, -0.0511, -0.0204,\n",
       "                       0.0169,  0.0280, -0.0519,  0.0826,  0.0715,  0.0380, -0.0668,  0.0671,\n",
       "                      -0.0624, -0.0392,  0.0343,  0.0455, -0.0419, -0.0637, -0.0155,  0.0517,\n",
       "                      -0.0783,  0.0489, -0.0624,  0.0751,  0.0469,  0.0931,  0.0056, -0.1061,\n",
       "                       0.0816, -0.0459,  0.0739, -0.0605, -0.0807,  0.0538, -0.0196,  0.0276,\n",
       "                      -0.0642,  0.0596,  0.0200,  0.0415, -0.0630,  0.0791,  0.0572, -0.0672,\n",
       "                       0.0487, -0.0802, -0.0459, -0.0484,  0.0731,  0.0470, -0.0574, -0.0462,\n",
       "                      -0.0070,  0.0133, -0.0427,  0.0460, -0.0736,  0.0666, -0.0364,  0.0179,\n",
       "                       0.0668, -0.0622, -0.0700,  0.0370, -0.0444, -0.0171,  0.0240, -0.0321,\n",
       "                       0.0476, -0.0389,  0.0750,  0.0520,  0.0570, -0.0312,  0.0212, -0.0179,\n",
       "                      -0.0612,  0.0397, -0.0770,  0.0502,  0.0322, -0.0134,  0.0094,  0.0190,\n",
       "                      -0.0753,  0.0792, -0.0196, -0.0818,  0.0313,  0.0110, -0.0399,  0.0483,\n",
       "                      -0.0318,  0.0647, -0.0594,  0.0242,  0.0348, -0.0657,  0.0773, -0.0404,\n",
       "                       0.0420, -0.0798, -0.0400, -0.0927, -0.0047,  0.0644,  0.0149,  0.0159,\n",
       "                      -0.0525,  0.0583, -0.0174, -0.0354,  0.0615,  0.0707,  0.0503, -0.0619,\n",
       "                      -0.0520, -0.0384,  0.0343,  0.0106,  0.0573, -0.0532,  0.0522,  0.0564,\n",
       "                       0.0928,  0.0128,  0.0421, -0.0662, -0.0298, -0.0584,  0.0508, -0.0613],\n",
       "                     device='cuda:0')),\n",
       "             ('quantization.codebooks',\n",
       "              tensor([[[-0.1381,  1.4941, -0.2488,  ..., -0.5181, -1.3330,  0.2927],\n",
       "                       [ 0.0558, -0.7206,  0.9876,  ..., -0.0734,  1.5444, -1.1366],\n",
       "                       [-0.8530,  0.4742, -2.1101,  ...,  1.3628,  0.7058,  2.8273],\n",
       "                       ...,\n",
       "                       [-1.5255,  0.7122,  2.1408,  ...,  0.5416, -1.2870,  0.9425],\n",
       "                       [ 0.8930,  0.2645, -0.4528,  ...,  0.7889,  0.0892,  1.0871],\n",
       "                       [-1.2990, -0.6232, -0.6123,  ..., -0.9585,  1.1199, -1.0287]],\n",
       "              \n",
       "                      [[-0.0456,  0.6404,  1.3355,  ...,  0.3966, -0.5163, -0.8326],\n",
       "                       [ 1.3283, -0.1857,  0.6506,  ..., -1.0748,  0.9771, -1.1427],\n",
       "                       [-0.0854,  0.1446,  0.0482,  ..., -1.3995,  0.5465, -1.1488],\n",
       "                       ...,\n",
       "                       [-1.6314,  0.4270, -0.7125,  ...,  0.8057, -0.9375, -1.0822],\n",
       "                       [ 0.8967, -0.6185, -0.9167,  ...,  1.7803,  1.6993,  1.2045],\n",
       "                       [ 0.3637,  1.0843, -1.0000,  ...,  0.6325,  0.8598,  0.7490]]],\n",
       "                     device='cuda:0')),\n",
       "             ('quantization.linear.weight',\n",
       "              tensor([[ 0.1541,  0.0687, -0.0377,  ...,  0.0411, -0.0737,  0.0264],\n",
       "                      [-0.0254, -0.0023,  0.0255,  ..., -0.0857,  0.0369,  0.0343],\n",
       "                      [-0.0481, -0.0475, -0.0342,  ...,  0.0663, -0.0730, -0.0739],\n",
       "                      ...,\n",
       "                      [ 0.0505,  0.0466,  0.0018,  ..., -0.0130,  0.0024,  0.0962],\n",
       "                      [-0.0491, -0.0463, -0.0074,  ...,  0.0703, -0.0560, -0.0900],\n",
       "                      [ 0.0299,  0.0348, -0.0216,  ..., -0.0278,  0.0275,  0.0470]],\n",
       "                     device='cuda:0')),\n",
       "             ('quantization.linear.bias',\n",
       "              tensor([ 1.2093e-01,  5.4797e-02,  1.0548e-02,  5.8550e-02,  5.4321e-02,\n",
       "                       1.3129e-01, -8.3115e-02,  1.2569e-02,  7.7296e-02, -7.3246e-02,\n",
       "                      -5.4981e-02,  4.9057e-02,  1.9317e-02,  6.7822e-02, -3.2087e-02,\n",
       "                      -1.1941e-02,  1.3956e-02, -8.8682e-02, -1.5873e-02,  1.0890e-02,\n",
       "                      -1.7398e-01,  1.3257e-02, -1.6518e-02,  2.7165e-02,  4.7980e-03,\n",
       "                       2.7573e-03, -1.7488e-02,  2.4402e-02, -4.9756e-02,  4.7680e-02,\n",
       "                      -1.0674e-02, -7.4673e-02, -6.3262e-02, -8.5456e-02,  3.5999e-02,\n",
       "                       3.6585e-02,  7.2624e-02, -1.2155e-02, -4.1341e-02, -4.4589e-02,\n",
       "                       5.9872e-02, -3.0873e-03, -8.8412e-03,  3.8276e-03,  1.8673e-02,\n",
       "                      -2.8547e-02,  4.2909e-02, -6.0861e-02, -2.5862e-02,  1.2478e-02,\n",
       "                      -3.2965e-03, -5.0885e-02, -4.1954e-03, -6.0118e-03, -4.8475e-02,\n",
       "                       6.1127e-02,  3.6814e-02, -2.2690e-01,  2.6417e-02, -1.9897e-02,\n",
       "                      -4.9959e-02,  1.6646e-02,  3.1530e-02,  6.2759e-02, -5.7158e-03,\n",
       "                      -1.2406e-02,  5.5685e-02,  9.7369e-03, -5.6213e-02,  4.6431e-02,\n",
       "                       1.1490e-01, -1.2461e-01, -3.5749e-02, -1.3704e-02, -1.8912e-02,\n",
       "                       8.0116e-02,  1.6010e-02,  7.8525e-02, -4.5745e-02, -7.2828e-02,\n",
       "                       7.1000e-02, -1.1306e-01, -4.7400e-02,  7.2745e-02, -1.7063e-02,\n",
       "                       9.6761e-02,  4.9879e-02,  8.6748e-03, -4.0621e-02,  5.1798e-02,\n",
       "                      -1.7546e-02,  3.9629e-02,  6.4400e-03, -8.5430e-03, -1.0615e-01,\n",
       "                       4.2281e-02,  6.1466e-02,  7.8287e-03,  1.2542e-03, -5.2163e-02,\n",
       "                       2.7476e-02, -1.1235e-02, -3.3475e-02,  5.7692e-02, -2.7562e-02,\n",
       "                      -3.9344e-02, -5.0875e-02,  1.4371e-02, -2.4455e-02,  8.6592e-02,\n",
       "                       4.1287e-02, -7.8926e-02,  3.4501e-02,  6.6034e-02, -3.3502e-02,\n",
       "                       9.2073e-02, -3.6144e-02, -8.4335e-02,  1.3981e-02,  1.3977e-02,\n",
       "                      -1.2210e-02, -3.2457e-03, -7.6233e-03, -2.6354e-02, -5.7896e-02,\n",
       "                      -4.2511e-02, -9.3852e-04, -4.7414e-02, -1.9508e-02,  2.9568e-02,\n",
       "                       1.0698e-01, -6.5745e-03, -2.2055e-02,  5.0936e-02,  3.9410e-02,\n",
       "                      -8.5012e-02, -4.9926e-02, -2.2784e-02, -9.2367e-02,  2.0268e-02,\n",
       "                       5.2073e-02, -2.5646e-02, -1.2647e-02,  2.9277e-02,  2.1459e-02,\n",
       "                      -4.5297e-02, -2.3297e-03, -3.7633e-02, -9.0104e-03,  1.3202e-02,\n",
       "                       1.0367e-01,  5.6740e-03,  1.0435e-02,  2.7459e-02,  3.2646e-02,\n",
       "                      -3.1443e-02, -8.9680e-02, -5.3296e-02,  2.1309e-02,  9.7961e-02,\n",
       "                       2.6574e-02,  2.9392e-02, -4.2246e-03,  3.1138e-02,  1.7879e-02,\n",
       "                      -2.7036e-02, -2.8754e-02,  1.1270e-01, -2.3472e-02,  1.2977e-02,\n",
       "                      -6.1088e-03, -1.0468e-03, -1.2671e-03, -1.2343e-02,  2.2556e-01,\n",
       "                       1.3551e-02,  9.6133e-02, -1.7045e-02, -3.0393e-02, -6.6375e-02,\n",
       "                      -5.2808e-02, -6.0245e-02,  7.3531e-03,  4.7483e-02, -1.0793e-01,\n",
       "                       8.3624e-02,  1.0450e-02, -3.6830e-02, -6.6362e-02, -3.5765e-03,\n",
       "                      -2.0592e-02, -4.1379e-02,  3.0235e-02,  3.1753e-02,  2.8880e-02,\n",
       "                       1.0273e-02, -1.4403e-03,  5.1894e-02,  6.6538e-02, -6.6147e-02,\n",
       "                      -9.8066e-03, -3.3438e-02, -1.2768e-01, -1.1710e-01,  3.0693e-02,\n",
       "                       6.1001e-02,  1.9793e-02,  9.3607e-03,  1.2251e-01,  3.2505e-02,\n",
       "                       5.2926e-02, -6.5230e-03, -3.3656e-02,  2.8100e-02, -3.4509e-02,\n",
       "                      -2.0787e-02, -5.2625e-02, -8.0059e-02,  1.6637e-02,  6.8943e-03,\n",
       "                       5.0087e-02,  7.6628e-05, -5.5238e-02, -1.9973e-02,  1.1593e-01,\n",
       "                      -7.9175e-03, -3.4138e-02, -5.4856e-02, -5.4758e-02, -3.1854e-02,\n",
       "                      -5.6742e-03,  3.7690e-02, -3.7591e-02,  1.6746e-02,  3.5338e-02,\n",
       "                      -9.8209e-02,  4.2172e-03, -6.5270e-02, -1.4797e-02, -6.7227e-02,\n",
       "                       1.0671e-02,  3.5918e-02,  6.0079e-02,  8.1161e-03,  8.2777e-04,\n",
       "                       9.4518e-02, -9.0125e-02,  2.5388e-02, -2.1376e-02,  3.3656e-02,\n",
       "                       3.6167e-02,  7.2881e-02, -4.3521e-02, -2.5275e-02, -2.7439e-02,\n",
       "                      -7.3653e-02, -3.2425e-02, -8.1601e-02,  3.1950e-02,  1.6218e-02,\n",
       "                       1.1711e-01, -2.8193e-02, -5.9865e-02, -3.4978e-03,  3.1175e-03,\n",
       "                      -7.4075e-02,  1.4748e-02,  6.8758e-03,  5.6188e-04, -2.6213e-02,\n",
       "                      -9.5853e-03,  1.5540e-01,  2.2870e-02,  3.1552e-02, -2.5426e-02,\n",
       "                       2.4543e-02, -2.2213e-03, -2.7566e-02, -5.4803e-02, -3.5689e-02,\n",
       "                       9.3320e-04,  1.5233e-02, -7.0123e-02, -2.8033e-02, -1.2768e-01,\n",
       "                      -1.1954e-02, -5.6583e-02,  8.2742e-02,  7.4273e-02, -4.6385e-02,\n",
       "                       3.5699e-02,  5.8489e-02, -5.4158e-03, -4.5530e-02, -9.6910e-03,\n",
       "                      -1.0720e-01, -1.1902e-02, -2.0902e-02, -7.2161e-02,  3.2067e-02,\n",
       "                      -4.8561e-02,  2.2231e-02, -3.9953e-02, -2.5211e-02,  3.3064e-02,\n",
       "                      -6.0742e-02,  6.5853e-03,  8.1124e-02,  2.1154e-02, -6.3366e-02,\n",
       "                      -3.7481e-02, -2.4730e-02,  1.7941e-02, -2.8281e-02,  8.8846e-02,\n",
       "                       8.3237e-02, -2.0375e-02, -7.3790e-04, -6.5729e-02,  7.5884e-02,\n",
       "                      -4.5435e-02,  1.6394e-01,  5.3704e-03,  1.4635e-02,  2.6748e-02,\n",
       "                       9.6353e-02, -7.1036e-02, -4.5821e-02, -7.8663e-03, -1.6810e-02,\n",
       "                      -3.6427e-02, -4.9669e-02, -7.8400e-02, -4.3805e-02, -1.4204e-02,\n",
       "                      -6.6845e-02,  9.3088e-02, -6.9293e-03, -6.4784e-02,  6.5905e-03,\n",
       "                      -1.5540e-02, -4.1376e-02,  4.1899e-02, -8.0404e-03,  3.4732e-02,\n",
       "                      -3.8931e-02, -2.7837e-02,  1.9651e-04,  1.0907e-01,  5.5237e-04,\n",
       "                      -1.2020e-02,  1.5198e-02, -7.7022e-03,  1.3126e-02,  2.4561e-02,\n",
       "                      -1.9763e-03, -2.6640e-02,  3.7603e-02,  3.9912e-02, -5.9727e-02,\n",
       "                       2.0753e-02,  4.5218e-02,  1.2751e-01,  1.9670e-02,  2.4534e-02,\n",
       "                      -1.1436e-01, -2.7920e-02,  5.2380e-02, -6.1465e-02,  1.9858e-02,\n",
       "                       1.6205e-01, -2.1344e-01, -4.5225e-02,  3.2771e-02, -8.7406e-02,\n",
       "                       9.3212e-03,  4.8852e-02,  6.8924e-02, -7.6792e-02,  3.7373e-03,\n",
       "                       5.0365e-02,  1.3931e-03, -4.4934e-02, -1.3492e-02, -2.1450e-02,\n",
       "                      -2.9170e-02,  2.5072e-02,  1.2764e-01,  3.6897e-02, -3.9900e-02,\n",
       "                      -9.8392e-02,  6.4954e-02,  2.8103e-02, -1.0424e-02, -3.6436e-02,\n",
       "                       3.5436e-02,  5.8164e-02, -4.7997e-02,  2.1098e-02, -3.6468e-03,\n",
       "                       9.1870e-02,  3.7499e-02,  3.5480e-02,  3.6522e-02, -6.4313e-03,\n",
       "                       1.2948e-01, -3.3440e-02, -3.3072e-02, -4.2894e-02, -2.7033e-01,\n",
       "                       4.5670e-02, -5.8728e-03,  8.0837e-02, -1.3347e-02, -5.7356e-02,\n",
       "                      -7.2223e-02,  1.7190e-02, -3.4002e-02, -1.7404e-02,  3.0493e-02,\n",
       "                      -2.6433e-02,  5.2978e-02, -9.4590e-03,  1.1439e-01, -1.5571e-03,\n",
       "                       3.1930e-02,  5.7008e-02,  2.2779e-02,  9.4011e-02,  1.1216e-02,\n",
       "                      -7.8276e-02, -6.4631e-02,  1.7880e-02, -3.3344e-03, -4.7157e-02,\n",
       "                       2.7929e-01, -3.5728e-02,  5.3909e-02, -4.4831e-02, -6.1335e-03,\n",
       "                       3.3553e-02, -1.1627e-03, -4.6120e-03, -1.9831e-02, -2.1094e-02,\n",
       "                       5.1614e-01, -1.9170e-02, -2.9860e-02,  1.7429e-02, -2.6573e-02,\n",
       "                       5.4997e-02,  1.4658e-03,  4.8638e-02, -6.4492e-03,  7.5638e-02,\n",
       "                       2.6201e-02, -1.4586e-01,  2.2631e-02, -3.9808e-02, -6.1815e-02,\n",
       "                       2.3466e-02,  9.0957e-03, -6.7250e-02,  7.2087e-02, -6.7775e-02,\n",
       "                       8.0660e-02,  2.2017e-02,  6.5200e-03,  1.9586e-02, -2.6795e-02,\n",
       "                       4.7118e-02, -6.3903e-02, -3.3170e-04,  9.1604e-02,  1.0006e-01,\n",
       "                       3.1855e-02, -2.1251e-02, -6.2980e-02,  1.0689e-01,  5.6029e-02,\n",
       "                       4.1069e-02, -4.8510e-02,  8.1884e-03,  8.7132e-02, -8.6468e-02,\n",
       "                       2.6101e-02, -2.9366e-03, -1.0377e-01,  4.0737e-03,  1.1400e-01,\n",
       "                       1.8290e-02,  3.0276e-01, -1.2358e-02,  1.3853e-03, -4.6082e-02,\n",
       "                      -5.6721e-02,  6.6667e-02,  3.0788e-02,  2.0432e-02, -1.8076e-02,\n",
       "                      -3.6019e-02, -2.3060e-01, -5.0896e-02,  3.7743e-02,  7.2764e-02,\n",
       "                      -4.7847e-04, -1.3583e-01,  2.4741e-02,  3.5929e-02, -1.9588e-02,\n",
       "                      -3.8434e-02,  9.2651e-02], device='cuda:0'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maa\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): subscript d has size 256 for operand 1 which does not broadcast with previously seen size 192",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Assurez-vous que les inputs sont sur le bon device\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Passe avant\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m quantized_repr, contextualized_reps, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Ajout des représentations à la liste\u001b[39;00m\n\u001b[1;32m     22\u001b[0m all_quantized_reps\u001b[38;5;241m.\u001b[39mappend(quantized_repr\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m, in \u001b[0;36mModel_W2V.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFeaturesEncoder(x)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m quantized_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m masked_reps, mask, mask_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_prob, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_length)\n\u001b[1;32m     46\u001b[0m contextualized_reps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTranformerBlock(masked_reps, masked_reps, masked_reps)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/W2V/MLA_Wave2Vec/Modules/quantizationModule.py:52\u001b[0m, in \u001b[0;36mQuantizationModule.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     49\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m1501\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_codebooks, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Compute logits and add Gumbel noise\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbtsd,gvd->btsg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodebooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m gumbel_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mrand_like(logits) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-9\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-9\u001b[39m)\n\u001b[1;32m     54\u001b[0m logits \u001b[38;5;241m=\u001b[39m (logits \u001b[38;5;241m+\u001b[39m gumbel_noise) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/functional.py:402\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    404\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): subscript d has size 256 for operand 1 which does not broadcast with previously seen size 192"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Créez un DataLoader pour le jeu de données de test\n",
    "dataset = TempLibriSpeech.LibriSpeech(split=\"test-clean\", target_length=480000, device='cuda')\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "all_quantized_reps = []\n",
    "all_contextualized_reps = []\n",
    "\n",
    "# Calcul de la perte de reconstruction ou de quantification\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        inputs, _ = batch  # Ici, _ signifie qu'il n'y a pas de labels\n",
    "        \n",
    "        inputs = inputs.to('cuda')  # Assurez-vous que les inputs sont sur le bon device\n",
    "\n",
    "        # Passe avant\n",
    "        quantized_repr, contextualized_reps, loss = model(inputs)\n",
    "\n",
    "        # Ajout des représentations à la liste\n",
    "        all_quantized_reps.append(quantized_repr.cpu().numpy())\n",
    "        all_contextualized_reps.append(contextualized_reps.cpu().numpy())\n",
    "\n",
    "        # Accumuler la perte\n",
    "        total_loss += loss.item()\n",
    "\n",
    "# Calcul de la moyenne de la perte sur l'ensemble du dataset\n",
    "average_loss = total_loss / len(data_loader)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Average Loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 174578.9069\n"
     ]
    }
   ],
   "source": [
    "average_loss = total_loss / len(data_loader)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Average Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3569e-04,  3.0518e-04,  3.6621e-04,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.0376e-03,  1.0986e-03,  9.1553e-04,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 3.6621e-04,  6.4087e-04,  7.6294e-04,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        ...,\n",
       "        [-9.7656e-04, -1.1597e-03, -1.0681e-03,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 8.2397e-04, -3.0518e-05,  9.1553e-05,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 7.0190e-04,  2.7466e-03,  5.3101e-03,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
